# 系统面经

##### 

#### 中级题

##### 哪些集合类是线程安全的

1. Concurrenthashmap的实现，1.7和1.8的实现

##### Arrays.sort的实现

##### 什么时候使用CopyOnArrayList

##### CAS和AQS的实现原理

##### reentrantlock的实现和Synchronied的区别

##### 双亲委派模型

##### 反射机制：反射动态擦除泛型、反射动态调用方法等

##### 动态绑定：父类引用指向子类对象

##### JVM内存管理机制：有哪些区域，每个区域做了什么

##### JVM垃圾回收机制：垃圾回收算法 垃圾回收器 垃圾回收策略

##### jvm参数的设置和jvm调优

##### 什么情况产生年轻代内存溢出、什么情况产生年老代内存溢出

##### Redis和memcached

1. 什么时候选择redis，什么时候选择memcached
2. 内存模型和存储策略是什么样的 

##### java中bio nio aio的区别和联系

##### 为什么bio是阻塞的 nio是非阻塞的 nio是模型是什么样的

- BIO就是指IO，即传统的Blocking IO,即同步并阻塞的IO。依赖于ServerSocket实现，即一个请求对应一个线程，如果线程数不够连接则会等待空余线程或者拒绝连接。
- NIO，即New IO或者Non-Blocking IO,即同步不阻塞的IO。定义在java.nio包下面。相比于传统的BIO,NIO 提供了高速的面向快的I/O,它加入了Buffer、Channel、Selector等概念。它是基于事件驱动的，采用了Reactor模式，它使用一个线程管理所有的socket通道，即客户端发送的连接请求都会注册到多路复用器上，多路复用器轮询到连接有I/O请求时才启动一个线程进行处理。它的特点是要不断主动地去询问数据有没有处理完，一般只适用于连接数目较大但连接时间短的应用，如聊天应用等。
- AIO，新的IO2.0，即NIO2.0，jdk1.7开始应用，叫做异步不阻塞的IO。AIO引入异常通道的概念，采用了Proactor模式，简化了程序编写，一个有效的请求才启动一个线程，它的特点是先由操作系统完成后才通知服务端程序启动线程去处理，一般适用于连接数较多且连接时间长的应用。

几种IO的综合对比：

|               | BIO    | NIO      | AIO    |
| ------------- | ------ | -------- | ------ |
| 客户端:线程数 | 1:1    | M:1      | M:0    |
| 阻塞类型      | 阻塞   | 非阻塞   | 非阻塞 |
| 同步类型      | 同步   | 同步     | 异步   |
| 编程难度      | 简单   | 非常复杂 | 复杂   |
| 调试难度      | 简单   | 复杂     | 复杂   |
| 可靠性        | 非常差 | 高       | 高     |
| 吞吐量        | 低     | 高       | 高     |

##### ClassNotFoundException , NoClassDefFoundError , ClassCastException

- ClassNotFoundException : 找不到类异常,继承了Exception，即在当前classpath路径下找不到这个类,这个异常一般发生在显示加载类的时候
- NoClassDefFoundError : 虚拟机隐式加载类出现的异常, 异常继承了Error类，一般发生在引用的类不存在，即类、方法或者属性引用了某个类或者接口，如果目标引用不存在就会抛出这个异常。

```plain
//MyDomBuilder继承了DOMBuilder，
//如果把DOMBuilder所属的jar包范围设置为provided，
//即运行时找不到DOMBuilder类就会报错。
import org.jdom2.input.DOMBuilder;
public class MyDomBuilder extends DOMBuilder{
}
public static void main(String[] args){
    MyDomBuilder builder = new MyDomBuilder();
}
```

- ClassCastException： 继承了运行时异常RuntimeException， 类转换异常，这个错误一般发生在一个对象强制转换类型的时候，如将一个String强制转换成Integer就会报这个错。

##### Java io的整体架构和使用的设计模式

##### 泛型与类型擦除

- Java语言中的泛型机制其实就是一颗语法糖，相较与C++、C#相比，其泛型实现实在是不那么优雅。

```plain
/**
 * 在源代码中存在泛型
 */
public static void main(String[] args) {
    Map<String,String> map = new HashMap<String,String>();
    map.put("hello","你好");
    String hello = map.get("hello");
    System.out.println(hello);
}
// 当上述源代码被编译为class文件后，泛型被擦除且引入强制类型转换
public static void main(String[] args) {
    HashMap map = new HashMap();
    //类型擦除
    map.put("hello", "你好");
    String hello = (String)map.get("hello");
    //强制转换
    System.out.println(hello);
}
```

#### 高级题

##### rpc相关：如何设计一个rpc框架，从io模型 传输协议 序列化方式综合考虑

##### Linux命令 统计，排序，前几问题等

##### StringBuff 和StringBuilder的实现，底层实现是通过byte数据，外加数组的拷贝来实现的

##### 内存缓存和数据库的一致性同步实现

##### 微服务的优缺点

##### 线程池的参数问题

##### ip问题 如何判断ip是否在多个ip段中

##### 判断数组两个中任意两个数之和是否为给定的值

##### synchronized实现原理

##### 消息队列广播模式和发布/订阅模式的区别

##### 生产者消费者代码实现

##### 死锁代码实现

##### 线程池：参数，每个参数的作用，几种不同线程池的比较，阻塞队列的使用，拒绝策略

##### Future和ListenableFuture 异步回调相关

##### 在Java中wait和seelp方法的不同

##### 什么时候需要加volatile关键字？它能保证线程安全吗？

##### concurrentHashMap怎么实现？concurrenthashmap在1.8和1.7里面有什么区别

##### CountDownLatch、LinkedHashMap、AQS实现原理

##### OOM说一下？怎么排查？哪些会导致OOM?

##### 说说一致性 Hash 原理

##### 分布式一致性协议，二段、三段、TCC，优缺点

##### Java的内存模型，Java8做了什么修改

##### 如何进行JVM调优？有哪些方法？

##### 怎么理解强一致性、单调一致性和最终一致性？

##### 谈一谈一致性哈希算法。

##### **序列化方案都有哪些，说说它们的优缺点？**

序列化有对象序列化，JSON序列化，XML序列化等，像java自带序列化、kryo、protostuff、GSON、jackson、fastjson等

##### Java对象引用四个级别（强、软、弱、虚）

- 强引用（StrongReference）， 就是我们平常最基本的对象引用，如果是强引用，那回收器不会回收带有强引用的对象。即使内存不足抛出OutOfMemoryError异常也不会回收强引用对象
- 软引用（SoftReference），一个对象只有软引用，如果内存空间足够情况下垃圾回收器就不会回收它，如果内存空间不够了就会对这些只有软引用的对象进行回收。只要垃圾回收器没有回收，该软引用对象就可以继续被程序使用。
- 弱引用（WeakReference），弱引用的对象具有更短暂的生命周期，在垃圾回收器线程扫描它所管辖的内存区域的过程中，一旦发现了只具有弱引用的对象，不管当前内存空间足够与否，都会回收它的内存。不过，由于垃圾回收器是一个优先级很低的线程，因此不一定会很快发现那些只具有弱引用的对象。
- 虚引用（PhantomReference），虚引用顾名思义就是形同虚设，虚引用并不决定对象的生命周期，如果一个对象仅持有虚引用，那么它就和没有任何引用一样，在任何时候都可能被垃圾回收器回收。

| 引用类型 | 回收时间     | 用途         |
| -------- | ------------ | ------------ |
| 强引用   | 永不回收     | 普通对象引用 |
| 软引用   | 内在不足回收 | 缓存对象     |
| 弱引用   | 垃圾回收时   | 缓存对象     |
| 虚引用   | 不确定       | 不确定       |

##### 解析XML的几种方式的原理与特点：DOM、SAX

### Java代码优化技巧

- [Java代码优化技巧](#toc_0)

- - [尽量指定类、方法的final修饰符](#toc_1)
  - [尽量重用对象](#toc_2)
  - [尽可能使用局部变量](#toc_3)
  - [及时关闭流](#toc_4)
  - [尽量减少对变量的重复计算](#toc_5)
  - [循环内不要不断创建对象引用](#toc_6)
  - [尽量采用懒加载的策略，即在需要的时候才创建](#toc_7)
  - [慎用异常](#toc_8)
  - [如果能估计到待添加的内容长度，为底层以数组方式实现的集合、工具类指定初始长度](#toc_9)
  - [当复制大量数据时，使用System.arraycopy()命令](#toc_10)
  - [乘法和除法使用移位操作](#toc_11)
  - [循环内不要不断创建对象引用](#toc_12)
  - [基于效率和类型检查的考虑，应该尽可能使用array，无法确定数组大小时才使用ArrayList](#toc_13)
  - [尽量使用HashMap、ArrayList、StringBuilder，除非线程安全需要，否则不推荐使用Hashtable、Vector、StringBuffer，后三者由于使用同步机制而导致了性能开销](#toc_14)
  - [尽量在合适的场合使用单例](#toc_15)
  - [尽量避免随意使用静态变量](#toc_16)
  - [及时清除不再需要的会话](#toc_17)
  - [使用同步代码块替代同步方法](#toc_18)
  - [将常量声明为static final，并以大写命名](#toc_19)
  - [程序运行过程中避免使用反射](#toc_20)
  - [使用数据库连接池和线程池](#toc_21)
  - [使用带缓冲的输入输出流进行IO操作](#toc_22)
  - [顺序插入和随机访问比较多的场景使用ArrayList，元素删除和中间插入比较多的场景使用LinkedList](#toc_23)
  - [公用的集合类中不使用的数据一定要及时remove掉](#toc_24)
  - [把一个基本数据类型转为字符串，基本数据类型.toString()是最快的方式, String.valueOf(数据)次之、数据+""最慢](#toc_25)
  - [使用最有效率的方式去遍历Map](#toc_26)
  - [对于ThreadLocal使用前或者使用后一定要先remove](#toc_27)
  - [以常量定义的方式替代魔鬼数字，魔鬼数字的存在将极大地降低代码可读性](#toc_28)
  - [推荐使用JDK7中新引入的Objects工具类来进行对象的equals比较，直接a.equals(b)，有空指针异常的风险](#toc_29)

------

#### 尽量指定类、方法的final修饰符

Java编译器会寻找机会内联所有的final方法，内联对于提升Java运行效率作用重大，此举能够使性能平均提高50%。

#### 尽量重用对象

出现字符串连接时使用StringBuilder/StringBuffer代替。由于Java虚拟机不仅要花时间生成对象，以后可能还需要花时间对这些对象进行垃圾回收和处理，因此，生成过多的对象将会给程序的性能带来很大的影响。

#### 尽可能使用局部变量

调用方法时传递的参数以及在调用中创建的临时变量都保存在栈中，速度较快，其他变量，如静态变量、实例变量等，都在堆中创建，速度较慢。另外，栈中创建的变量，随着方法的运行结束，这些内容就没了，不需要额外的垃圾回收。

#### 及时关闭流

Java编程过程中，进行数据库连接、I/O流操作时务必小心，在使用完毕后，及时关闭以释放资源。因为对这些大对象的操作会造成系统大的开销，稍有不慎，将会导致严重的后果。

#### 尽量减少对变量的重复计算

对方法的调用，即使方法中只有一句语句，也是有消耗的，包括创建栈帧、调用方法时保护现场、调用方法完毕时恢复现场等。

#### 循环内不要不断创建对象引用

#### 尽量采用懒加载的策略，即在需要的时候才创建

#### 慎用异常

异常对性能不利。抛出异常首先要创建一个新的对象，Throwable接口的构造函数调用名为fillInStackTrace()的本地同步方法，fillInStackTrace()方法检查堆栈，收集调用跟踪信息。只要有异常被抛出，Java虚拟机就必须调整调用堆栈，因为在处理过程中创建了一个新的对象。异常只能用于错误处理，不应该用来控制程序流程。

#### 如果能估计到待添加的内容长度，为底层以数组方式实现的集合、工具类指定初始长度

比如ArrayList、LinkedLlist、StringBuilder、StringBuffer、HashMap、HashSet等等

#### 当复制大量数据时，使用System.arraycopy()命令

#### 乘法和除法使用移位操作

#### 循环内不要不断创建对象引用

#### 基于效率和类型检查的考虑，应该尽可能使用array，无法确定数组大小时才使用ArrayList

#### 尽量使用HashMap、ArrayList、StringBuilder，除非线程安全需要，否则不推荐使用Hashtable、Vector、StringBuffer，后三者由于使用同步机制而导致了性能开销

#### 尽量在合适的场合使用单例

#### 尽量避免随意使用静态变量

当某个对象被定义为static的变量所引用，那么gc通常是不会回收这个对象所占有的堆内存的

#### 及时清除不再需要的会话

#### 使用同步代码块替代同步方法

#### 将常量声明为static final，并以大写命名

这样在编译期间就可以把这些内容放入常量池中，避免运行期间计算生成常量的值。另外，将常量的名字以大写命名也可以方便区分出常量与变量

#### 程序运行过程中避免使用反射

#### 使用数据库连接池和线程池

这两个池都是用于重用对象的，前者可以避免频繁地打开和关闭连接，后者可以避免频繁地创建和销毁线程

#### 使用带缓冲的输入输出流进行IO操作

带缓冲的输入输出流，即BufferedReader、BufferedWriter、BufferedInputStream、BufferedOutputStream，这可以极大地提升IO效率

#### 顺序插入和随机访问比较多的场景使用ArrayList，元素删除和中间插入比较多的场景使用LinkedList

#### 公用的集合类中不使用的数据一定要及时remove掉

#### 把一个基本数据类型转为字符串，基本数据类型.toString()是最快的方式, String.valueOf(数据)次之、数据+""最慢

#### 使用最有效率的方式去遍历Map

```plain
Set<Map.Entry<String,String>> entrySet = hm.entrySet();
Iterator<Map.Entry<String,String>> iter = entrySet.iterator();
while(iter.hasNext())
```

#### 对于ThreadLocal使用前或者使用后一定要先remove

#### 以常量定义的方式替代魔鬼数字，魔鬼数字的存在将极大地降低代码可读性

#### 推荐使用JDK7中新引入的Objects工具类来进行对象的equals比较，直接a.equals(b)，有空指针异常的风险

### 设计模式

- [设计模式](#toc_0)

- - [单例模式](#toc_1)
  - [代理模式](#toc_2)
  - [适配器模式](#toc_3)
  - [装饰者模式：动态给类加功能。](#toc_4)
  - [观察者模式](#toc_5)
  - [策略模式](#toc_6)
  - [外观模式](#toc_7)
  - [命令模式](#toc_8)
  - [创建者模式](#toc_9)
  - [抽象工厂模式](#toc_10)

#### 单例模式

- 懒汉式
- 饿汉式
- 双重校验锁
- 静态加载
- 内部类加载、枚举类加载。保证一个类仅有一个实例，并提供一个访问它的全局访问点。

#### 代理模式

- 动态代理
- 静态代理

什么时候使用动态代理。

#### 适配器模式

将一个类的接口转换成客户希望的另外一个接口。适配器模式使得原本由于接口不兼容而不能一起工作的那些类可以一起工作。

#### 装饰者模式：动态给类加功能。

#### 观察者模式

有时被称作发布/订阅模式，观察者模式定义了一种一对多的依赖关系，让多个观察者对象同时监听某一个主题对象。这个主题对象在状态发生变化时，会通知所有观察者对象，使它们能够自动更新自己。

#### 策略模式

定义一系列的算法,把它们一个个封装起来, 并且使它们可相互替换。

#### 外观模式

为子系统中的一组接口提供一个一致的界面，外观模式定义了一个高层接口，这个接口使得这一子系统更加容易使用。

#### 命令模式

将一个请求封装成一个对象，从而使您可以用不同的请求对客户进行参数化。

#### 创建者模式

将一个复杂的构建与其表示相分离，使得同样的构建过程可以创建不同的表示。

#### 抽象工厂模式

提供一个创建一系列相关或相互依赖对象的接口，而无需指定它们具体的类。

### java多线程

- [java多线程](#toc_0)

- - [如何评估一台机器多少线程比较合适？ 理论指导和压测手段？](#toc_1)
  - [ThreadLocal的作用， 副作用？](#toc_2)
  - [什么叫线程安全和非安全， 对我们编程有什么影响？](#toc_3)
  - [如何在高并发场景下，安全的创建一个单例模式](#toc_4)
  - [Java中如何实现多线程?](#toc_5)
  - [volatile的原理，作用，能代替锁么](#toc_6)
  - [Lock与Synchronized的区别](#toc_7)
  - [synchronized是java中的一个关键字，也就是说是Java语言内置的特性。那么为什么会出现Lock呢？](#toc_8)
  - [Synchronized有哪几种用法](#toc_9)
  - [解释以下名词：重排序，自旋锁，偏向锁，轻量级锁，可重入锁，公平锁，非公平锁，乐观锁，悲观锁](#toc_10)
  - [锁有哪几种？](#toc_11)
  - [为什么要使用线程池](#toc_12)
  - [Java中如何获取到线程dump文件](#toc_13)
  - [一个线程如果出现了运行时异常会怎么样](#toc_14)
  - [如何在两个线程之间共享数据（线程同步）](#toc_15)
  - [如何查找哪个线程使用CPU最长](#toc_16)
  - [什么是CAS什么是AQS](#toc_17)
  - [ConcurrentHashMap的并发度是什么](#toc_18)
  - [run()和start()方法区别](#toc_19)
  - [如何控制某个方法允许并发访问线程的个数？](#toc_20)
  - [多个线程同时读写，读线程的数量远远大于写线程，你认为应该如何解决并发的问题？你会选择加什么样的锁？](#toc_21)
  - [线程池内的线程如果全部忙，提交一个新的任务，会发生什什么？队列全部塞满了之后，还是忙，再提交会发生什么？](#toc_22)
  - [剖析Disruptor:为什么会这么快？](#toc_23)
  - [怎么中断一个线程？如何保证中断业务不影响？](#toc_24)
  - [怎么终止一个线程？如何优雅地终止线程？](#toc_25)
  - [怎么控制同一时间只有3个线程运行？](#toc_26)
  - [Jdk中排查多线程问题用什么命令？](#toc_27)
  - [Java中用到了什么线程调度算法？](#toc_28)
  - [Thread.sleep(0)的作用是什么？](#toc_29)
  - [sleep和wait的区别](#toc_30)
  - [Hashtable的size()方法为什么要做同步？](#toc_31)
  - [为什么wait/notify/notifyAll这些方法不在thread类里面？](#toc_32)
  - [Runnable接口和Callable接口的区别](#toc_33)
  - [CyclicBarrier和CountDownLatch的区别](#toc_34)
  - [Java中如何获取到线程dump文件](#toc_35)

#### 如何评估一台机器多少线程比较合适？ 理论指导和压测手段？

#### ThreadLocal的作用， 副作用？

#### 什么叫线程安全和非安全， 对我们编程有什么影响？

HashMap 和 ConcurrentHashMap的区别

#### 如何在高并发场景下，安全的创建一个单例模式

#### Java中如何实现多线程?

- 继承Thread类
- 实现Runnable接口
- 实现Callable接口通过FutureTask包装器来创建Thread线程
- 使用ExecutorService、Callable、Future实现有返回结果的多线程

如果想让线程池执行任务的话需要实现的Runnable接口或Callable接口。 Runnable接口或Callable接口实现类都可以被ThreadPoolExecutor或ScheduledThreadPoolExecutor执行。两者的区别在于 Runnable 接口不会返回结果但是 Callable 接口可以返回结果。

#### volatile的原理，作用，能代替锁么

1. volatile 关键字的作用 保证内存的可见性 防止指令重排. 即每次读取到volatile变量，一定是最新的数据
2. volatile 并不能保证线程安全性。而 synchronized 则可实现线程的安全性 

#### Lock与Synchronized的区别

1. 首先synchronized是java内置关键字，在jvm层面，Lock是个java类；
2. synchronized无法判断是否获取锁的状态，Lock可以判断是否获取到锁；
3. synchronized会自动释放锁(a 线程执行完同步代码会释放锁 ；b 线程执行过程中发生异常会释放锁)，Lock需在finally中手工释放锁（unlock()方法释放锁），否则容易造成线程死锁；
4. 用synchronized关键字的两个线程1和线程2，如果当前线程1获得锁，线程2线程等待。如果线程1阻塞，线程2则会一直等待下去，而Lock锁就不一定会等待下去，如果尝试获取不到锁，线程可以不用一直等待就结束了；
5. synchronized的锁可重入、不可中断、非公平，而Lock锁可重入、可判断、可公平（两者皆可）
6. Lock锁适合大量同步的代码的同步问题，synchronized锁适合代码少量的同步问题。

#### synchronized是java中的一个关键字，也就是说是Java语言内置的特性。那么为什么会出现Lock呢？

#### Synchronized有哪几种用法

#### 解释以下名词：重排序，自旋锁，偏向锁，轻量级锁，可重入锁，公平锁，非公平锁，乐观锁，悲观锁

#### 锁有哪几种？

- 公平锁/非公平锁

公平锁是指多个线程按照申请锁的顺序来获取锁; 非公平锁是指多个线程获取锁的顺序并不是按照申请锁的顺序,有可能，会造成优先级反转或者饥饿现象。

对于Java ReentrantLock而言，通过构造函数指定该锁是否是公平锁，默认是非公平锁。非公平锁的优点在于吞吐量比公平锁大。对于Synchronized而言，也是一种非公平锁。

- 可重入锁

可重入锁又名递归锁，是指在同一个线程在外层方法获取锁的时候，在进入内层方法会自动获取锁。

- 独享锁/共享锁

独享锁：一次只能被一个线程所访问

共享锁：线程可以被多个线程所持有。

ReadWriteLock 读锁是共享锁，写锁是独享锁。对于Java ReentrantLock而言，其是独享锁。对于Synchronized而言，当然是独享锁。

- 互斥锁/读写锁
- 乐观锁/悲观锁

乐观锁：对于一个数据的操作并发，是不会发生修改的。在更新数据的时候，会尝试采用更新，不断重入的方式，更新数据。

悲观锁：对于同一个数据的并发操作，是一定会发生修改的。因此对于同一个数据的并发操作，悲观锁采用加锁的形式。悲观锁认为，不加锁的操作一定会出问题，

- 分段锁

分段锁，其思想就是让锁的粒度变小。分段锁其实是一种锁的设计，并不是具体的一种锁，对于ConcurrentHashMap而言，其并发的实现就是通过分段锁的形式来实现高效的并发操作。

- 偏向锁/轻量级锁/重量级锁
  这三种锁是指锁的状态，并且是针对Synchronized,这三种锁的状态是通过对象监视器在对象头中的字段来表明的。

偏向锁是指一段同步代码一直被一个线程所访问，那么该线程会自动获取锁。降低获取锁的代价。在Java 5通过引入锁升级的机制来实现高效Synchronized。

轻量级锁 是指当锁是偏向锁的时候，被另一个线程所访问，偏向锁就会升级为轻量级锁，其他线程会通过自旋的形式尝试获取锁，不会阻塞，提高性能。

重量级锁是指当锁为轻量级锁的时候，另一个线程虽然是自旋，但自旋不会一直持续下去，当自旋一定次数的时候，还没有获取到锁，就会进入阻塞，该锁膨胀为重量级锁。重量级锁会让其他申请的线程进入阻塞，性能降低。

- 自旋锁

在Java中，自旋锁是指尝试获取锁的线程不会立即阻塞，而是采用循环的方式去尝试获取锁，这样的好处是减少线程上下文切换的消耗，缺点是循环会消耗CPU。

#### 为什么要使用线程池

避免频繁地创建和销毁线程，达到线程对象的重用。另外，使用线程池还可以灵活地控制并发的数目。

#### Java中如何获取到线程dump文件

1. 获取到线程的pid，可以通过使用jps命令，在Linux环境下还可以使用ps -ef | grep java
2. 通过使用jstack pid命令

#### 一个线程如果出现了运行时异常会怎么样

如果异常没捕获的话，线程就停止执行了。如果这个线程持有某个某个对象的监视器，那么这个对象监视器会被立即释放

#### 如何在两个线程之间共享数据（线程同步）

通过在线程之间共享对象就可以了，然后通过wait/notify/notifyAll、await/signal/signalAll进行唤起和等待

阻塞队列BlockingQueue就是为线程之间共享数据而设计的

#### 如何查找哪个线程使用CPU最长

1. 获取项目的pid，jps或者ps -ef | grep java
2. top -H -p pid，顺序不能改变

#### 什么是CAS什么是AQS

- CAS，全称为Compare and Swap，即比较-替换。

假设有三个操作数：内存值V、旧的预期值A、要修改的值B，当且仅当预期值A和内存值V相同时，才会将内存值修改为B并返回true，否则什么都不做并返回false。当然CAS一定要volatile变量配合，这样才能保证每次拿到的变量是主内存中最新的那个值，否则旧的预期值A对某条线程来说，永远是一个不会变的值A，只要某次CAS操作失败，永远都不可能成功。

- AQS是一个用来构建锁和同步器的框架，使用AQS能简单且高效地构造出应用广泛的大量的同步器。

如果说java.util.concurrent的基础是CAS的话，那么AQS就是整个Java并发包的核心了，ReentrantLock、CountDownLatch、Semaphore等等都用到了它。

AQS核心思想是，如果被请求的共享资源空闲，则将当前请求资源的线程设置为有效的工作线程，并且将共享资源设置为锁定状态。如果被请求的共享资源被占用，那么就需要一套线程阻塞等待以及被唤醒时锁分配的机制，这个机制AQS是用CLH队列锁实现的，即将暂时获取不到锁的线程加入到队列中。

AQS定义了对双向队列所有的操作，而只开放了tryLock和tryRelease方法给开发者使用，开发者可以根据自己的实现重写tryLock和tryRelease方法，以实现自己的并发功能。

#### ConcurrentHashMap的并发度是什么

ConcurrentHashMap的并发度就是segment的大小，默认为16，这意味着最多同时可以有16条线程操作ConcurrentHashMap

#### run()和start()方法区别

#### 如何控制某个方法允许并发访问线程的个数？

- 按并发控制，分布式场景
- 按时间控制

#### 多个线程同时读写，读线程的数量远远大于写线程，你认为应该如何解决并发的问题？你会选择加什么样的锁？

#### 线程池内的线程如果全部忙，提交一个新的任务，会发生什什么？队列全部塞满了之后，还是忙，再提交会发生什么？

#### 剖析Disruptor:为什么会这么快？

[剖析Disruptor:为什么会这么快？](http://ifeve.com/locks-are-bad/)

#### 怎么中断一个线程？如何保证中断业务不影响？

#### 怎么终止一个线程？如何优雅地终止线程？

- 终止线程的stop方法，通过stop方法可以很快速、方便地终止一个线程
- 优雅终止需要添加一个变量，判断这个变量在某个值的时候就退出循环，这时候每个循环为一个整合不被强行终止就不会影响单个业务的执行结果。 

![img](https://cdn.nlark.com/yuque/0/2019/png/406432/1565342631777-789483a5-56fb-41f6-84d7-fe342ef84812.png)￼

#### 怎么控制同一时间只有3个线程运行？

#### Jdk中排查多线程问题用什么命令？

#### Java中用到了什么线程调度算法？

#### Thread.sleep(0)的作用是什么？

#### sleep和wait的区别

- 使用上

sleep是Thread线程类的方法，而wait是Object顶级类的方法,

sleep可以在任何地方使用，而wait只能在同步方法或者同步块中使用

- CPU及资源锁释放

sleep,wait调用后都会暂停当前线程并让出cpu的执行时间，但不同的是sleep不会释放当前持有的对象的锁资源，到时间后会继续执行，而wait会放弃所有锁并需要notify/notifyAll后重新获取到对象锁资源后才能继续执行。

- 异常捕获

sleep需要捕获或者抛出异常，而wait/notify/notifyAll不需要

#### Hashtable的size()方法为什么要做同步？

#### 为什么wait/notify/notifyAll这些方法不在thread类里面？

#### Runnable接口和Callable接口的区别

#### CyclicBarrier和CountDownLatch的区别

#### Java中如何获取到线程dump文件

### Spring面试相关

- [Spring面试相关](#toc_0)

- - [简述 AOP 和 IOC 概念](#toc_1)
  - [你有没有⽤用过Spring的AOP? 是用来干嘛的? 大概会怎么使用？](#toc_2)
  - [BeanFactory和ApplicationContext有什么区别？](#toc_3)
  - [列举ApplicationContext的实现方式](#toc_4)
  - [Spring有几种配置方式？](#toc_5)
  - [请解释Spring Bean的生命周期？](#toc_6)
  - [哪些是重要的bean生命周期方法？](#toc_7)
  - [Spring Bean的作用域之间有什么区别？](#toc_8)
  - [Spring框架中的单例Beans是线程安全的么？](#toc_9)
  - [请举例说明如何在Spring中注入一个Java Collection？](#toc_10)
  - [说出 Spring MVC 常用注解](#toc_11)
  - [如何使用 SpringMVC 完成 JSON 操作](#toc_12)
  - [如果⼀一个接口有2个不同的实现, 那么怎么来Autowire一个指定的实现？](#toc_13)
  - [BeanFactory – BeanFactory 实现举例](#toc_14)
  - [Spring支持的事务管理类型](#toc_15)
  - [AOP](#toc_16)
  - [什么是织入。什么是织入应用的不同点？](#toc_17)
  - [spring url request如何和controller映射起来](#toc_18)
  - [spring mvc rest api拦截方法](#toc_19)

#### 简述 AOP 和 IOC 概念

#### 你有没有⽤用过Spring的AOP? 是用来干嘛的? 大概会怎么使用？

#### BeanFactory和ApplicationContext有什么区别？

- BeanFactory 可以理解为含有bean集合的工厂类。BeanFactory 包含了种bean的定义，以便在接收到客户端请求时将对应的bean实例化。
- 从表面上看，application context如同bean factory一样具有bean定义、bean关联关系的设置，根据请求分发bean的功能。但applicationcontext在此基础上还提供了其他的功能。

1. 1. 提供了支持国际化的文本消息
   2. 统一的资源文件读取方式
   3. 在监听器中注册的bean的事件

#### 列举ApplicationContext的实现方式

以下是三种较常见的 ApplicationContext 实现方式：

- ClassPathXmlApplicationContext
  \> 从classpath的XML配置文件中读取上下文，并生成上下文定义。应用程序上下文从程序环境变量中

```plain
ApplicationContext context = new ClassPathXmlApplicationContext("bean.xml");
```

- FileSystemXmlApplicationContext
  \> 由文件系统中的XML配置文件读取上下文。

```plain
ApplicationContext context = new FileSystemXmlApplicationContext("bean.xml");
```

- XmlWebApplicationContext：由Web应用的XML文件读取上下文。
- AnnotationConfigApplicationContext(基于Java配置启动容器)

#### Spring有几种配置方式？

- 基于XML的配置

```plain
<beans>    
    <bean id="myService" class="com.somnus.services.MyServiceImpl"/>    
</beans>
```

- 基于注解的配置

1. 1. @Required：该注解应用于设值方法。
   2. @Autowired：该注解应用于有值设值方法、非设值方法、构造方法和变量。
   3. @Qualifier：该注解和@Autowired注解搭配使用，用于消除特定bean自动装配的歧义。
   4. JSR-250 Annotations：Spring支持基于JSR-250 注解的以下注解 @Resource、@PostConstruct 和 @PreDestroy。

```plain
<beans>    
   <context:annotation-config/>    
   <!-- bean definitions go here -->    
</beans>
```

- 基于Java的配置

1. 1. @Configuration注解
   2. @Bean注解
   3. @ComponentScan

#### 请解释Spring Bean的生命周期？

Spring框架提供了以下四种方式来管理bean的生命周期事件：

1. Spring容器 从XML 文件中读取bean的定义，并实例化bean。
2. Spring根据bean的定义填充所有的属性。
3. 如果bean实现了BeanNameAware 接口，Spring 传递bean 的ID 到 setBeanName方法。
4. 如果Bean 实现了 BeanFactoryAware 接口， Spring传递beanfactory 给setBeanFactory 方法。
5. 如果有任何与bean相关联的BeanPostProcessors，Spring会在postProcesserBeforeInitialization()方法内调用它们。
6. 如果bean实现IntializingBean了，调用它的afterPropertySet方法，如果bean声明了初始化方法，调用此初始化方法。
7. 如果有BeanPostProcessors 和bean 关联，这些bean的postProcessAfterInitialization() 方法将被调用。
8. 如果bean实现了 DisposableBean，它将调用destroy()方法。

#### 哪些是重要的bean生命周期方法？

*. InitializingBean和DisposableBean回调接口

*. 针对特殊行为的其他Aware接口

*. Bean配置文件中的Custom init()方法和destroy()方法

*. @PostConstruct和@PreDestroy注解方式

#### Spring Bean的作用域之间有什么区别？

1. singleton：这种bean范围是默认的，这种范围确保不管接受到多少个请求，每个容器中只有一个bean的实例，单例的模式由bean factory自身来维护。
2. prototype：原形范围与单例范围相反，为每一个bean请求提供一个实例。
3. request：在请求bean范围内会每一个来自客户端的网络请求创建一个实例，在请求完成以后，bean会失效并被垃圾回收器回收。
4. session：与请求范围类似，确保每个session中有一个bean的实例，在session过期后，bean会随之失效。
5. global- session：global-session和Portlet应用相关。当你的应用部署在Portlet容器中工作时，它包含很多portlet。如果 你想要声明让所有的portlet共用全局的存储变量的话，那么这全局变量需要存储在global-session中。

#### Spring框架中的单例Beans是线程安全的么？

1. 关于单例bean的线程安全和并发问题需要开发者自行去搞定。
2. 但实际上，大部分的Spring bean并没有可变的状态(比如Serview类和DAO类).

#### 请举例说明如何在Spring中注入一个Java Collection？

1. <list> : 该标签用来装配可重复的list值。

2. <set> : 该标签用来装配没有重复的set值。

3. <map>: 该标签可用来注入键和值可以为任何类型的键值对。

4. <props> : 该标签支持注入键和值都是字符串类型的键值对。

#### 说出 Spring MVC 常用注解

1. @RequestMapping 
2. @PathVariable 
3. @RequestParam 
4. @RequestBoy 
5. @ResponseBody
6. @RestController (作用等于 @ResponseBody加在类上+@Controller)

#### 如何使用 SpringMVC 完成 JSON 操作

1. 配置 MappingJacksonHttpMessageConverter 
2. 使用 @RequestBody 注解或 ResponseEntity 作为返回值

#### 如果⼀一个接口有2个不同的实现, 那么怎么来Autowire一个指定的实现？

#### BeanFactory – BeanFactory 实现举例

#### Spring支持的事务管理类型

- 编程式事务管理：这意味你通过编程的方式管理事务，给你带来极大的灵活性，但是难维护。
- 声明式事务管理：这意味着你可以将业务代码和事务管理分离，你只需用注解和XML配置来管理事务。

#### AOP

- Aspect 切面
- 关注点 pointcut
- 连接点
- 通知, Spring切面可以应用五种类型的通知：

1. 1. before：前置通知，在一个方法执行前被调用
   2. after：在方法执行之后调用的通知，无论方法执行是否成功
   3. after-returning：仅当方法成功完成后执行的通知
   4. after-throwing：在方法抛出异常退出时执行的通知
   5. around：在方法执行之前和之后调用的通知

#### 什么是织入。什么是织入应用的不同点？

织入是将切面和到其他应用类型或对象连接或创建一个被通知对象的过程。

织入可以在编译时，加载时，或运行时完成。

#### spring url request如何和controller映射起来

[映射](https://www.jianshu.com/p/c92197e1c892)

当DispatcherServlet接受到客户端的请求后，SpringMVC 通过 HandlerMapping 找到请求的Controller。

HandlerMapping 在这里起到路由的作用，负责找到请求的Controller。

- org.springframework.web.servlet.handler.SimpleUrlHandlerMapping
  通过配置请求路径和Controller映射建立关系，找到相应的Controller
- org.springframework.web.servlet.mvc.support.ControllerClassNameHandlerMapping
  通过 Controller 的类名找到请求的Controller。
- org.springframework.web.servlet.handler.BeanNameUrlHandlerMapping
  通过定义的 beanName 进行查找要请求的Controller
- org.springframework.web.servlet.mvc.annotation.DefaultAnnotationHandlerMapping
  通过注解 @RequestMapping("/userlist") 来查找对应的Controller。

#### spring mvc rest api拦截方法

[RESTFul api拦截 ](https://blog.csdn.net/sky_jiangcheng/article/details/82631791)

- 过滤器（Filter）：可以拿到原始的Http请求和响应的信息，只能获得其请求和响应携带的参数，但是却拿不到真正处理请求的控制器和方法的信息。
- 拦截器（Interceptor）：既可以拿到原始的Http请求和响应的信息，也能拿到真正处理请求的方法信息，但是拿不到方法被调用时，真正调用的参数的值。
- 切片 （Aspect） : 可以拿到方法被调用时真正传进来的参数的值，但是却拿不到原始的Http请求和响应。

![img](https://cdn.nlark.com/yuque/0/2019/png/406432/1565342726317-85a6e8b5-a6da-433a-92d0-8b6d5d7a46c9.png)￼

### 数据库相关

- [数据库相关](#toc_0)

- - [索引是什么？有什么作用以及优缺点？](#toc_1)
  - [什么是事务？](#toc_2)
  - [Spring事务的7种传播级别](#toc_3)
  - [什么是嵌套事务?](#toc_4)
  - [Spring事务的注解配置](#toc_5)
  - [在同一个类中一个普通方法调用另一个有@Transcational注解的方法时，Spring事务管理还启作用吗？](#toc_6)
  - [数据库的乐观锁和悲观锁是什么？](#toc_7)
  - [说一说drop、delete与truncate的区别](#toc_8)
  - [什么是内联接、左外联接、右外联接？](#toc_9)
  - [order by, group by, having的作用](#toc_10)
  - [数据隔离级别](#toc_11)
  - [Mybatis动态sql是做什么的？都有哪些动态sql？能简述一下动态sql的执行原理不？](#toc_12)
  - [#{}和${}的区别是什么？](#toc_13)
  - [MyBatis与Hibernate有哪些不同？](#toc_14)
  - [MyBatis的好处是什么？](#toc_15)
  - [简述Mybatis的Xml映射文件和Mybatis内部数据结构之间的映射关系？](#toc_16)
  - [什么是MyBatis的接口绑定,有什么好处？](#toc_17)
  - [什么情况下用注解绑定,什么情况下用xml绑定？](#toc_18)
  - [当实体类中的属性名和表中的字段名不一样，如果将查询的结果封装到指定pojo？](#toc_19)
  - [Mybatis的Xml映射文件中，不同的Xml映射文件，id是否可以重复？](#toc_20)
  - [Mybatis中如何执行批处理？](#toc_21)
  - [在mapper中如何传递多个参数？](#toc_22)
  - [resultType resultMap的区别？](#toc_23)
  - [如果有很多数据插入MYSQL 你会选择什么方式?](#toc_24)
  - [索引具体采用的哪种数据结构呢？](#toc_25)
  - [InnoDB使用的B+ 树的索引模型，你知道为什么采用B+ 树吗？这和Hash索引比较起来有什么优缺点吗？](#toc_26)
  - [B+ Tree的叶子节点都可以存哪些东西吗？](#toc_27)
  - [MySQL的回表查询，是什么意思？](#toc_28)
  - [覆盖索引是什么意思？](#toc_29)
  - [在创建索引的时候都会考虑哪些因素呢？](#toc_30)
  - [有时候创建了索引，但执行的时候并没有使用这个索引呢？](#toc_31)
  - [事务四大特性，以及事务的二段提交机制？](#toc_32)
  - [数据库万级变成亿级，怎么处理？](#toc_33)
  - [MySQL 性能优化策略](#toc_34)
  - [MySQL的基本操作 主从数据库一致性维护](#toc_35)
  - [mysql的优化策略有哪些](#toc_36)
  - [mysql索引的实现 B+树的实现原理](#toc_37)
  - [什么情况索引不会命中，会造成全表扫描](#toc_38)

#### 索引是什么？有什么作用以及优缺点？

索引是对数据库表中一或多个列的值进行排序的结构, 索引就是加快检索表中数据的方法。

#### 什么是事务？

事务（Transaction）是并发控制的基本单位。所谓的事务，它是一个操作序列，这些操作要么都执行，要么都不执行，它是一个不可分割的工作单位。事务是数据库维护数据一致性的单位，在每个事务结束时，都能保持数据一致性。

#### Spring事务的7种传播级别

- PROPAGATION_REQUIRED ，默认的spring事务传播级别

使用该级别的特点是，如果上下文中已经存在事务，那么就加入到事务中执行，如果当前上下文中不存在事务，则新建事务执行。

- PROPAGATION_SUPPORTS 

该传播级别的特点是，如果上下文存在事务，则支持事务加入事务，如果没有事务，则使用非事务的方式执行。

- PROPAGATION_MANDATORY

该级别的事务要求上下文中必须要存在事务，否则就会抛出异常！

- PROPAGATION_REQUIRES_NEW

该传播级别的特点是，每次都会新建一个事务，并且同时将上下文中的事务挂起，执行当前新建事务完成以后，上下文事务恢复再执行

这是一个很有用的传播级别，举一个应用场景：现在有一个发送100个红包的操作，在发送之前，要做一些系统的初始化、验证、数据记录操作，然后发送100封红包，然后再记录发送日志，发送日志要求100%的准确，如果日志不准确，那么整个父事务逻辑需要回滚。

怎么处理整个业务需求呢？就是通过这个PROPAGATION_REQUIRES_NEW 级别的事务传播控制就可以完成。发送红包的子事务不会直接影响到父事务的提交和回滚。

- PROPAGATION_NOT_SUPPORTED

当前级别的特点就是上下文中存在事务，则挂起事务，执行当前逻辑，结束后恢复上下文的事务, 可以帮助你将事务极可能的缩小。

- PROPAGATION_NEVER

该事务更严格，上面一个事务传播级别只是不支持而已，有事务就挂起，而PROPAGATION_NEVER传播级别要求上下文中不能存在事务，一旦有事务，就抛出runtime异常，强制停止执行！

- PROPAGATION_NESTED

该传播级别特征是，如果上下文中存在事务，则嵌套事务执行，如果不存在事务，则新建事务。

#### 什么是嵌套事务?

嵌套是子事务套在父事务中执行，子事务是父事务的一部分，在进入子事务之前，父事务建立一个回滚点，叫save point，然后执行子事务，这个子事务的执行也算是父事务的一部分，然后子事务执行结束，父事务继续执行。重点就在于那个save point：

- 如果子事务回滚，会发生什么？

父事务会回滚到进入子事务前建立的save point，然后尝试其他的事务或者其他的业务逻辑，父事务之前的操作不会受到影响，更不会自动回滚。

- 如果父事务回滚，会发生什么？

父事务回滚，子事务也会跟着回滚！为什么呢，因为父事务结束之前，子事务是不会提交的，我们说子事务是父事务的一部分。

#### Spring事务的注解配置

1. 把一个DataSource（如DruidDataSource）作为一个@Bean注册到Spring容器中，配置好事务性资源。
2. 把一个@EnableTransactionManagement注解放到一个@Configuration类上，配置好事务管理器，并启用事务管理。
3. 把一个@Transactional注解放到类上或方法上，可以设置注解的属性，表明该方法按配置好的属性参与到事务中。

- 如何配置回滚异常

使用@Transactional注解的rollbackFor/rollbackForClassName属性，可以精确配置导致回滚的异常类型，包括checked exceptions。

noRollbackFor/noRollbackForClassName属性，可以配置不导致回滚的异常类型，当遇到这样的未处理异常时，照样提交相关事务。

- 事务注解在类/方法上

@Transactional注解既可以标注在类上，也可以标注在方法上。当在类上时，默认应用到类里的所有方法。如果此时方法上也标注了，则方法上的优先级高。

- 事务注解在类上的继承性

@Transactional注解的作用可以传播到子类，即如果父类标了子类就不用标了。但倒过来就不行了。

- 事务注解在接口/类上

@Transactional注解可以用在接口上，也可以在类上。在接口上时，必须使用基于接口的代理才行，即JDK动态代理。

事实是Java的注解不能从接口继承，如果你使用基于类的代理，即CGLIB，或基于织入方面，即AspectJ，事务设置不会被代理和织入基础设施认出来，目标对象不会被包装到一个事务代理中。

Spring团队建议注解标注在类上而非接口上。 

#### 在同一个类中一个普通方法调用另一个有@Transcational注解的方法时，Spring事务管理还启作用吗？

答案是不会起作用的。此处的this指向目标对象，因此调用this.b()将不会执行b事务切面，即不会执行事务增强

#### 数据库的乐观锁和悲观锁是什么？

乐观并发控制(乐观锁)和悲观并发控制（悲观锁）是并发控制主要采用的技术手段。

- 悲观锁：假定会发生并发冲突，屏蔽一切可能违反数据完整性的操作
- 乐观锁：假设不会发生并发冲突，只在提交操作时检查是否违反数据完整性。

#### 说一说drop、delete与truncate的区别

1. 速度,一般来说: drop> truncate >delete 
2. delete和truncate只删除表的数据不删除表的结构
3. delete语句是dml,这个操作会放到rollback segement中,事务提交之后才生效

#### 什么是内联接、左外联接、右外联接？

#### order by, group by, having的作用

#### 数据隔离级别

- Serializable 

最严格的级别，事务串行执行，资源消耗最大

- REPEATABLE READ 

保证一个事务不会修改已经由另一个事务读取但未提交（回滚）的数据。避免了“脏读取”和“不可重复读取”的情况，但是带来了更多的性能损失。

- READ COMMITTED

大多数主流数据库的默认事务等级，保证了一个事务不会读到另一个并行事务已修改但未提交的数据，避免了“脏读取”。该级别适用于大多数系统。

- Read Uncommitted

保证了读取过程中不会读取到非法数据。

|                  | 脏读 | 不可重复读 | 幻读 |
| ---------------- | ---- | ---------- | ---- |
| Serializable     | 不会 | 不会       | 不会 |
| REPEATABLE READ  | 不会 | 不会       | 会   |
| READ COMMITTED   | 不会 | 会         | 会   |
| Read Uncommitted | 会   | 会         | 会   |

#### Mybatis动态sql是做什么的？都有哪些动态sql？能简述一下动态sql的执行原理不？

- Mybatis动态sql可以让我们在Xml映射文件内，以标签的形式编写动态sql，完成逻辑判断和动态拼接sql的功能。
- Mybatis提供了9种动态sql标签：trim|where|set|foreach|if|choose|when|otherwise|bind。
- 其执行原理为，使用OGNL从sql参数对象中计算表达式的值，根据表达式的值动态拼接sql，以此来完成动态sql的功能。

#### #{}和${}的区别是什么？

- \#{}是预编译处理，${}是字符串替换。
- Mybatis在处理#{}时，会将sql中的#{}替换为?号，调用PreparedStatement的set方法来赋值；
- Mybatis在处理时，就是把时，就是把{}替换成变量的值。
- 使用#{}可以有效的防止SQL注入，提高系统安全性。

#### MyBatis与Hibernate有哪些不同？

#### MyBatis的好处是什么？

#### 简述Mybatis的Xml映射文件和Mybatis内部数据结构之间的映射关系？

Mybatis将所有Xml配置信息都封装到All-In-One重量级对象Configuration内部。

1. 在Xml映射文件中，标签会被解析为ParameterMap对象，其每个子元素会被解析为ParameterMapping对象。
2. 标签会被解析为ResultMap对象，其每个子元素会被解析为ResultMapping对象。
3. 每一个<select>、<insert>、<update>、<delete>标签均会被解析为MappedStatement对象，标签内的sql会被解析为BoundSql对象。

#### 什么是MyBatis的接口绑定,有什么好处？

#### 什么情况下用注解绑定,什么情况下用xml绑定？

#### 当实体类中的属性名和表中的字段名不一样，如果将查询的结果封装到指定pojo？

- 通过在查询的sql语句中定义字段名的别名。
- 通过<resultMap>来映射字段名和实体类属性名的一一对应的关系。

#### Mybatis的Xml映射文件中，不同的Xml映射文件，id是否可以重复？

不同的Xml映射文件，如果配置了namespace，那么id可以重复；如果没有配置namespace，那么id不能重复

#### Mybatis中如何执行批处理？

使用BatchExecutor完成批处理。

#### 在mapper中如何传递多个参数？

- 直接在方法中传递参数，xml文件用#{0} #{1}来获取
- 使用 @param 注解:这样可以直接在xml文件中通过#{name}来获取

#### resultType resultMap的区别？

1. 类的名字和数据库相同时，可以直接设置resultType参数为Pojo类
2. 若不同，需要设置resultMap 将结果名字和Pojo名字进行转换

#### 如果有很多数据插入MYSQL 你会选择什么方式?

#### 索引具体采用的哪种数据结构呢？

MySQL主要有两种结构：Hash索引和B+ Tree索引； InnoDB引擎，默认的是B+树。

#### InnoDB使用的B+ 树的索引模型，你知道为什么采用B+ 树吗？这和Hash索引比较起来有什么优缺点吗？

B+ 树是一种多路平衡查询树，B+Tree索引和Hash索引区别？

- 哈希索引适合等值查询，但是无法进行范围查询；
- 哈希索引没办法利用索引完成排序 ；
- 哈希索引不支持多列联合索引的最左匹配规则；
- 如果有大量重复键值的情况下，哈希索引的效率会很低，因为存在哈希碰撞问题。

#### B+ Tree的叶子节点都可以存哪些东西吗？

- InnoDB的B+ Tree可能存储的是整行数据，也有可能是主键的值。
- InnoDB 里，索引B+ Tree的叶子节点存储了整行数据的是主键索引，也被称之为聚簇索引。而索引B+ Tree的叶子节点存储了主键的值的是非主键索引，也被称之为非聚簇索引。
- 聚集索引,表中存储的数据按照索引的顺序存储,检索效率比普通索引高,但对数据新增/修改/删除的影响比较大 
- 非聚集索引,不影响表中的数据存储顺序,检索效率比聚集索引低,对数据新增/修改/删除的影响很小

[聚簇索引与非聚簇索引的区别](https://www.cnblogs.com/qlqwjy/p/7770580.html)

#### MySQL的回表查询，是什么意思？

- MySQL中的回表查询是二级索引无法直接查询所有列的数据，通过二级索引查询到聚簇索引后，再查询到想要的数据，这种通过二级索引查询出来的过程，就叫做回表。
  这样理解对吗？
- 如果explain查看执行计划，在使用了索引，且Extra是Using where的情况下，表示回表查询数据。

#### 覆盖索引是什么意思？

- 覆盖索引（covering index）指一个查询语句的执行只用从索引中就能够取得，不必从数据表中读取。也可以称之为实现了索引覆盖。
- 当一条查询语句符合覆盖索引条件时，MySQL只需要通过索引就可以返回查询所需要的数据，这样避免了查到索引后再返回表操作，减少I/O提高效率。

如，表covering_index_sample中有一个普通索引 idx_key1_key2(key1,key2)。

当我们通过SQL语句：select key2 from covering_index_sample where key1 = 'keytest';的时候，就可以通过覆盖索引查询，无需回表。

#### 在创建索引的时候都会考虑哪些因素呢？

- 字段区分度
- 联合索引（最左前缀匹配）

#### 有时候创建了索引，但执行的时候并没有使用这个索引呢？

一条SQL语句的查询，可以有不同的执行方案，至于最终选择哪种方案，需要通过优化器进行选择，选择执行成本最低的方案。优化过程大致如下：

- 根据搜索条件，找出所有可能使用的索引；
- 计算全表扫描的代价；
- 计算使用不同索引执行查询的代价；
- 对比各种执行方案的代价，找出成本最低的那一个。

#### 事务四大特性，以及事务的二段提交机制？

#### 数据库万级变成亿级，怎么处理？

#### MySQL 性能优化策略

- 为查询缓存优化你的查询， 像 NOW() 和 RAND() 或是其它的诸如此类的 SQL 函数都不会开启查询缓存，因为这些函数的返回是会不定的易变的
- 当只要一行数据时使用 LIMIT 1
- 为搜索字段建索引
- 在 Join 表的时候使用相同类型的字段，并将其索引
- 千万不要 ORDER BY RAND()
- 避 免 SELECT *
- 使用 ENUM 而不是 VARCHAR

ENUM 类型是非常快和紧凑的。在实际上，其保存的是 TINYINT，但其外表上显示为字符串。这样一来，用这个字段来做一些选项列表变得相当的完美。

- 尽可能的使用 NOT NULL定义
- Prepared Statements 
- 把 IP 地址存成 UNSIGNED INT

只需要 4 个字节

尤其是当你需要使用这样的 WHERE 条件：IP between ip1 and ip2

- 固定长度的表会更快

如果表中的所有字段都是“固定长度”的，整个表会被认为是 “static” 或 “fixed-length”

- 垂直分割

样可以降低表的复杂度和字段的数目，从而达到优化的目的。

- 拆分大的 DELETE 或 INSERT 语句
- 越小的列会越快

#### MySQL的基本操作 主从数据库一致性维护

#### mysql的优化策略有哪些

#### mysql索引的实现 B+树的实现原理

#### 什么情况索引不会命中，会造成全表扫描

### zookeeper

- [zookeeper](#toc_0)

- - [数据存储](#toc_1)
  - [Znode节点又根据节点的生命周期与类型分为4种节点](#toc_2)
  - [监听机制](#toc_3)
  - [监听机制的步骤](#toc_4)
  - [节点常见的事件通知](#toc_5)
  - [应用场景](#toc_6)

- - - [注册中心](#toc_7)

- - - - [ 和Eureka相比，有什么优劣势](#toc_8)

- - - [分布式锁](#toc_9)

- - - - [redis和db也能创建分布式锁，那有什么异同呢？](#toc_10)

- - - [集群管理与master选举](#toc_11)
    - [负载均衡](#toc_12)
    - [命名服务(Naming Service)](#toc_13)
    - [分布式通知/协调](#toc_14)
    - [简单场景的分布式队列](#toc_15)
    - [配置管理](#toc_16)

- - [paxos是什么？](#toc_17)
  - [什么是Lease机制？](#toc_18)
  - [如何理解选主算法？](#toc_19)

------

#### 数据存储

zookeeper提供了类似Linux文件系统一样的数据结构。每一个节点对应一个Znode节点，每一个Znode节点都可以存储1MB（默认）的数据。

![img](https://cdn.nlark.com/yuque/0/2019/png/406432/1565343352063-9c564a2b-d942-4f5a-b83e-a81eb7f80fdf.png)

- Znode:包含ACL权限控制、修改/访问时间、最后一次操作的事务Id(zxid)等等
- 所有数据存储在内存中，在内存中维护这么一颗树。
- 每次对Znode节点修改都是保证顺序和原子性的操作。写操作是原子性操作。

**举个例子，在注册中心中，可以通过路径"/fsof/服务名1/providers"找到"服务1"的所有提供者。**

#### Znode节点又根据节点的生命周期与类型分为4种节点

![img](https://cdn.nlark.com/yuque/0/2019/png/406432/1565343362738-5de10c22-d698-43c8-a586-3babd5e5dd64.png)

- 生命周期：当客户端会话结束的时候，是否清理掉这个会话创建的节点。持久-不清理，临时-清理。
- 类型：每一个会话，创建单独的节点（例子：正常节点：rudytan,顺序编号节点：rudytan001,rudytan002等等）

#### 监听机制

zookeeper除了提供对Znode节点的处理能力，还提供了对节点的变更进行监听通知的能力。

![img](https://cdn.nlark.com/yuque/0/2019/png/406432/1565343374938-cbdcc844-1193-4400-9cce-a425785aa9f6.png)

#### 监听机制的步骤

- 任何session(session1,session2)都可以对自己感兴趣的znode监听。
- 当znode通过session1对节点进行了修改。
- session1,session2都会收到znode的变更事件通知。

#### 节点常见的事件通知

- session建立成功事件
- 节点添加
- 节点删除
- 节点变更
- 子节点列表变化

#### 应用场景

[ZooKeeper典型应用场景一览](https://www.cnblogs.com/tommyli/p/3766189.html)

[zookeeper的实际运用场景、特点](https://blog.csdn.net/qq_35216516/article/details/80529321)

#### 注册中心

![img](https://cdn.nlark.com/yuque/0/2019/png/406432/1565343386868-82b0486e-4e7d-4f6a-87ce-65890b94e0bd.png)

- 依赖于临时节点
- 消费者启动的时候，会先去注册中心中全量拉取服务的注册列表。
- 当某个服务节点有变化的时候，通过监听机制做数据更新。
- zookeeper挂了，不影响消费者的服务调用

####  和Eureka相比，有什么优劣势

![img](https://cdn.nlark.com/yuque/0/2019/png/406432/1565343399204-2dfcd3cb-55c7-406a-8395-5b6f89892783.png)

通过上面的架构图，可以发现Eureka不同于zk中的节点，Eureka中的节点每一个节点对等。是个AP系统，而不是zk的CP系统。在注册中心的应用场景下，相对于与强数据一致性，更加关心可用性。

#### 分布式锁

[ZooKeeper典型应用场景：分布式锁](https://baijiahao.baidu.com/s?id=1610572906386264645&wfr=spider&for=pc)

![img](https://cdn.nlark.com/yuque/0/2019/png/406432/1565343408553-c1e70315-fc11-4d56-b405-336450c3d6f2.png)

- 依赖于临时顺序节点
- 判断当前client的顺序号是否是最小的，如果是获取到锁。
- 没有获取到锁的节点监听最小节点的删除事件（比如lock_key_001）
- 锁释放，最小节点删除，剩余节点重新开始获取锁。
- 重复步骤二到四

#### redis和db也能创建分布式锁，那有什么异同呢？

- 从理解的难易程度角度（从低到高）
  数据库 > 缓存（Redis） > Zookeeper
- 从实现的复杂性角度（从低到高）
  Zookeeper >= 缓存（Redis） > 数据库
- 从性能角度（从高到低）
  缓存（Redis） > Zookeeper >= 数据库
- 从可靠性角度（从高到低）
  Zookeeper > 缓存（Redis） > 数据库

#### 集群管理与master选举

![img](https://cdn.nlark.com/yuque/0/2019/png/406432/1565343419152-51d0999d-2165-49ae-bcfb-72b52e143676.png)

- 依赖于临时节点
- zookeeper保证无法重复创建一个已存在的数据节点，创建成功的client为master。
- 非master，在已经创建的节点上注册节点删除事件监听。
- 当master挂掉后，其他集群节点收到节点删除事件，进行重新选举
- 重复步骤二到四

#### 负载均衡

#### 命名服务(Naming Service)

#### 分布式通知/协调

#### 简单场景的分布式队列

#### 配置管理

------

#### paxos是什么？

#### 什么是Lease机制？

#### 如何理解选主算法？

### 消息MQ

- [消息MQ](#toc_0)

- - [什么是消息中间件](#toc_1)

- - - [谈谈消息中间件 rocketmq,kafka,activemq,rabbitmq从架构设计，再到实现，以及应用场景区别？](#toc_2)

- - [什么是JMS](#toc_3)

- - - [JMS定义五种不同的消息格式，其中（1）、（2）用的比较多](#toc_4)
    - [JMS的消息传递类型](#toc_5)

- - [kafka](#toc_6)

- - - [Kafka 消息是采用 Pull 模式，还是 Push 模式？](#toc_7)
    - [Kafka consumer 是否可以消费指定分区消息？](#toc_8)
    - [Kafka 与传统消息系统之间区别](#toc_9)
    - [Kafka将以下消息保存至Zookeeper中](#toc_10)
    - [副本同步队列ISR(in-sync replicas)](#toc_11)

------

#### 什么是消息中间件

#### 谈谈消息中间件 rocketmq,kafka,activemq,rabbitmq从架构设计，再到实现，以及应用场景区别？

#### 什么是JMS

JMS（Java Messaging Service）是Java平台上有关面向消息中间件的技术规范，它便于消息系统中的Java应用程序进行消息交换,并且通过提供标准的产生、发送、接收消息的接口简化企业应用的开发。

#### JMS定义五种不同的消息格式，其中（1）、（2）用的比较多

- TextMessage,一个字符串对象
- MapMessage一套键值对
- ObjectMessage一个序列化的Java对象
- ByteMessage一个字节的数据流
- StreamMessageJava原始值的数据流

#### JMS的消息传递类型

- 一种是点对点，消息生产者与消息消费者一一对应
  ![img](https://cdn.nlark.com/yuque/0/2019/png/406432/1565343098352-92159ac2-8d70-4710-a87b-c26809852c69.png)
- 一种是发布/订阅模式，消费者订阅后，生产者产生一条消息可能会有多个消费者接收
  ![img](https://cdn.nlark.com/yuque/0/2019/png/406432/1565343107755-fca2a24d-f98c-4f5f-afdc-e57d5ae48e64.png)

#### kafka

#### Kafka 消息是采用 Pull 模式，还是 Push 模式？

Kafka 遵循了一种大部分消息系统共同的传统的设计：producer 将消息推送到 broker，consumer 从 broker 拉取消息

#### Kafka consumer 是否可以消费指定分区消息？

Kafaconsumer 消费消息时，向 broker 发出"fetch"请求去消费特定分区的消息，consumer 指定消息在日志中的偏移量（offset），就可以消费从这个位置开始的消息，customer 拥有了 offset 的控制权，可以向后回滚去重新消费之前的消息。

#### Kafka 与传统消息系统之间区别

- Kafka 持久化日志，这些日志可以被重复读取和无限期保留
- Kafka 是一个分布式系统：它以集群的方式运行，可以灵活伸缩，在内部通过复制数据提升容错能力和高可用性
- Kafka 支持实时的流式处理

#### Kafka将以下消息保存至Zookeeper中

- 消费者组的每个分区的偏移量，不过后来Kafka将其保存至内部主题__consumer_offsets中
- 访问权限列表
- 生产者和消费者速率限定额度
- 分区leader信息和它们的健康状态

![img](https://cdn.nlark.com/yuque/0/2019/png/406432/1565343143890-8fbde426-be29-4f98-8036-98123d62b925.png)

- Controller控制器的作用
  控制器负责决定集群如何做出反应并指示节点做某事，它是功能不能过于复杂的Broker节点，最主要的职责是负责节点下线和重新加入时重平衡和分配新的分区leader

#### 副本同步队列ISR(in-sync replicas)

副本同步队列ISR(in-sync replicas)，它是由leader维护的，follower从leader同步数据是有延迟的，任意一个超过阈值都会被剔除出ISR列表, 存入OSR(Outof-Sync Replicas)列表中，新加入的follower也会先存放在OSR中

一个follower想被选举成leader，它必须在ISR队列中才有资格,不过，在没有同步副本存在并且已有leader都下线的边缘情况下，可以选择可用性而不是一致性

ISR列表维护标准如下：

- 它在过去的X秒内有完整同步leader消息，通过replica.lag.time.max.ms配置约定
- 它在过去的X秒内向Zookeeper发送了一个心跳，通过zookeeper.session.timeout.ms配置约定

### Redis

- [Redis](#toc_0)

- - [介绍下redis](#toc_1)
  - [Redis的全称是什么？](#toc_2)
  - [缓存穿透可以介绍一下么？你认为应该如何解决这个问题?](#toc_3)
  - [怎么理解强一致性、单调一致性和最终一致性？](#toc_4)
  - [为什么缓存更新策略是先更新数据库后删除缓存](#toc_5)
  - [你是怎么触发缓存更新的？](#toc_6)
  - [你们用Redis来做什么？为什么不用其他的KV存储例例如Memcached,Cassandra等?](#toc_7)
  - [一个字符串类型的值能存储最大容量是多少？](#toc_8)
  - [Redis相比memcached有哪些优势？](#toc_9)
  - [你们用什么Redis客户端?](#toc_10)
  - [Jedis与Redisson对比有什么优缺点？](#toc_11)
  - [Redis支持哪几种数据类型？](#toc_12)
  - [你熟悉哪些Redis的数据结构? zset是干什么的? 和set有什么区别?](#toc_13)
  - [说说Redis哈希槽的概念？](#toc_14)
  - [Redis的hash, 存储和获取的具体命令叫什么名字?](#toc_15)
  - [LPOP和BLPOP的区别?](#toc_16)
  - [Redis的有一些包含SCAN关键字的命令是干嘛的? SCAN返回的数据量是固定的吗?](#toc_17)
  - [Redis有哪几种数据淘汰策略？](#toc_18)
  - [Redis中的Lua有没有使用过? 可以用来做什么? 为什么可以这么用?](#toc_19)
  - [Redis的Pipeline是用来干什么的?](#toc_20)
  - [Redis持久化大概有几种方式? aof和rdb的区别是什么? AOF有什么优缺点吗?](#toc_21)
  - [Redis Replication的大致流程是什么? bgsave这个命令的执行过程? -- 偏题](#toc_22)
  - [如果有很多 KV数据要存储到Redis, 但是内存不足, 通过什么方式可以缩减内存? 为什么这样可以缩小内存?](#toc_23)
  - [为什么要做Redis分区？](#toc_24)
  - [Redis中List, HashTable都用到了ZipList, 为什么会选择它?](#toc_25)
  - [Redis是单线程的，如何提高多核CPU的利用率？](#toc_26)
  - [Redis集群方案应该怎么做？都有哪些方案？](#toc_27)
  - [Redis扩容，失效key清理策略](#toc_28)
  - [Redis的持久化怎么做，aof和rdb，有什么区别，有什么优缺点。](#toc_29)
  - [Redis集群会有写操作丢失吗？为什么？](#toc_30)
  - [怎么理解Redis事务](#toc_31)
  - [Redis事务相关的命令有哪几个？](#toc_32)
  - [Redis实现分布式锁与Zookeeper实现分布式锁区别](#toc_33)

- - - [Redis实现分布式锁思路](#toc_34)
    - [Zookeeper实现分布式锁思路](#toc_35)
    - [相同点](#toc_36)
    - [不同点](#toc_37)

------

#### 介绍下redis

- Redis本质上是一个Key-Value类型的内存数据库

很像memcached，整个数据库统统加载在内存当中进行操作，定期通过异步操作把数据库数据flush到硬盘上进行保存。因为是纯内存操作，Redis的性能非常出色，每秒可以处理超过 10万次读写操作，是已知性能最快的Key-Value DB。

- Redis最大的魅力是支持保存多种数据结构，此外单个value的最大限制是1GB，不像 memcached只能保存1MB的数据

Redis可以用来实现很多有用的功能，比方说用他的List来做FIFO双向链表，实现一个轻量级的高性 能消息队列服务，用他的Set可以做高性能的tag系统等等。另外Redis也可以对存入的Key-Value设置expire时间，因此也可以被当作一 个功能加强版的memcached来用。

- Redis的主要缺点是数据库容量受到物理内存的限制，不能用作海量数据的高性能读写，因此Redis适合的场景主要局限在较小数据量的高性能操作和运算上。

#### Redis的全称是什么？

Remote Dictionary Server

#### 缓存穿透可以介绍一下么？你认为应该如何解决这个问题?

#### 怎么理解强一致性、单调一致性和最终一致性？

#### 为什么缓存更新策略是先更新数据库后删除缓存

#### 你是怎么触发缓存更新的？

(比如设置超时时间(被动方式), 比如更新的时候主动update)？如果是被动的方式如何控制多个入口同时触发某个缓存更新？

#### 你们用Redis来做什么？为什么不用其他的KV存储例例如Memcached,Cassandra等?

1. memcached所有的值均是简单的字符串，redis作为其替代者，支持更为丰富的数据类型
2. redis的速度比memcached快很多
3. redis可以持久化其数据

#### 一个字符串类型的值能存储最大容量是多少？

512M

#### Redis相比memcached有哪些优势？

- memcached所有的值均是简单的字符串，redis作为其替代者，支持更为丰富的数据类型
- redis的速度比memcached快很多
- redis可以持久化其数据

#### 你们用什么Redis客户端?

Redisson、Jedis、lettuce等等，官方推荐使用Redisson。

Redisson是一个高级的分布式协调Redis客服端，能帮助用户在分布式环境中轻松实现一些Java的对象 (Bloom filter, BitSet, Set, SetMultimap, ScoredSortedSet, SortedSet, Map, ConcurrentMap, List, ListMultimap, Queue, BlockingQueue, Deque, BlockingDeque, Semaphore, Lock, ReadWriteLock, AtomicLong, CountDownLatch, Publish / Subscribe, HyperLogLog)。

#### Jedis与Redisson对比有什么优缺点？

- Jedis是Redis的Java实现的客户端，其API提供了比较全面的Redis命令的支持；
- Redisson实现了分布式和可扩展的Java数据结构，和Jedis相比，功能较为简单，不支持字符串操作，不支持排序、事务、管道、分区等Redis特性。
- Redisson的宗旨是促进使用者对Redis的关注分离，从而让使用者能够将精力更集中地放在处理业务逻辑上。

#### Redis支持哪几种数据类型？

String、List、Set、Sorted Set、hashes

#### 你熟悉哪些Redis的数据结构? zset是干什么的? 和set有什么区别?

#### 说说Redis哈希槽的概念？

Redis集群没有使用一致性hash,而是引入了哈希槽的概念，Redis集群有16384个哈希槽，每个key通过CRC16校验后对16384取模来决定放置哪个槽，集群的每个节点负责一部分hash槽。

#### Redis的hash, 存储和获取的具体命令叫什么名字?

#### LPOP和BLPOP的区别?

#### Redis的有一些包含SCAN关键字的命令是干嘛的? SCAN返回的数据量是固定的吗?

#### Redis有哪几种数据淘汰策略？

- noeviction: 返回错误当内存限制达到并且客户端尝试执行会让更多内存被使用的命令（大部分的写入指令，但DEL和几个例外）
- allkeys-lru: 尝试回收最少使用的键（LRU），使得新添加的数据有空间存放。
- volatile-lru: 尝试回收最少使用的键（LRU），但仅限于在过期集合的键,使得新添加的数据有空间存放。
- allkeys-random: 回收随机的键使得新添加的数据有空间存放。
- volatile-random: 回收随机的键使得新添加的数据有空间存放，但仅限于在过期集合的键。
- volatile-ttl: 回收在过期集合的键，并且优先回收存活时间（TTL）较短的键,使得新添加的数据有空间存放。

#### Redis中的Lua有没有使用过? 可以用来做什么? 为什么可以这么用?

#### Redis的Pipeline是用来干什么的?

#### Redis持久化大概有几种方式? aof和rdb的区别是什么? AOF有什么优缺点吗?

#### Redis Replication的大致流程是什么? bgsave这个命令的执行过程? -- 偏题

#### 如果有很多 KV数据要存储到Redis, 但是内存不足, 通过什么方式可以缩减内存? 为什么这样可以缩小内存?

#### 为什么要做Redis分区？

分区可以让Redis管理更大的内存，Redis将可以使用所有机器的内存。如果没有分区，你最多只能使用一台机器的内存。分区使Redis的计算能力通过简单地增加计算机得到成倍提升,Redis的网络带宽也会随着计算机和网卡的增加而成倍增长。

#### Redis中List, HashTable都用到了ZipList, 为什么会选择它?

#### Redis是单线程的，如何提高多核CPU的利用率？

可以在同一个服务器部署多个Redis的实例，并把他们当作不同的服务器来使用，在某些时候，无论如何一个服务器是不够的，

所以，如果你想使用多个CPU，你可以考虑一下分片（shard）

#### Redis集群方案应该怎么做？都有哪些方案？

- twemproxy，大概概念是，它类似于一个代理方式，使用方法和普通redis无任何区别，设置好它下属的多个redis实例后，使用时在本需要连接redis的地方改为连接twemproxy，它会以一个代理的身份接收请求并使用一致性hash算法，将请求转接到具体redis，将结果再返回twemproxy

使用方式简便(相对redis只需修改连接端口)，对旧项目扩展的首选。 问题：twemproxy自身单端口实例的压力，使用一致性hash后，对redis节点数量改变时候的计算值的改变，数据无法自动移动到新的节点。

- codis，目前用的最多的集群方案，基本和twemproxy一致的效果，但它支持在 节点数量改变情况下，旧节点数据可恢复到新hash节点。
- redis cluster3.0自带的集群，特点在于他的分布式算法不是一致性hash，而是hash槽的概念，以及自身支持节点设置从节点。
- 在业务代码层实现，起几个毫无关联的redis实例，在代码层，对key 进行hash计算，然后去对应的redis实例操作数据。 

这种方式对hash层代码要求比较高，考虑部分包括，节点失效后的替代算法方案，数据震荡后的自动脚本恢复，实例的监控，等等。

#### Redis扩容，失效key清理策略

#### Redis的持久化怎么做，aof和rdb，有什么区别，有什么优缺点。

- RDB持久化方式能够在指定的时间间隔能对你的数据进行快照存储.
- AOF持久化方式记录每次对服务器写的操作,当服务器重启的时候会重新执行这些命令来恢复原始的数据,AOF命令以redis协议追加保存每次写的操作到文件末尾.Redis还能对AOF文件进行后台重写,使得AOF文件的体积不至于过大.

如果你只希望你的数据在服务器运行的时候存在,你也可以不使用任何持久化方式.

你也可以同时开启两种持久化方式, 在这种情况下, 当redis重启的时候会优先载入AOF文件来恢复原始的数据,因为在通常情况下AOF文件保存的数据集要比RDB文件保存的数据集要完整.

最重要的事情是了解RDB和AOF持久化方式的不同,让我们以RDB持久化方式开始

#### Redis集群会有写操作丢失吗？为什么？

Redis并不能保证数据的强一致性，这意味这在实际中集群在特定的条件下可能会丢失写操作

#### 怎么理解Redis事务

事务是一个单独的隔离操作：事务中的所有命令都会序列化、按顺序地执行。事务在执行的过程中，不会被其他客户端发送来的命令请求所打断。

#### Redis事务相关的命令有哪几个？

MULTI、EXEC、DISCARD、WATCH

------

#### Redis实现分布式锁与Zookeeper实现分布式锁区别

#### Redis实现分布式锁思路

基于Redis实现分布式锁（setnx）setnx也可以存入key，如果存入key成功返回1，如果存入的key已经存在了，返回0.

#### Zookeeper实现分布式锁思路

同时在zookeeper上创建相同的一个临时节点，因为临时节点路径是保证唯一，只要谁能够创建节点成功，谁就能够获取到锁，没有创建成功节点，就会进行等待，当释放锁的时候，采用事件通知给客户端重新获取锁的资源。

#### 相同点

在集群环境下，保证只允许有一个jvm进行执行。

#### 不同点

- 获取锁

1. 1. 多个客户端（jvm），会在Zookeeper上创建同一个临时节点，因为Zookeeper节点命名路径保证唯一，不允许出现重复，只要谁能够先创建成功，谁能够获取到锁。
   2. 多个客户端（jvm），会在Redis使用setnx命令创建相同的一个key，因为Redis的key保证唯一，不允许出现重复，只要谁能够先创建成功，谁能够获取到锁。

- 释放锁

1. 1. Zookeeper使用直接关闭临时节点session会话连接，如果session会话连接关闭的话，该临时节点也会被删除。
   2. Redis在释放锁的时候，为了确保是锁的一致性问题，在删除的redis 的key时候，需要判断同一个锁的id，才可以删除。

- 如何解决死锁现象问题

1. 1. Zookeeper使用会话有效期方式解决死锁现象。
   2. Redis 是对key设置有效期解决死锁现象

- 性能角度考虑因为Redis是NoSQL数据库，相对比来说Redis比Zookeeper性能要好。

1. 1. Redis分布式锁，必须使用者自己间隔时间轮询去尝试加锁，当锁被释放后，存在多线程去争抢锁，并且可能每次间隔时间去尝试锁的时候，都不成功，对性能浪费很大
   2. Zookeeper分布锁，首先创建加锁标志文件，如果需要等待其他锁，则添加监听后等待通知或者超时，当有锁释放，无须争抢，按照节点顺序，依次通知使用者。

- 可靠性, Zookeeper可靠性比Redis更好。

1. 1. 因为Redis有效期不是很好控制，可能会产生有效期延迟；
   2. Zookeeper就不一样，因为Zookeeper临时节点先天性可控的有效期



### 网络相关

- [网络相关](#toc_0)

- - [TCP粘包和拆包产生的原因](#toc_1)
  - [TCP粘包和拆包的解决策略](#toc_2)
  - [三次握手](#toc_3)
  - [四次握手](#toc_4)
  - [一次完整的HTTP请求过程](#toc_5)
  - [讲一下长连接](#toc_6)

- - - [基于http协议的长连接](#toc_7)
    - [发心跳包](#toc_8)

- - [HTTP 2.0 和 1.1 区别](#toc_9)
  - [HTTPS和HTTP的区别](#toc_10)
  - [简述Http请求get和post的区别以及数据包格式](#toc_11)
  - [Https的加密方式](#toc_12)
  - [Session和cookie的区别。](#toc_13)
  - [http请求报文结构和内容](#toc_14)
  - [http三次握手和四次挥手](#toc_15)
  - [OSI有哪七层模型？TCP/IP是哪四层模型。](#toc_16)

------

#### TCP粘包和拆包产生的原因

应用程序写入数据的字节大小大于套接字发送缓冲区的大小

进行MSS大小的TCP分段。MSS是最大报文段长度的缩写。MSS是TCP报文段中的数据字段的最大长度。数据字段加上TCP首部才等于整个的TCP报文段。所以MSS并不是TCP报文段的最大长度，而是：MSS=TCP报文段长度-TCP首部长度

以太网的payload大于MTU进行IP分片。MTU指：一种通信协议的某一层上面所能通过的最大数据包大小。如果IP层有一个数据包要传，而且数据的长度比链路层的MTU大，那么IP层就会进行分片，把数据包分成托干片，让每一片都不超过MTU。注意，IP分片可以发生在原始发送端主机上，也可以发生在中间路由器上。

#### TCP粘包和拆包的解决策略

- 消息定长。例如100字节。
- 在包尾部增加回车或者空格符等特殊字符进行分割，典型的如FTP协议
- 将消息分为消息头和消息尾。
- 其它复杂的协议，如RTMP协议等。

#### 三次握手

- 第一次握手：建立连接时，客户端发送syn包(syn=j)到服务器，并进入SYN_SEND状态，等待服务器确认；
- 第二次握手：服务器收到syn包，必须确认客户的SYN（ack=j+1），同时自己也发送一个SYN包（syn=k），即SYN+ACK包，此时服务器进入SYN_RECV状态；
- 第三次握手：客户端收到服务器的SYN＋ACK包，向服务器发送确认包ACK(ack=k+1)，此包发送完毕，客户端和服务器进入ESTABLISHED状态，完成三次握手。

完成三次握手，客户端与服务器开始传送数据

#### 四次握手

- 客户端先发送FIN，进入FIN_WAIT1状态
- 服务端收到FIN，发送ACK，进入CLOSE_WAIT状态，客户端收到这个ACK，进入FIN_WAIT2状态
- 服务端发送FIN，进入LAST_ACK状态
- 客户端收到FIN，发送ACK，进入TIME_WAIT状态，服务端收到ACK，进入CLOSE状态

TIME_WAIT的状态就是主动断开的一方（这里是客户端），发送完最后一次ACK之后进入的状态。并且持续时间还挺长的。客户端TIME_WAIT持续2倍MSL时长，在linux体系中大概是60s，转换成CLOSE状态

#### 一次完整的HTTP请求过程

域名解析 --> 发起TCP的3次握手 --> 建立TCP连接后发起http请求 --> 服务器响应http请求，浏览器得到html代码 --> 浏览器解析html代码，并请求html代码中的资源（如js、css、图片等） --> 浏览器对页面进行渲染呈现给用户

#### 讲一下长连接

#### 基于http协议的长连接

在HTTP1.0和HTTP1.1协议中都有对长连接的支持。其中HTTP1.0需要在request中增加”Connection： keep-alive“ header才能够支持，而HTTP1.1默认支持.

#### 发心跳包

#### HTTP 2.0 和 1.1 区别

- 区别一：多路复用
  多路复用允许单一的 HTTP/2 连接同时发起多重的请求-响应消息。看个例子：
  ![img](https://cdn.nlark.com/yuque/0/2019/png/406432/1565343607316-fd3bd4a3-78f9-4cbf-b833-781ad149c5c4.png)
  多路复用技术：单连接多资源的方式，减少服务端的链接压力,内存占用更少,连接吞吐量更大；由于减少TCP 慢启动时间，提高传输的速度
- 区别二：首部压缩
- 区别三：HTTP2支持服务器推送

#### HTTPS和HTTP的区别

- https协议需要到CA申请证书，一般免费证书很少，需要交费。
- http是超文本传输协议，信息是明文传输；https 则是具有安全性的ssl加密传输协 议。
- http和https使用的是完全不同的连接方式，用的端口也不一样，前者是80，后者是443。
- http的连接很简单，是无状态的；HTTPS协议是由SSL+HTTP协议构建的可进行加密传输、身份认证的网络协议，比http协议安全。
- http默认使用80端口，https默认使用443端口

#### 简述Http请求get和post的区别以及数据包格式

- 两种动作不一样，get是获取资源，post是提交资源 
- get参数在URL中不安全，post是放在http body中的相对安全 
- get传输字节数受限于URL长度，post无限制 
- 后台获取数据的方式get只能是QueryString, post可从InputStream中获取 
- base64编码后有+=特殊符号的会转码不能经get传输，如果是改进的base64会替换掉特殊符号可以用get传输。

#### Https的加密方式

#### Session和cookie的区别。

#### http请求报文结构和内容

#### http三次握手和四次挥手

#### OSI有哪七层模型？TCP/IP是哪四层模型。

### 监控、稳定性

- [监控、稳定性](#toc_0)

- - [业务日志是通过什么方式来收集的？](#toc_1)
  - [线上机器如何监控？采用什么开源产品或者自研的产品？它是分钟级的还是秒级的？](#toc_2)
  - [如果让你来想办法收集一个JAVA后端应用的性能数据，你会在意哪些方面? 你会选择什么样的工具、思路来收集?](#toc_3)
  - [一般你调用第三方的时候会不会监控调用情况？](#toc_4)

------

#### 业务日志是通过什么方式来收集的？

#### 线上机器如何监控？采用什么开源产品或者自研的产品？它是分钟级的还是秒级的？

#### 如果让你来想办法收集一个JAVA后端应用的性能数据，你会在意哪些方面? 你会选择什么样的工具、思路来收集?

#### 一般你调用第三方的时候会不会监控调用情况？

### linux

- [linux](#toc_0)

------

日志特别大只想看最后100行怎么弄弄? 如果想一直看日志的持续输出，用什么命令?

2.如果日志一边输出，一边想实时看到有没有某个关键字应该怎么弄？

3.grep如果忽略大小写应该怎么弄? 正则表达式呢？

4.vim往下一行是什么键？往下30行呢? 跳到文件末尾一行是什么? 跳回来是什么? 向后搜索是什么?

5.如果有个文本文件，按空格作为列的分隔符，如果想统计第三列里面的每个单词的出现次数应该怎么弄？

6.如果把上面的出现次数排个序应该怎么弄? 想按照数字本身的顺序而不是字符串的顺序排列怎么弄？

7.Linux环境变量是以什么作为分隔符的？环境变量通过什么命令设置？

8.给某个文件权设置限比如设置为64 是用什么命令？这个6是什么意思？

9.Linux下面如果想看某个进程的资源占用情况是怎么看的？系统load大概指的什么意思？你们线上系统load一般多少？如果一个4核机器，你认为多少load是比较正常的？top命令里面按一下1会发生什么?

10.top命令里面，有时候所有进程的CPU使用率加起来超过100%是怎么回事？

11.还有哪些查看系统性能或者供你发现问题的命令？你一般是看哪个参数？

12.想看某个进程打开了哪些网络连接是什么命令？里面连接的状态你比较关心哪几种？ -- 偏题

有没有做过Linux系统参数方面的优化，大概优化过什么？

13.系统参数里面有个叫做backlog的可以用来干什么？

14.查看网络连接发现好多TIMEWAIT 可能是什么原因？对你的应用会有什么影响？你会选择什么样的方式来减少这些TIMEWAIT

15.可否介绍一下TCP三次握手的过程，如果现在有个网络程序，你用第三方的library来发送数据，你怀疑这个library发送的数据有问题，那么怎么来验证？tcpdump导出的文件你一般是怎么分析的？

16.KeepAlive是用来干什么的？这样的好处是什么？

### 算法相关

- [算法相关](#toc_0)

- - [常用排序算法](#toc_1)
  - [链表相关](#toc_2)
  - [数组相关](#toc_3)
  - [字符串相关](#toc_4)
  - [树相关](#toc_5)
  - [TopK](#toc_6)
  - [有1亿个数字，其中有2个是重复的，快速找到它，时间和空间要最优](#toc_7)

#### 常用排序算法

二分查找

#### 链表相关

- 合并多个单有序链表（假设都是递增的）

#### 数组相关

#### 字符串相关

#### 树相关

#### TopK

- 10亿个数字里里面找最小的10个

#### 有1亿个数字，其中有2个是重复的，快速找到它，时间和空间要最优

10亿个数字里里面找最小的10个。

有1亿个数字，其中有2个是重复的，快速找到它，时间和空间要最优。

2亿个随机生成的无序整数,找出中间大小的值。

给一个不知道长度的（可能很大）输入字符串，设计一种方案，将重复的字符排重。

遍历二叉树。

有3n+1个数字，其中3n个中是重复的，只有1个是不重复的，怎么找出来。

写一个字符串（如：www.javastack.cn）反转函数。

常用的排序算法，快排，归并、冒泡。 快排的最优时间复杂度，最差复杂度。冒泡排序的

优化方案。

二分查找的时间复杂度，优势。

一个已经构建好的TreeSet，怎么完成倒排序。

什么是B+树，B-树，列出实际的使用场景。

一个单向链表，删除倒数第N个数据。

200个有序的数组，每个数组里面100个元素，找出top20的元素。

单向链表，查找中间的那个元素

### 大数据

#### Hadoop

- Hadoop是什么
- 介绍下HDFS

- - HDFS 优缺点
  - [HDFS 的特点](https://github.com/wangzhiwubigdata/God-Of-BigData/blob/master/大数据框架学习/Hadoop-HDFS.md#三HDFS-的特点)

- - - [高容错](https://github.com/wangzhiwubigdata/God-Of-BigData/blob/master/大数据框架学习/Hadoop-HDFS.md#31-高容错)
    - [高吞吐量](https://github.com/wangzhiwubigdata/God-Of-BigData/blob/master/大数据框架学习/Hadoop-HDFS.md#32-高吞吐量)
    - [大文件支持](https://github.com/wangzhiwubigdata/God-Of-BigData/blob/master/大数据框架学习/Hadoop-HDFS.md#33--大文件支持)
    - [简单一致性模型](https://github.com/wangzhiwubigdata/God-Of-BigData/blob/master/大数据框架学习/Hadoop-HDFS.md#33-简单一致性模型)
    - [跨平台移植性](https://github.com/wangzhiwubigdata/God-Of-BigData/blob/master/大数据框架学习/Hadoop-HDFS.md#34-跨平台移植性)

- - HDFS 组成架构
  - HDFS文件大小默认是多少，如何设置
  - HDFS文件大小为什么不能设置太大或太小
  - [文件系统命名空间](https://github.com/wangzhiwubigdata/God-Of-BigData/blob/master/大数据框架学习/Hadoop-HDFS.md#22-文件系统命名空间)
  - [数据复制及实现原理](https://github.com/wangzhiwubigdata/God-Of-BigData/blob/master/大数据框架学习/Hadoop-HDFS.md#24-数据复制的实现原理)
  - [副本的选择](https://github.com/wangzhiwubigdata/God-Of-BigData/blob/master/大数据框架学习/Hadoop-HDFS.md#25--副本的选择)
  - [架构的稳定性](https://github.com/wangzhiwubigdata/God-Of-BigData/blob/master/大数据框架学习/Hadoop-HDFS.md#26-架构的稳定性)

- - - [心跳机制和重新复制](https://github.com/wangzhiwubigdata/God-Of-BigData/blob/master/大数据框架学习/Hadoop-HDFS.md#1-心跳机制和重新复制)
    - [数据的完整性](https://github.com/wangzhiwubigdata/God-Of-BigData/blob/master/大数据框架学习/Hadoop-HDFS.md#2-数据的完整性)
    - [元数据的磁盘故障](https://github.com/wangzhiwubigdata/God-Of-BigData/blob/master/大数据框架学习/Hadoop-HDFS.md#3元数据的磁盘故障)
    - [支持快照](https://github.com/wangzhiwubigdata/God-Of-BigData/blob/master/大数据框架学习/Hadoop-HDFS.md#4支持快照)

#### Hive

#### Spark

**Spark Core :**

1. [Spark 简介](https://github.com/wangzhiwubigdata/God-Of-BigData/blob/master/大数据框架学习/Spark简介.md)
2. [弹性式数据集 RDD](https://github.com/wangzhiwubigdata/God-Of-BigData/blob/master/大数据框架学习/Spark_RDD.md)
3. [RDD 常用算子详解](https://github.com/wangzhiwubigdata/God-Of-BigData/blob/master/大数据框架学习/Spark_Transformation和Action算子.md)
4. [Spark 运行模式与作业提交](https://github.com/wangzhiwubigdata/God-Of-BigData/blob/master/大数据框架学习/Spark部署模式与作业提交.md)
5. [Spark 累加器与广播变量](https://github.com/wangzhiwubigdata/God-Of-BigData/blob/master/大数据框架学习/Spark累加器与广播变量.md)

**Spark SQL :**

1. [DateFrame 和 DataSet](https://github.com/wangzhiwubigdata/God-Of-BigData/blob/master/大数据框架学习/SparkSQL_Dataset和DataFrame简介.md)
2. [Structured API 的基本使用](https://github.com/wangzhiwubigdata/God-Of-BigData/blob/master/大数据框架学习/Spark_Structured_API的基本使用.md)
3. [Spark SQL 外部数据源](https://github.com/wangzhiwubigdata/God-Of-BigData/blob/master/大数据框架学习/SparkSQL外部数据源.md)
4. [Spark SQL 常用聚合函数](https://github.com/wangzhiwubigdata/God-Of-BigData/blob/master/大数据框架学习/SparkSQL常用聚合函数.md)
5. [Spark SQL JOIN 操作](https://github.com/wangzhiwubigdata/God-Of-BigData/blob/master/大数据框架学习/SparkSQL联结操作.md)

**Spark Streaming ：**

1. [Spark Streaming 简介](https://github.com/wangzhiwubigdata/God-Of-BigData/blob/master/大数据框架学习/Spark_Streaming与流处理.md)
2. [Spark Streaming 基本操作](https://github.com/wangzhiwubigdata/God-Of-BigData/blob/master/大数据框架学习/Spark_Streaming基本操作.md)

#### Flink

1. [Flink 核心概念综述](https://github.com/wangzhiwubigdata/God-Of-BigData/blob/master/大数据框架学习/Flink核心概念综述.md)
2. [Flink Data Source](https://github.com/wangzhiwubigdata/God-Of-BigData/blob/master/大数据框架学习/Flink_Data_Source.md)
3. [Flink Data Transformation](https://github.com/wangzhiwubigdata/God-Of-BigData/blob/master/大数据框架学习/Flink_Data_Transformation.md)
4. [Flink Data Sink](https://github.com/wangzhiwubigdata/God-Of-BigData/blob/master/大数据框架学习/Flink_Data_Sink.md)
5. [Flink 窗口模型](https://github.com/wangzhiwubigdata/God-Of-BigData/blob/master/大数据框架学习/Flink_Windows.md)
6. [Flink 状态管理与检查点机制](https://github.com/wangzhiwubigdata/God-Of-BigData/blob/master/大数据框架学习/Flink状态管理与检查点机制.md)

#### Hbase

1. [Hbase 简介](https://github.com/wangzhiwubigdata/God-Of-BigData/blob/master/大数据框架学习/Hbase简介.md)
2. [HBase 系统架构及数据结构](https://github.com/wangzhiwubigdata/God-Of-BigData/blob/master/大数据框架学习/Hbase系统架构及数据结构.md)
3. [HBase 常用 Shell 命令](https://github.com/wangzhiwubigdata/God-Of-BigData/blob/master/大数据框架学习/Hbase_Shell.md)
4. [HBase Java API](https://github.com/wangzhiwubigdata/God-Of-BigData/blob/master/大数据框架学习/Hbase_Java_API.md)

### web开发安全

- [web开发安全](#toc_0)
- [主流web漏洞](#toc_1)
- [csrf 攻击](#toc_2)
- [xss 攻击](#toc_3)
- [SQL 注入](#toc_4)
- [URL跳转漏洞](#toc_5)
- [什么是DoS、DDoS、DRDoS攻击？如何防御？](#toc_6)

------

#### 主流web漏洞

![img](https://cdn.nlark.com/yuque/0/2019/png/406432/1565344289364-8c9fc4f0-7445-446d-a8d5-0cdb76599735.png)

#### csrf 攻击

CSRF（Cross-site request forgery）跨站请求伪造，也被称为“One Click Attack”或者Session Riding，通常缩写为CSRF或者XSRF，是一种对网站的恶意利用。但它与XSS非常不同，XSS利用站点内的信任用户，而CSRF则通过伪装成受信任用户的请求来利用受信任的网站。与XSS攻击相比，CSRF攻击往往不大流行（因此对其进行防范的资源也相当稀少）和难以防范，所以被认为比XSS更具危险性。

[浅谈CSRF攻击方式](https://www.cnblogs.com/hyddd/archive/2009/04/09/1432744.html)

![img](https://cdn.nlark.com/yuque/0/2019/png/406432/1565344298809-05ddd5cc-6dd6-4c60-bda9-a45919a192d1.png)

#### xss 攻击

[Cross-Site Scripting](https://segmentfault.com/a/1190000016551188)（跨站脚本攻击）简称 XSS，是一种代码注入攻击。攻击者通过在目标网站上注入恶意脚本，使之在用户的浏览器上运行。利用这些恶意脚本，攻击者可获取用户的敏感信息如 Cookie、SessionID 等，进而危害数据安全。

- 在 HTML 中内嵌的文本中，恶意内容以 script 标签形成注入。
- 在内联的 JavaScript 中，拼接的数据突破了原本的限制（字符串，变量，方法名等）。
- 在标签属性中，恶意内容包含引号，从而突破属性值的限制，注入其他属性或者标签。
- 在标签的 href、src 等属性中，包含 javascript: 等可执行代码。
- 在 onload、onerror、onclick 等事件中，注入不受控制代码。
- 在 style 属性和标签中，包含类似 background-image:url("javascript:..."); 的代码（新版本浏览器已经可以防范）。
- 在 style 属性和标签中，包含类似 expression(...) 的 CSS 表达式代码（新版本浏览器已经可以防范）。

XSS 分类

| 类型       | 存储区*                 | 插入点*         |
| ---------- | ----------------------- | --------------- |
| 存储型 XSS | 后端数据库              | HTML            |
| 反射型 XSS | URL                     | HTML            |
| DOM 型 XSS | 后端数据库/前端存储/URL | 前端 JavaScript |

#### SQL 注入

#### URL跳转漏洞

#### 什么是DoS、DDoS、DRDoS攻击？如何防御？





#### 消息中间件

目前在使用的消息中间件是RocketMQ和kafka



- Rocket 特点

RocketMQ是一个分布式消息和流处理平台，具有低延迟，高性能和高可靠性，亿万级容量和灵活的可扩展性。它由四部分组成：名称服务器，代理服务器，生产者和消费者。它们中的每一个都可以水平扩展，而不会出现单点故障。



- Kafka 特点

支持消息的发布和订阅，这个和RocketMq类似；支持数据实时处理；能保证消息的可靠性投递；支持消息的持久化存储，并通过多副本分布式的存储方案来保证消息的容错；高吞吐率，单 Broker 可以轻松处理数千个分区以及每秒百万级的消息量。



- Rocket和Kafka的区别

| 比较项                 | RocketMq                        | Kafka                             |
| ---------------------- | ------------------------------- | --------------------------------- |
| **顺序消息**           | 确保分区内的消息的顺序          | 确保严格的消息顺序,并能优雅的扩展 |
| **定时消息**           | 不支持                          | 支持                              |
| **批量消息**           | 支持,异步生产                   | 支持,使用同步的模式以避免消息丢失 |
| **广播消息**           | 不支持                          | 支持                              |
| **消息过滤**           | 支持, 可以使用Kafka流来筛选消息 | 支持,基于SQL92的属性筛选表达式    |
| **服务器端触发的重试** | 不支持                          | 支持                              |
| **消息存储**           | 高性能存储                      | 高性能和低延迟文件存储            |
| **消息可追溯**         | 支持                            | 支持,时间戳和偏移量               |
| **消息优先级**         | 不支持                          | 不支持                            |
| **管理和操作工具**     | 支持,通过终端命令可以进行配置   | 开箱即用, 用户只需要注意一些配置  |
|                        |                                 |                                   |



- 具体指导

中台应用间的业务消息都是通过RocketMQ来进行，一般性的应用消息通过RocketMQ来进行，RocketMQ对业务消息提供了更高的可用性、管理方便、使用上可以按Topic进行筛选等特点。

但结合业务特点，比较计量数据， 需要进行高速大批量进行写入和消费，消费方固定，但对实时顺序性等要求没有那么高的可以考虑kafka



#### NoSQL数据库

- 目前中台在使用的NoSQL数据库主要有

1. HBase
2. MongoDB

3. ElasticSearch
4. Redis



- HBase



Hbase，是一个高可靠、高性能、可伸缩的分布式数据库。Hbase参考了谷歌的BigTable建模，使用HDFS作为底层存储。使用Zookeeper作为协同服务组件。



可以提供数据的实时随机读写的NoSQL数据库，他的特点如下：

1.  Hbase的表没有固定的字段定义
2.  Hbase的表中每行存储的都是一些key-value对

3.  Hbase的表中有列族的划分，用户可以指定将哪些kv插入哪个列族
4.  Hbase的表在物理存储上，是按照列族来分割的，不同列族的数据一定存储在不同的文件中

5.  Hbase的表中的每一行都固定有一个行键，而且每一行的行键在表中不能重复
6.  Hbase中的数据，包含行键，包含key，包含value，都是byte[ ]类型，hbase不负责为用户维护数据类型

7.  HBASE对事务的支持很差

HBASE相比于其他nosql数据库(mongodb、redis、cassendra、hazelcast)的特点：

1. Hbase的表数据存储在HDFS文件系统中
2. 存储容量可以线性扩展； 数据存储的安全性可靠性极高！



***如果要使用HBase，对于数据的RowKey怎么设计需要慎重考虑，RowKey的设计会极大的影响后续的业务便利性，而且一段设计定型了，后续也很难更改。\***



- MongoDB







- ElasticSearch

ES特性：是一个**分布式、可扩展、实时的搜索与数据分析引擎**。

1. **全文搜索**
2. **结构化数据的实时统计**

3. **数据分析**
4. **复杂的人类语言处理**

5. **地理位置和对象间关联关系**等



ES特点（有点）：

1. 速度快：当数据量到达千万级以上的时候，关系型数据库单表无论是通过增加索引、分库分表来优化，最终能够优化的效果往往不如人意（且分库分表复杂度较高），而ES可以轻松hold住千万、亿级数据量。
2. 不只是全文检索：在传统关系型数据库中，我们很多使用需要采用模糊查询的方式来获取想要的数据，LIKE '%检索项%'，  SQL不会走索引的（不符合最左前缀原则），将执行全表扫描，性能很差。 但在ES中实现上述的查询则很简单，可以实时的查询到想要的结果。





- Redis

Redis是一个高性能的(key/value)分布式内存数据库，基于内存运行并支持持久化的NoSQL数据库。value的数据类型支持主要有 String、List、Hash、Set、ZSet 这5种。



Redis的应用场景主要有:

1. String

1. 1. 取最新N个数据的操作如：可以将最新的10条评论的ID放在Redis的List集合里面
   2. 模拟类似于HttpSession这种需要设定过期时间的功能

1. 1. 缓存： Redis提供了键过期功能，也提供了灵活的键淘汰策略
   2. 计数器：什么是计数器，如电商网站商品的浏览量、视频网站视频的播放数等

1. 1. 分布式锁 ： 可以利用Redis的setnx功能来编写分布式的锁，如果设置返回1说明获取锁成功，否则获取锁失败
   2. 分布式Session

1. 1. 限流

1. Hash

1. 1. 存储用户信息
   2. 用户主页访问量

1. 1. 组合查询

1. List：微博关注人时间轴列表、简单队列

1. 1. Redis提供的有序集合数据类构能实现各种复杂的排行榜应用

1. Set

1. 1. 赞、踩
   2. 标签

1. 1. 好友关系

1. Zset：排行榜



- 定时任务使用场景

1. 定时备份数据
2. 业务（订单）超时自动取消

3. 业务（订单）失败后的定时重试
4. 按时间段统计信息

5. 业务定期（优惠券要过期）给用户发送提醒消息等。



#### 定时任务



- 定时任务的基本概念

执行器：负责执行任务。

调度器：根据配置（cron表达式）详情，告知执行器去执行任务

任务：自己的业务实现，比如优惠券要过期给用户发送一个提醒。



- 使用xxl-job任务需要注意的地方

1. 定时任务是靠机器按crob表达式进行调度的，都是有一定的的延迟，如果有一个业务要求12:00分生效，理想情况下也会有几秒的延迟，不可能12:00准时生效。
2. xxl-job只是一个触发入口，具体的实现时需要业务来处理的。

3. 对耗时严重的任务，建议仅仅通过xxl-job进行触发，触发后以异步方式执行，不要占用xxl-job的链接资源。
4. 对大批量的任务，最好结合MQ队列一起来处理。



xxl-job接入指南 ：https://qianxun.yuque.com/ddad5m/ykumxg/kgb6h9



#### 缓存中间件



开发过程中经常性的需要对数据进行缓存，常用的缓存技术手段基本有下面几个

1. 无外部依赖的，jdk自身提供的 HashMap/ConcurrentHashMap
2. 单机缓存管理，简单引入jar包的guava

3. 分布式缓存管理，使用redis，memcache等



这里重点强调下使用分布式缓存的选型，为了提高大家的编码效率，编码一致性，缓存的统一处理框架推荐使用JetCache：

https://github.com/alibaba/jetcache

https://github.com/alibaba/jetcache/wiki/Home_CN





#### 性能设计

1. 性能指标分解

  系统性能指标

  子系统性能指标



2. 性能监控

  是否需要性能方面的监控，如过需要，请给出明确的监控指标项。

3. 限流和降级

  限流和降级是否需要，策略，及使用的技术方案。

4. 性能相关设计策略与性能需求的映射关系



5. 架构设计阶段提前做好快速定位性能问题或故障的预案。SkyWalking作为默认需要接入的。

​    对请求的各个环节、链路进行分析，找到可能出现瓶颈的地方，是前端需要优化，还是后端服务需要优化，还是存储需要优化。





# 应用性能设计原则



## 1.考虑使用分布式缓存原则

1.1设计cache集群化部署，集中更新缓存带来性能和资源开销；如果cache失效，大量请求命中DB带来服务性能雪崩，避免丢失过多数据造成服务压力陡增。避免单点问题，提供更加高可用，高性能的服务。

1.2 设计热点数据进行预热加载：高峰期来临前，将热点数据提前存入缓存，提高高峰期的服务性能。

1.3 不存在的数据并定期清理：防止查询不到，导致cache无法命中而频繁访问DB的场景

1.4 分布式缓存集中管理，保证可扩展性，降低系统复杂度



## 2.考虑异步化设计原则

通过分布式消息队列来实现削峰的目的，通过业务配合技术来解决问题。一般合理使用消息队列，可有效抵御促销活动大量涌入的订单对系统造成的冲击



## 3. 考虑集群策略原则

使用负载均衡技术为一个应用构建一个由多台服务器组成的服务器集群，将并发请求分发到多台服务器上处理，避免单一服务器因负载压力过大而响应缓慢，使用户请求具有更好的响应延迟特性



## 4.代码性能优化原则

4.1 多线程中的密集型计算：线程数不宜超过CPU核数。如果是IO处理，则线程数=[任务执行时间/(任务执行时间-IO等待时间)] * CPU核数

4.2将对象设计成无状态对象，多采用局部对象，并发访问资源时使用锁

4.3 资源复用原则：系统运行时，尽量减少那些开销很大的资源的创建和销毁

4.4合理设置JVM参数，以最大程度避免不合理的full gc



## 5.存储性能优化原则

5.1 硬件选择——机械硬盘VS固态硬盘

5.2 B+树 vs LSM树（数据结构）：关系型数据库的索引采用B+树进行实现，nosql数据库采用了LSM树进行存储。所以对于读写操作较多，LSM树其性能远高于b+树

5.3 存储和备份方式选择（RAID vs HDFS），采用HDFS结合map reduce进行海量数据存储和分析，能自动进行并发访问和冗余备份，具有很高的可靠性



# 一致性

在业务系统中，数据一致性非常的重要，总体上说，有2种方式来保证一致性

- 事务性的强一致性
- 数据的最终一致性



- 事务性的强一致性

事务性的强一致，实施的代价比较高，基本局限于服务应用内部，并且一个应用如果事务太多，比如降低并发性，增加数据库的负载；如果在分布式情况下，要实现事务一致性，还需要引入复杂的分布式事务解决方案；所以，不建议一般的业务系统采用事务一致性方案，只对资金类要求很严格的业务有限使用。



- 数据的最终一致性

数据的最终一致性，需要处理好几个问题

1. 业务调用的幂等处理
2. 业务失败的重试（补偿）处理

3. 业务异步处理的握手处理
4. 数据不一致的检测和报警



前3个步骤是保证一致性的关键，需要开发在开发过程中重点把握；第4个步骤是事后止损措施。



要求：

- 明确系统内部哪些数据需要一致
- 明确系统和外部系统之间哪些数据需要保持数据一致性

- 保证数据一致的策略和实现方式



# 可靠性

**I.避免单点（重要）**：集群+LB、容器化部署(k8s的编排管理保证了pod的数量和健康,并且支持弹性伸缩、滚动升级)

**II.熔断**：快速失败，避免服务雪崩，保护整个服务链路；（dubbo+hystrix）

**III.降级**： 不同的业务采用不同的降级逻辑，保证核心服务的正常运行；（在dubbo消费端可以配置mock对调用进行降级）

**IV.限流**： 防止流量超出系统所能承受的阈值；（sentinel）

**V.缓存**： 避免同一时间大量请求直接落到数据库，将数据库击垮；（本地缓存、分布式缓存）

**VI.超时和重试机制**： 设置超时时间避免请求堆积，重试避免偶尔的网络抖动；（配置dubbo的timeout和retry次数，注意服务接口的幂等）



## 一、什么时候需要读写分离？



- 高频读，低频写
- 读请求单节点数据库性能难以支撑（通常每秒QPS吞吐量可能超过3w，IOPS超过2w，建议考虑）

- 读请求有弹性伸缩的要求（是否需要高峰扩容，闲时回收）
- 缓存存在的情况下，仍旧可能因为命中率，首次加载等场景，存在集中查询的场合



## 二、读写分离前提



- 对主从同步导致性能的少量下降有一定的容忍性（性能：同步复制<半同步复制<异步复制）
- 对主从分离的数据可见性延迟有一定的容忍性

- 对业务中读取后更新等场景有严格的把控评估和解决方案
- 对代码中可读写分离的功能有明确的把控

- 事务中查询不应读写分离
- 读写分离可能加剧业务脏写问题，因此从根本上规避此类问题接入读写分离的系统应当有数据写入一致性方案，例如version版本控制



## 三、读写分离方案



1. 阿里云数据库读写分离方案：

https://help.aliyun.com/document_detail/96073.html?spm=a2c4g.11186623.2.13.54582e9bkHFr2j#concept-ptl-fl4-wdb



1. ShardingJDBC及ShardingProxy：

https://shardingsphere.apache.org/document/current/en/features/replica-query/



1. 业务系统实现可控读写分离

自行实现`



## 四、方案比较

|               | 阿里云数据库读写分离                                         | 数据库中间件    | 业务系统实现读写分离                     |
| ------------- | ------------------------------------------------------------ | --------------- | ---------------------------------------- |
| 部署方式      | 仅公有云                                                     | 公有云/专有云   | 公有云/专有云                            |
| 代码耦合      | 无侵入/标记侵入                                              | 无侵入/标记侵入 | 标记侵入/强耦合                          |
| 可控性        | 自动分发：代理层通过SELECT及UPDATE关键字自动分发，业务不可控标记分发：通过force hint标记分发控制，对业务有侵入控制 | 同左            | 业务完全控制，指定本次查询是读库或者写库 |
| 事务          | 不支持事务                                                   | 不支持事务      | 不支持事务                               |
| 可用区/多中心 | 不支持，读写节点不可跨可用区                                 | 支持            | 支持                                     |



## 一、什么时候需要分库分表

- 预估单表记录数大于500w，且可能持续增长
- 预估单库容量大于1TB，且可能持续增长

- 预估单库或者单表存在读写热点问题，尤其是写热点问题
- 预估存在多中心场合



## 二、分库分表的作用

- 水平扩展，理论上数据库容量无限扩展
- 热点分散，合理设计分表，缓解单表中频繁访问，行锁及I/O争抢的问题

- 易于维护，单表DDL可操作，不因为表体积过大导致无法维护
- 提升性能，相较大体积表，即使表上出现skip等耗时操作，仍旧可以等待响应，不至于挂起

- 多中心部署技术路径必须项



## 三、分库分表方案

### 1. 设计分片键及分片策略

1. 1. 考虑最频繁查询业务字段，且全局唯一（真正的全局唯一，支持多中心架构）
   2. 分片策略下，预估单表容量大小

1. 1. 分片策略下，预估单表查询热度



### 2. 动态分片 or 静态分片

|          | 静态分片                                                     | 动态分片                                                   |
| -------- | ------------------------------------------------------------ | ---------------------------------------------------------- |
| 分片算法 | Hash等取模法                                                 | 时间片算法，雪花算法，范围算法，检索表等                   |
| 节点数   | 预设固定                                                     | 执行中可变                                                 |
| 节点变化 | 成本极大，需数据迁移重排                                     | 可适应算法变更                                             |
| 单点查询 | 性能极好                                                     | 根据算法不同，理论上最好情况可达静态分片同等性能           |
| 跨表查询 | 少量分片无需构建索引表分片数较多需要构建索引表或者其他数据整合方案 | 需要构建动态索引表或者其他数据整合方案                     |
| 跨库分片 | 跨库算法和跨表算法可以与业务无关                             | 跨库算法和跨表算法需要根据业务设计                         |
| 维护性   | 较差，无法直观获知数据位于哪个分片中                         | 可设计，可以通过算法将分片信息维护于分片键本身或者检索表中 |



### 3. 跨表业务查询方案设计

需要考虑业务跨表数据连接、查询和排序等场景。设计全局静态索引表，或者数据聚合查询方案（例如ElasticSearch等）



### 4. 维护可行性

- 数据迁移可行性
- 分片重排可行性

- 数据聚合可行性

### 

## 四、可执行参考方案

### 1. 阿里云集群数据库

#### 1.1 PolarDB

PolarDB是阿里云提供的基于计算与存储分离理念设计的原生关系型数据库，其已经提供了大容量存储及读写分离特性，支持最大容量100T，16个计算节点，每节点最高88vCPU（理论值）。

可参考：https://www.aliyun.com/product/polardb?spm=5176.13910061.J_8058803260.128.467830f1cXm7rR



#### 1.2 PolarDB-X（原DRDS，水平分片型）

PolarDB-X是阿里云提供的基于DRDS分布式SQL模型以及X-DB分布式存储设计的云分布式原生关系型数据库，支持PB级存储，峰值8700wTPS（理论值），基于Paxos一致性协议确保跨可用区数据一致性。

可参考：https://www.aliyun.com/product/drds?spm=5176.155538.J_8058803260.129.59baee1fsN3PbW



### 2. 分库分表中间件

#### 2.1 ShardingJDBC 

可参考：https://shardingsphere.apache.org/document/current/en/overview/#shardingsphere-jdbc

#### 2.2 ShardingProxy

可参考：https://shardingsphere.apache.org/document/current/en/overview/#shardingsphere-proxy



|          | shardingJDBC                                     | shardingProxy                          |
| -------- | ------------------------------------------------ | -------------------------------------- |
| 架构     | 分布式无状态设计                                 | 中心式有状态设计                       |
| 性能     | 本地执行，静态算法，性能较好                     | 云服务管理，代理模式，多一跳，性能稍差 |
| 可靠性   | 无单点故障                                       | 有单点故障                             |
| 可运维性 | 节点变更、路由切换存在一致性风险（根据算法决定） | 节点变更代理统一管理，算法保障一致性   |
| 编码     | 引入jar包，配置数据                              | 需要部署独立进程                       |



### 3. 业务定制化分库分表（不推荐）

在一些特殊场合下，可以考虑业务引入定制化分库分表策略。

优点：

1. 1. 数据分布贴近业务，可以最合理设计
   2. 性能可定制

1. 1. 数据可视性较好

缺点：

1. 1. 可运维性差
   2. 需要人力维护成本

1. 1. 后期变更需要完全定制





#### 监控报警



监控事项分为服务监控，业务监控，性能监控。

每类监控需要明确：

- 监控项（服务状态，业务埋点，性能指标等）
- 监控的实现方式（skywalking，metric，日志等）

- 感知方式

- - 定期查看监控页面
  - 报警通知

- - - 报警阈值，通知方式，通知频次等