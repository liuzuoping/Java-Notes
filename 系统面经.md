# 系统面经

### Redis

- [Redis](#toc_0)

- - [介绍下redis](#toc_1)
  - [Redis的全称是什么？](#toc_2)
  - [缓存穿透可以介绍一下么？你认为应该如何解决这个问题?](#toc_3)
  - [怎么理解强一致性、单调一致性和最终一致性？](#toc_4)
  - [为什么缓存更新策略是先更新数据库后删除缓存](#toc_5)
  - [你是怎么触发缓存更新的？](#toc_6)
  - [你们用Redis来做什么？为什么不用其他的KV存储例例如Memcached,Cassandra等?](#toc_7)
  - [一个字符串类型的值能存储最大容量是多少？](#toc_8)
  - [Redis相比memcached有哪些优势？](#toc_9)
  - [你们用什么Redis客户端?](#toc_10)
  - [Jedis与Redisson对比有什么优缺点？](#toc_11)
  - [Redis支持哪几种数据类型？](#toc_12)
  - [你熟悉哪些Redis的数据结构? zset是干什么的? 和set有什么区别?](#toc_13)
  - [说说Redis哈希槽的概念？](#toc_14)
  - [Redis的hash, 存储和获取的具体命令叫什么名字?](#toc_15)
  - [LPOP和BLPOP的区别?](#toc_16)
  - [Redis的有一些包含SCAN关键字的命令是干嘛的? SCAN返回的数据量是固定的吗?](#toc_17)
  - [Redis有哪几种数据淘汰策略？](#toc_18)
  - [Redis中的Lua有没有使用过? 可以用来做什么? 为什么可以这么用?](#toc_19)
  - [Redis的Pipeline是用来干什么的?](#toc_20)
  - [Redis持久化大概有几种方式? aof和rdb的区别是什么? AOF有什么优缺点吗?](#toc_21)
  - [Redis Replication的大致流程是什么? bgsave这个命令的执行过程? -- 偏题](#toc_22)
  - [如果有很多 KV数据要存储到Redis, 但是内存不足, 通过什么方式可以缩减内存? 为什么这样可以缩小内存?](#toc_23)
  - [为什么要做Redis分区？](#toc_24)
  - [Redis中List, HashTable都用到了ZipList, 为什么会选择它?](#toc_25)
  - [Redis是单线程的，如何提高多核CPU的利用率？](#toc_26)
  - [Redis集群方案应该怎么做？都有哪些方案？](#toc_27)
  - [Redis扩容，失效key清理策略](#toc_28)
  - [Redis的持久化怎么做，aof和rdb，有什么区别，有什么优缺点。](#toc_29)
  - [Redis集群会有写操作丢失吗？为什么？](#toc_30)
  - [怎么理解Redis事务](#toc_31)
  - [Redis事务相关的命令有哪几个？](#toc_32)
  - [Redis实现分布式锁与Zookeeper实现分布式锁区别](#toc_33)

- - - [Redis实现分布式锁思路](#toc_34)
    - [Zookeeper实现分布式锁思路](#toc_35)
    - [相同点](#toc_36)
    - [不同点](#toc_37)

------

#### 介绍下redis

- Redis本质上是一个Key-Value类型的内存数据库

很像memcached，整个数据库统统加载在内存当中进行操作，定期通过异步操作把数据库数据flush到硬盘上进行保存。因为是纯内存操作，Redis的性能非常出色，每秒可以处理超过 10万次读写操作，是已知性能最快的Key-Value DB。

- Redis最大的魅力是支持保存多种数据结构，此外单个value的最大限制是1GB，不像 memcached只能保存1MB的数据

Redis可以用来实现很多有用的功能，比方说用他的List来做FIFO双向链表，实现一个轻量级的高性 能消息队列服务，用他的Set可以做高性能的tag系统等等。另外Redis也可以对存入的Key-Value设置expire时间，因此也可以被当作一 个功能加强版的memcached来用。

- Redis的主要缺点是数据库容量受到物理内存的限制，不能用作海量数据的高性能读写，因此Redis适合的场景主要局限在较小数据量的高性能操作和运算上。

#### Redis的全称是什么？

Remote Dictionary Server

#### 缓存穿透可以介绍一下么？你认为应该如何解决这个问题?

#### 怎么理解强一致性、单调一致性和最终一致性？

#### 为什么缓存更新策略是先更新数据库后删除缓存

#### 你是怎么触发缓存更新的？

(比如设置超时时间(被动方式), 比如更新的时候主动update)？如果是被动的方式如何控制多个入口同时触发某个缓存更新？

#### 你们用Redis来做什么？为什么不用其他的KV存储例例如Memcached,Cassandra等?

1. memcached所有的值均是简单的字符串，redis作为其替代者，支持更为丰富的数据类型
2. redis的速度比memcached快很多
3. redis可以持久化其数据

#### 一个字符串类型的值能存储最大容量是多少？

512M

#### Redis相比memcached有哪些优势？

- memcached所有的值均是简单的字符串，redis作为其替代者，支持更为丰富的数据类型
- redis的速度比memcached快很多
- redis可以持久化其数据

#### 你们用什么Redis客户端?

Redisson、Jedis、lettuce等等，官方推荐使用Redisson。

Redisson是一个高级的分布式协调Redis客服端，能帮助用户在分布式环境中轻松实现一些Java的对象 (Bloom filter, BitSet, Set, SetMultimap, ScoredSortedSet, SortedSet, Map, ConcurrentMap, List, ListMultimap, Queue, BlockingQueue, Deque, BlockingDeque, Semaphore, Lock, ReadWriteLock, AtomicLong, CountDownLatch, Publish / Subscribe, HyperLogLog)。

#### Jedis与Redisson对比有什么优缺点？

- Jedis是Redis的Java实现的客户端，其API提供了比较全面的Redis命令的支持；
- Redisson实现了分布式和可扩展的Java数据结构，和Jedis相比，功能较为简单，不支持字符串操作，不支持排序、事务、管道、分区等Redis特性。
- Redisson的宗旨是促进使用者对Redis的关注分离，从而让使用者能够将精力更集中地放在处理业务逻辑上。

#### Redis支持哪几种数据类型？

String、List、Set、Sorted Set、hashes

#### 你熟悉哪些Redis的数据结构? zset是干什么的? 和set有什么区别?

#### 说说Redis哈希槽的概念？

Redis集群没有使用一致性hash,而是引入了哈希槽的概念，Redis集群有16384个哈希槽，每个key通过CRC16校验后对16384取模来决定放置哪个槽，集群的每个节点负责一部分hash槽。

#### Redis的hash, 存储和获取的具体命令叫什么名字?

#### LPOP和BLPOP的区别?

#### Redis的有一些包含SCAN关键字的命令是干嘛的? SCAN返回的数据量是固定的吗?

#### Redis有哪几种数据淘汰策略？

- noeviction: 返回错误当内存限制达到并且客户端尝试执行会让更多内存被使用的命令（大部分的写入指令，但DEL和几个例外）
- allkeys-lru: 尝试回收最少使用的键（LRU），使得新添加的数据有空间存放。
- volatile-lru: 尝试回收最少使用的键（LRU），但仅限于在过期集合的键,使得新添加的数据有空间存放。
- allkeys-random: 回收随机的键使得新添加的数据有空间存放。
- volatile-random: 回收随机的键使得新添加的数据有空间存放，但仅限于在过期集合的键。
- volatile-ttl: 回收在过期集合的键，并且优先回收存活时间（TTL）较短的键,使得新添加的数据有空间存放。

#### Redis中的Lua有没有使用过? 可以用来做什么? 为什么可以这么用?

#### Redis的Pipeline是用来干什么的?

#### Redis持久化大概有几种方式? aof和rdb的区别是什么? AOF有什么优缺点吗?

#### Redis Replication的大致流程是什么? bgsave这个命令的执行过程? -- 偏题

#### 如果有很多 KV数据要存储到Redis, 但是内存不足, 通过什么方式可以缩减内存? 为什么这样可以缩小内存?

#### 为什么要做Redis分区？

分区可以让Redis管理更大的内存，Redis将可以使用所有机器的内存。如果没有分区，你最多只能使用一台机器的内存。分区使Redis的计算能力通过简单地增加计算机得到成倍提升,Redis的网络带宽也会随着计算机和网卡的增加而成倍增长。

#### Redis中List, HashTable都用到了ZipList, 为什么会选择它?

#### Redis是单线程的，如何提高多核CPU的利用率？

可以在同一个服务器部署多个Redis的实例，并把他们当作不同的服务器来使用，在某些时候，无论如何一个服务器是不够的，

所以，如果你想使用多个CPU，你可以考虑一下分片（shard）

#### Redis集群方案应该怎么做？都有哪些方案？

- twemproxy，大概概念是，它类似于一个代理方式，使用方法和普通redis无任何区别，设置好它下属的多个redis实例后，使用时在本需要连接redis的地方改为连接twemproxy，它会以一个代理的身份接收请求并使用一致性hash算法，将请求转接到具体redis，将结果再返回twemproxy

使用方式简便(相对redis只需修改连接端口)，对旧项目扩展的首选。 问题：twemproxy自身单端口实例的压力，使用一致性hash后，对redis节点数量改变时候的计算值的改变，数据无法自动移动到新的节点。

- codis，目前用的最多的集群方案，基本和twemproxy一致的效果，但它支持在 节点数量改变情况下，旧节点数据可恢复到新hash节点。
- redis cluster3.0自带的集群，特点在于他的分布式算法不是一致性hash，而是hash槽的概念，以及自身支持节点设置从节点。
- 在业务代码层实现，起几个毫无关联的redis实例，在代码层，对key 进行hash计算，然后去对应的redis实例操作数据。 

这种方式对hash层代码要求比较高，考虑部分包括，节点失效后的替代算法方案，数据震荡后的自动脚本恢复，实例的监控，等等。

#### Redis扩容，失效key清理策略

#### Redis的持久化怎么做，aof和rdb，有什么区别，有什么优缺点。

- RDB持久化方式能够在指定的时间间隔能对你的数据进行快照存储.
- AOF持久化方式记录每次对服务器写的操作,当服务器重启的时候会重新执行这些命令来恢复原始的数据,AOF命令以redis协议追加保存每次写的操作到文件末尾.Redis还能对AOF文件进行后台重写,使得AOF文件的体积不至于过大.

如果你只希望你的数据在服务器运行的时候存在,你也可以不使用任何持久化方式.

你也可以同时开启两种持久化方式, 在这种情况下, 当redis重启的时候会优先载入AOF文件来恢复原始的数据,因为在通常情况下AOF文件保存的数据集要比RDB文件保存的数据集要完整.

最重要的事情是了解RDB和AOF持久化方式的不同,让我们以RDB持久化方式开始

#### Redis集群会有写操作丢失吗？为什么？

Redis并不能保证数据的强一致性，这意味这在实际中集群在特定的条件下可能会丢失写操作

#### 怎么理解Redis事务

事务是一个单独的隔离操作：事务中的所有命令都会序列化、按顺序地执行。事务在执行的过程中，不会被其他客户端发送来的命令请求所打断。

#### Redis事务相关的命令有哪几个？

MULTI、EXEC、DISCARD、WATCH

------

#### Redis实现分布式锁与Zookeeper实现分布式锁区别

#### Redis实现分布式锁思路

基于Redis实现分布式锁（setnx）setnx也可以存入key，如果存入key成功返回1，如果存入的key已经存在了，返回0.

#### Zookeeper实现分布式锁思路

同时在zookeeper上创建相同的一个临时节点，因为临时节点路径是保证唯一，只要谁能够创建节点成功，谁就能够获取到锁，没有创建成功节点，就会进行等待，当释放锁的时候，采用事件通知给客户端重新获取锁的资源。

#### 相同点

在集群环境下，保证只允许有一个jvm进行执行。

#### 不同点

- 获取锁

1. 1. 多个客户端（jvm），会在Zookeeper上创建同一个临时节点，因为Zookeeper节点命名路径保证唯一，不允许出现重复，只要谁能够先创建成功，谁能够获取到锁。
   2. 多个客户端（jvm），会在Redis使用setnx命令创建相同的一个key，因为Redis的key保证唯一，不允许出现重复，只要谁能够先创建成功，谁能够获取到锁。

- 释放锁

1. 1. Zookeeper使用直接关闭临时节点session会话连接，如果session会话连接关闭的话，该临时节点也会被删除。
   2. Redis在释放锁的时候，为了确保是锁的一致性问题，在删除的redis 的key时候，需要判断同一个锁的id，才可以删除。

- 如何解决死锁现象问题

1. 1. Zookeeper使用会话有效期方式解决死锁现象。
   2. Redis 是对key设置有效期解决死锁现象

- 性能角度考虑因为Redis是NoSQL数据库，相对比来说Redis比Zookeeper性能要好。

1. 1. Redis分布式锁，必须使用者自己间隔时间轮询去尝试加锁，当锁被释放后，存在多线程去争抢锁，并且可能每次间隔时间去尝试锁的时候，都不成功，对性能浪费很大
   2. Zookeeper分布锁，首先创建加锁标志文件，如果需要等待其他锁，则添加监听后等待通知或者超时，当有锁释放，无须争抢，按照节点顺序，依次通知使用者。

- 可靠性, Zookeeper可靠性比Redis更好。

1. 1. 因为Redis有效期不是很好控制，可能会产生有效期延迟；
   2. Zookeeper就不一样，因为Zookeeper临时节点先天性可控的有效期



### 网络相关

- [网络相关](#toc_0)

- - [TCP粘包和拆包产生的原因](#toc_1)
  - [TCP粘包和拆包的解决策略](#toc_2)
  - [三次握手](#toc_3)
  - [四次握手](#toc_4)
  - [一次完整的HTTP请求过程](#toc_5)
  - [讲一下长连接](#toc_6)

- - - [基于http协议的长连接](#toc_7)
    - [发心跳包](#toc_8)

- - [HTTP 2.0 和 1.1 区别](#toc_9)
  - [HTTPS和HTTP的区别](#toc_10)
  - [简述Http请求get和post的区别以及数据包格式](#toc_11)
  - [Https的加密方式](#toc_12)
  - [Session和cookie的区别。](#toc_13)
  - [http请求报文结构和内容](#toc_14)
  - [http三次握手和四次挥手](#toc_15)
  - [OSI有哪七层模型？TCP/IP是哪四层模型。](#toc_16)

------

#### TCP粘包和拆包产生的原因

应用程序写入数据的字节大小大于套接字发送缓冲区的大小

进行MSS大小的TCP分段。MSS是最大报文段长度的缩写。MSS是TCP报文段中的数据字段的最大长度。数据字段加上TCP首部才等于整个的TCP报文段。所以MSS并不是TCP报文段的最大长度，而是：MSS=TCP报文段长度-TCP首部长度

以太网的payload大于MTU进行IP分片。MTU指：一种通信协议的某一层上面所能通过的最大数据包大小。如果IP层有一个数据包要传，而且数据的长度比链路层的MTU大，那么IP层就会进行分片，把数据包分成托干片，让每一片都不超过MTU。注意，IP分片可以发生在原始发送端主机上，也可以发生在中间路由器上。

#### TCP粘包和拆包的解决策略

- 消息定长。例如100字节。
- 在包尾部增加回车或者空格符等特殊字符进行分割，典型的如FTP协议
- 将消息分为消息头和消息尾。
- 其它复杂的协议，如RTMP协议等。

#### 三次握手

- 第一次握手：建立连接时，客户端发送syn包(syn=j)到服务器，并进入SYN_SEND状态，等待服务器确认；
- 第二次握手：服务器收到syn包，必须确认客户的SYN（ack=j+1），同时自己也发送一个SYN包（syn=k），即SYN+ACK包，此时服务器进入SYN_RECV状态；
- 第三次握手：客户端收到服务器的SYN＋ACK包，向服务器发送确认包ACK(ack=k+1)，此包发送完毕，客户端和服务器进入ESTABLISHED状态，完成三次握手。

完成三次握手，客户端与服务器开始传送数据

#### 四次握手

- 客户端先发送FIN，进入FIN_WAIT1状态
- 服务端收到FIN，发送ACK，进入CLOSE_WAIT状态，客户端收到这个ACK，进入FIN_WAIT2状态
- 服务端发送FIN，进入LAST_ACK状态
- 客户端收到FIN，发送ACK，进入TIME_WAIT状态，服务端收到ACK，进入CLOSE状态

TIME_WAIT的状态就是主动断开的一方（这里是客户端），发送完最后一次ACK之后进入的状态。并且持续时间还挺长的。客户端TIME_WAIT持续2倍MSL时长，在linux体系中大概是60s，转换成CLOSE状态

#### 一次完整的HTTP请求过程

域名解析 --> 发起TCP的3次握手 --> 建立TCP连接后发起http请求 --> 服务器响应http请求，浏览器得到html代码 --> 浏览器解析html代码，并请求html代码中的资源（如js、css、图片等） --> 浏览器对页面进行渲染呈现给用户

#### 讲一下长连接

#### 基于http协议的长连接

在HTTP1.0和HTTP1.1协议中都有对长连接的支持。其中HTTP1.0需要在request中增加”Connection： keep-alive“ header才能够支持，而HTTP1.1默认支持.

#### 发心跳包

#### HTTP 2.0 和 1.1 区别

- 区别一：多路复用
  多路复用允许单一的 HTTP/2 连接同时发起多重的请求-响应消息。看个例子：
  ![img](https://cdn.nlark.com/yuque/0/2019/png/406432/1565343607316-fd3bd4a3-78f9-4cbf-b833-781ad149c5c4.png)
  多路复用技术：单连接多资源的方式，减少服务端的链接压力,内存占用更少,连接吞吐量更大；由于减少TCP 慢启动时间，提高传输的速度
- 区别二：首部压缩
- 区别三：HTTP2支持服务器推送

#### HTTPS和HTTP的区别

- https协议需要到CA申请证书，一般免费证书很少，需要交费。
- http是超文本传输协议，信息是明文传输；https 则是具有安全性的ssl加密传输协 议。
- http和https使用的是完全不同的连接方式，用的端口也不一样，前者是80，后者是443。
- http的连接很简单，是无状态的；HTTPS协议是由SSL+HTTP协议构建的可进行加密传输、身份认证的网络协议，比http协议安全。
- http默认使用80端口，https默认使用443端口

#### 简述Http请求get和post的区别以及数据包格式

- 两种动作不一样，get是获取资源，post是提交资源 
- get参数在URL中不安全，post是放在http body中的相对安全 
- get传输字节数受限于URL长度，post无限制 
- 后台获取数据的方式get只能是QueryString, post可从InputStream中获取 
- base64编码后有+=特殊符号的会转码不能经get传输，如果是改进的base64会替换掉特殊符号可以用get传输。

#### Https的加密方式

#### Session和cookie的区别。

#### http请求报文结构和内容

#### http三次握手和四次挥手

#### OSI有哪七层模型？TCP/IP是哪四层模型。

### 监控、稳定性

- [监控、稳定性](#toc_0)

- - [业务日志是通过什么方式来收集的？](#toc_1)
  - [线上机器如何监控？采用什么开源产品或者自研的产品？它是分钟级的还是秒级的？](#toc_2)
  - [如果让你来想办法收集一个JAVA后端应用的性能数据，你会在意哪些方面? 你会选择什么样的工具、思路来收集?](#toc_3)
  - [一般你调用第三方的时候会不会监控调用情况？](#toc_4)

------

#### 业务日志是通过什么方式来收集的？

#### 线上机器如何监控？采用什么开源产品或者自研的产品？它是分钟级的还是秒级的？

#### 如果让你来想办法收集一个JAVA后端应用的性能数据，你会在意哪些方面? 你会选择什么样的工具、思路来收集?

#### 一般你调用第三方的时候会不会监控调用情况？

### linux

- [linux](#toc_0)

------

日志特别大只想看最后100行怎么弄弄? 如果想一直看日志的持续输出，用什么命令?

2.如果日志一边输出，一边想实时看到有没有某个关键字应该怎么弄？

3.grep如果忽略大小写应该怎么弄? 正则表达式呢？

4.vim往下一行是什么键？往下30行呢? 跳到文件末尾一行是什么? 跳回来是什么? 向后搜索是什么?

5.如果有个文本文件，按空格作为列的分隔符，如果想统计第三列里面的每个单词的出现次数应该怎么弄？

6.如果把上面的出现次数排个序应该怎么弄? 想按照数字本身的顺序而不是字符串的顺序排列怎么弄？

7.Linux环境变量是以什么作为分隔符的？环境变量通过什么命令设置？

8.给某个文件权设置限比如设置为64 是用什么命令？这个6是什么意思？

9.Linux下面如果想看某个进程的资源占用情况是怎么看的？系统load大概指的什么意思？你们线上系统load一般多少？如果一个4核机器，你认为多少load是比较正常的？top命令里面按一下1会发生什么?

10.top命令里面，有时候所有进程的CPU使用率加起来超过100%是怎么回事？

11.还有哪些查看系统性能或者供你发现问题的命令？你一般是看哪个参数？

12.想看某个进程打开了哪些网络连接是什么命令？里面连接的状态你比较关心哪几种？ -- 偏题

有没有做过Linux系统参数方面的优化，大概优化过什么？

13.系统参数里面有个叫做backlog的可以用来干什么？

14.查看网络连接发现好多TIMEWAIT 可能是什么原因？对你的应用会有什么影响？你会选择什么样的方式来减少这些TIMEWAIT

15.可否介绍一下TCP三次握手的过程，如果现在有个网络程序，你用第三方的library来发送数据，你怀疑这个library发送的数据有问题，那么怎么来验证？tcpdump导出的文件你一般是怎么分析的？

16.KeepAlive是用来干什么的？这样的好处是什么？

### 算法相关

- [算法相关](#toc_0)

- - [常用排序算法](#toc_1)
  - [链表相关](#toc_2)
  - [数组相关](#toc_3)
  - [字符串相关](#toc_4)
  - [树相关](#toc_5)
  - [TopK](#toc_6)
  - [有1亿个数字，其中有2个是重复的，快速找到它，时间和空间要最优](#toc_7)

#### 常用排序算法

二分查找

#### 链表相关

- 合并多个单有序链表（假设都是递增的）

#### 数组相关

#### 字符串相关

#### 树相关

#### TopK

- 10亿个数字里里面找最小的10个

#### 有1亿个数字，其中有2个是重复的，快速找到它，时间和空间要最优

10亿个数字里里面找最小的10个。

有1亿个数字，其中有2个是重复的，快速找到它，时间和空间要最优。

2亿个随机生成的无序整数,找出中间大小的值。

给一个不知道长度的（可能很大）输入字符串，设计一种方案，将重复的字符排重。

遍历二叉树。

有3n+1个数字，其中3n个中是重复的，只有1个是不重复的，怎么找出来。

写一个字符串（如：www.javastack.cn）反转函数。

常用的排序算法，快排，归并、冒泡。 快排的最优时间复杂度，最差复杂度。冒泡排序的

优化方案。

二分查找的时间复杂度，优势。

一个已经构建好的TreeSet，怎么完成倒排序。

什么是B+树，B-树，列出实际的使用场景。

一个单向链表，删除倒数第N个数据。

200个有序的数组，每个数组里面100个元素，找出top20的元素。

单向链表，查找中间的那个元素

### 大数据

#### Hadoop

- Hadoop是什么
- 介绍下HDFS

- - HDFS 优缺点
  - [HDFS 的特点](https://github.com/wangzhiwubigdata/God-Of-BigData/blob/master/大数据框架学习/Hadoop-HDFS.md#三HDFS-的特点)

- - - [高容错](https://github.com/wangzhiwubigdata/God-Of-BigData/blob/master/大数据框架学习/Hadoop-HDFS.md#31-高容错)
    - [高吞吐量](https://github.com/wangzhiwubigdata/God-Of-BigData/blob/master/大数据框架学习/Hadoop-HDFS.md#32-高吞吐量)
    - [大文件支持](https://github.com/wangzhiwubigdata/God-Of-BigData/blob/master/大数据框架学习/Hadoop-HDFS.md#33--大文件支持)
    - [简单一致性模型](https://github.com/wangzhiwubigdata/God-Of-BigData/blob/master/大数据框架学习/Hadoop-HDFS.md#33-简单一致性模型)
    - [跨平台移植性](https://github.com/wangzhiwubigdata/God-Of-BigData/blob/master/大数据框架学习/Hadoop-HDFS.md#34-跨平台移植性)

- - HDFS 组成架构
  - HDFS文件大小默认是多少，如何设置
  - HDFS文件大小为什么不能设置太大或太小
  - [文件系统命名空间](https://github.com/wangzhiwubigdata/God-Of-BigData/blob/master/大数据框架学习/Hadoop-HDFS.md#22-文件系统命名空间)
  - [数据复制及实现原理](https://github.com/wangzhiwubigdata/God-Of-BigData/blob/master/大数据框架学习/Hadoop-HDFS.md#24-数据复制的实现原理)
  - [副本的选择](https://github.com/wangzhiwubigdata/God-Of-BigData/blob/master/大数据框架学习/Hadoop-HDFS.md#25--副本的选择)
  - [架构的稳定性](https://github.com/wangzhiwubigdata/God-Of-BigData/blob/master/大数据框架学习/Hadoop-HDFS.md#26-架构的稳定性)

- - - [心跳机制和重新复制](https://github.com/wangzhiwubigdata/God-Of-BigData/blob/master/大数据框架学习/Hadoop-HDFS.md#1-心跳机制和重新复制)
    - [数据的完整性](https://github.com/wangzhiwubigdata/God-Of-BigData/blob/master/大数据框架学习/Hadoop-HDFS.md#2-数据的完整性)
    - [元数据的磁盘故障](https://github.com/wangzhiwubigdata/God-Of-BigData/blob/master/大数据框架学习/Hadoop-HDFS.md#3元数据的磁盘故障)
    - [支持快照](https://github.com/wangzhiwubigdata/God-Of-BigData/blob/master/大数据框架学习/Hadoop-HDFS.md#4支持快照)

#### Hive

#### Spark

**Spark Core :**

1. [Spark 简介](https://github.com/wangzhiwubigdata/God-Of-BigData/blob/master/大数据框架学习/Spark简介.md)
2. [弹性式数据集 RDD](https://github.com/wangzhiwubigdata/God-Of-BigData/blob/master/大数据框架学习/Spark_RDD.md)
3. [RDD 常用算子详解](https://github.com/wangzhiwubigdata/God-Of-BigData/blob/master/大数据框架学习/Spark_Transformation和Action算子.md)
4. [Spark 运行模式与作业提交](https://github.com/wangzhiwubigdata/God-Of-BigData/blob/master/大数据框架学习/Spark部署模式与作业提交.md)
5. [Spark 累加器与广播变量](https://github.com/wangzhiwubigdata/God-Of-BigData/blob/master/大数据框架学习/Spark累加器与广播变量.md)

**Spark SQL :**

1. [DateFrame 和 DataSet](https://github.com/wangzhiwubigdata/God-Of-BigData/blob/master/大数据框架学习/SparkSQL_Dataset和DataFrame简介.md)
2. [Structured API 的基本使用](https://github.com/wangzhiwubigdata/God-Of-BigData/blob/master/大数据框架学习/Spark_Structured_API的基本使用.md)
3. [Spark SQL 外部数据源](https://github.com/wangzhiwubigdata/God-Of-BigData/blob/master/大数据框架学习/SparkSQL外部数据源.md)
4. [Spark SQL 常用聚合函数](https://github.com/wangzhiwubigdata/God-Of-BigData/blob/master/大数据框架学习/SparkSQL常用聚合函数.md)
5. [Spark SQL JOIN 操作](https://github.com/wangzhiwubigdata/God-Of-BigData/blob/master/大数据框架学习/SparkSQL联结操作.md)

**Spark Streaming ：**

1. [Spark Streaming 简介](https://github.com/wangzhiwubigdata/God-Of-BigData/blob/master/大数据框架学习/Spark_Streaming与流处理.md)
2. [Spark Streaming 基本操作](https://github.com/wangzhiwubigdata/God-Of-BigData/blob/master/大数据框架学习/Spark_Streaming基本操作.md)

#### Flink

1. [Flink 核心概念综述](https://github.com/wangzhiwubigdata/God-Of-BigData/blob/master/大数据框架学习/Flink核心概念综述.md)
2. [Flink Data Source](https://github.com/wangzhiwubigdata/God-Of-BigData/blob/master/大数据框架学习/Flink_Data_Source.md)
3. [Flink Data Transformation](https://github.com/wangzhiwubigdata/God-Of-BigData/blob/master/大数据框架学习/Flink_Data_Transformation.md)
4. [Flink Data Sink](https://github.com/wangzhiwubigdata/God-Of-BigData/blob/master/大数据框架学习/Flink_Data_Sink.md)
5. [Flink 窗口模型](https://github.com/wangzhiwubigdata/God-Of-BigData/blob/master/大数据框架学习/Flink_Windows.md)
6. [Flink 状态管理与检查点机制](https://github.com/wangzhiwubigdata/God-Of-BigData/blob/master/大数据框架学习/Flink状态管理与检查点机制.md)

#### Hbase

1. [Hbase 简介](https://github.com/wangzhiwubigdata/God-Of-BigData/blob/master/大数据框架学习/Hbase简介.md)
2. [HBase 系统架构及数据结构](https://github.com/wangzhiwubigdata/God-Of-BigData/blob/master/大数据框架学习/Hbase系统架构及数据结构.md)
3. [HBase 常用 Shell 命令](https://github.com/wangzhiwubigdata/God-Of-BigData/blob/master/大数据框架学习/Hbase_Shell.md)
4. [HBase Java API](https://github.com/wangzhiwubigdata/God-Of-BigData/blob/master/大数据框架学习/Hbase_Java_API.md)

### web开发安全

- [web开发安全](#toc_0)
- [主流web漏洞](#toc_1)
- [csrf 攻击](#toc_2)
- [xss 攻击](#toc_3)
- [SQL 注入](#toc_4)
- [URL跳转漏洞](#toc_5)
- [什么是DoS、DDoS、DRDoS攻击？如何防御？](#toc_6)

------

#### 主流web漏洞

![img](https://cdn.nlark.com/yuque/0/2019/png/406432/1565344289364-8c9fc4f0-7445-446d-a8d5-0cdb76599735.png)

#### csrf 攻击

CSRF（Cross-site request forgery）跨站请求伪造，也被称为“One Click Attack”或者Session Riding，通常缩写为CSRF或者XSRF，是一种对网站的恶意利用。但它与XSS非常不同，XSS利用站点内的信任用户，而CSRF则通过伪装成受信任用户的请求来利用受信任的网站。与XSS攻击相比，CSRF攻击往往不大流行（因此对其进行防范的资源也相当稀少）和难以防范，所以被认为比XSS更具危险性。

[浅谈CSRF攻击方式](https://www.cnblogs.com/hyddd/archive/2009/04/09/1432744.html)

![img](https://cdn.nlark.com/yuque/0/2019/png/406432/1565344298809-05ddd5cc-6dd6-4c60-bda9-a45919a192d1.png)

#### xss 攻击

[Cross-Site Scripting](https://segmentfault.com/a/1190000016551188)（跨站脚本攻击）简称 XSS，是一种代码注入攻击。攻击者通过在目标网站上注入恶意脚本，使之在用户的浏览器上运行。利用这些恶意脚本，攻击者可获取用户的敏感信息如 Cookie、SessionID 等，进而危害数据安全。

- 在 HTML 中内嵌的文本中，恶意内容以 script 标签形成注入。
- 在内联的 JavaScript 中，拼接的数据突破了原本的限制（字符串，变量，方法名等）。
- 在标签属性中，恶意内容包含引号，从而突破属性值的限制，注入其他属性或者标签。
- 在标签的 href、src 等属性中，包含 javascript: 等可执行代码。
- 在 onload、onerror、onclick 等事件中，注入不受控制代码。
- 在 style 属性和标签中，包含类似 background-image:url("javascript:..."); 的代码（新版本浏览器已经可以防范）。
- 在 style 属性和标签中，包含类似 expression(...) 的 CSS 表达式代码（新版本浏览器已经可以防范）。

XSS 分类

| 类型       | 存储区*                 | 插入点*         |
| ---------- | ----------------------- | --------------- |
| 存储型 XSS | 后端数据库              | HTML            |
| 反射型 XSS | URL                     | HTML            |
| DOM 型 XSS | 后端数据库/前端存储/URL | 前端 JavaScript |

#### SQL 注入

#### URL跳转漏洞

#### 什么是DoS、DDoS、DRDoS攻击？如何防御？





#### 消息中间件

目前在使用的消息中间件是RocketMQ和kafka



- Rocket 特点

RocketMQ是一个分布式消息和流处理平台，具有低延迟，高性能和高可靠性，亿万级容量和灵活的可扩展性。它由四部分组成：名称服务器，代理服务器，生产者和消费者。它们中的每一个都可以水平扩展，而不会出现单点故障。



- Kafka 特点

支持消息的发布和订阅，这个和RocketMq类似；支持数据实时处理；能保证消息的可靠性投递；支持消息的持久化存储，并通过多副本分布式的存储方案来保证消息的容错；高吞吐率，单 Broker 可以轻松处理数千个分区以及每秒百万级的消息量。



- Rocket和Kafka的区别

| 比较项                 | RocketMq                        | Kafka                             |
| ---------------------- | ------------------------------- | --------------------------------- |
| **顺序消息**           | 确保分区内的消息的顺序          | 确保严格的消息顺序,并能优雅的扩展 |
| **定时消息**           | 不支持                          | 支持                              |
| **批量消息**           | 支持,异步生产                   | 支持,使用同步的模式以避免消息丢失 |
| **广播消息**           | 不支持                          | 支持                              |
| **消息过滤**           | 支持, 可以使用Kafka流来筛选消息 | 支持,基于SQL92的属性筛选表达式    |
| **服务器端触发的重试** | 不支持                          | 支持                              |
| **消息存储**           | 高性能存储                      | 高性能和低延迟文件存储            |
| **消息可追溯**         | 支持                            | 支持,时间戳和偏移量               |
| **消息优先级**         | 不支持                          | 不支持                            |
| **管理和操作工具**     | 支持,通过终端命令可以进行配置   | 开箱即用, 用户只需要注意一些配置  |
|                        |                                 |                                   |



- 具体指导

中台应用间的业务消息都是通过RocketMQ来进行，一般性的应用消息通过RocketMQ来进行，RocketMQ对业务消息提供了更高的可用性、管理方便、使用上可以按Topic进行筛选等特点。

但结合业务特点，比较计量数据， 需要进行高速大批量进行写入和消费，消费方固定，但对实时顺序性等要求没有那么高的可以考虑kafka



#### NoSQL数据库

- 目前中台在使用的NoSQL数据库主要有

1. HBase
2. MongoDB

3. ElasticSearch
4. Redis



- HBase



Hbase，是一个高可靠、高性能、可伸缩的分布式数据库。Hbase参考了谷歌的BigTable建模，使用HDFS作为底层存储。使用Zookeeper作为协同服务组件。



可以提供数据的实时随机读写的NoSQL数据库，他的特点如下：

1.  Hbase的表没有固定的字段定义
2.  Hbase的表中每行存储的都是一些key-value对

3.  Hbase的表中有列族的划分，用户可以指定将哪些kv插入哪个列族
4.  Hbase的表在物理存储上，是按照列族来分割的，不同列族的数据一定存储在不同的文件中

5.  Hbase的表中的每一行都固定有一个行键，而且每一行的行键在表中不能重复
6.  Hbase中的数据，包含行键，包含key，包含value，都是byte[ ]类型，hbase不负责为用户维护数据类型

7.  HBASE对事务的支持很差

HBASE相比于其他nosql数据库(mongodb、redis、cassendra、hazelcast)的特点：

1. Hbase的表数据存储在HDFS文件系统中
2. 存储容量可以线性扩展； 数据存储的安全性可靠性极高！



***如果要使用HBase，对于数据的RowKey怎么设计需要慎重考虑，RowKey的设计会极大的影响后续的业务便利性，而且一段设计定型了，后续也很难更改。\***



- MongoDB







- ElasticSearch

ES特性：是一个**分布式、可扩展、实时的搜索与数据分析引擎**。

1. **全文搜索**
2. **结构化数据的实时统计**

3. **数据分析**
4. **复杂的人类语言处理**

5. **地理位置和对象间关联关系**等



ES特点（有点）：

1. 速度快：当数据量到达千万级以上的时候，关系型数据库单表无论是通过增加索引、分库分表来优化，最终能够优化的效果往往不如人意（且分库分表复杂度较高），而ES可以轻松hold住千万、亿级数据量。
2. 不只是全文检索：在传统关系型数据库中，我们很多使用需要采用模糊查询的方式来获取想要的数据，LIKE '%检索项%'，  SQL不会走索引的（不符合最左前缀原则），将执行全表扫描，性能很差。 但在ES中实现上述的查询则很简单，可以实时的查询到想要的结果。





- Redis

Redis是一个高性能的(key/value)分布式内存数据库，基于内存运行并支持持久化的NoSQL数据库。value的数据类型支持主要有 String、List、Hash、Set、ZSet 这5种。



Redis的应用场景主要有:

1. String

1. 1. 取最新N个数据的操作如：可以将最新的10条评论的ID放在Redis的List集合里面
   2. 模拟类似于HttpSession这种需要设定过期时间的功能

1. 1. 缓存： Redis提供了键过期功能，也提供了灵活的键淘汰策略
   2. 计数器：什么是计数器，如电商网站商品的浏览量、视频网站视频的播放数等

1. 1. 分布式锁 ： 可以利用Redis的setnx功能来编写分布式的锁，如果设置返回1说明获取锁成功，否则获取锁失败
   2. 分布式Session

1. 1. 限流

1. Hash

1. 1. 存储用户信息
   2. 用户主页访问量

1. 1. 组合查询

1. List：微博关注人时间轴列表、简单队列

1. 1. Redis提供的有序集合数据类构能实现各种复杂的排行榜应用

1. Set

1. 1. 赞、踩
   2. 标签

1. 1. 好友关系

1. Zset：排行榜



- 定时任务使用场景

1. 定时备份数据
2. 业务（订单）超时自动取消

3. 业务（订单）失败后的定时重试
4. 按时间段统计信息

5. 业务定期（优惠券要过期）给用户发送提醒消息等。



#### 定时任务



- 定时任务的基本概念

执行器：负责执行任务。

调度器：根据配置（cron表达式）详情，告知执行器去执行任务

任务：自己的业务实现，比如优惠券要过期给用户发送一个提醒。



- 使用xxl-job任务需要注意的地方

1. 定时任务是靠机器按crob表达式进行调度的，都是有一定的的延迟，如果有一个业务要求12:00分生效，理想情况下也会有几秒的延迟，不可能12:00准时生效。
2. xxl-job只是一个触发入口，具体的实现时需要业务来处理的。

3. 对耗时严重的任务，建议仅仅通过xxl-job进行触发，触发后以异步方式执行，不要占用xxl-job的链接资源。
4. 对大批量的任务，最好结合MQ队列一起来处理。



xxl-job接入指南 ：https://qianxun.yuque.com/ddad5m/ykumxg/kgb6h9



#### 缓存中间件



开发过程中经常性的需要对数据进行缓存，常用的缓存技术手段基本有下面几个

1. 无外部依赖的，jdk自身提供的 HashMap/ConcurrentHashMap
2. 单机缓存管理，简单引入jar包的guava

3. 分布式缓存管理，使用redis，memcache等



这里重点强调下使用分布式缓存的选型，为了提高大家的编码效率，编码一致性，缓存的统一处理框架推荐使用JetCache：

https://github.com/alibaba/jetcache

https://github.com/alibaba/jetcache/wiki/Home_CN





#### 性能设计

1. 性能指标分解

  系统性能指标

  子系统性能指标



2. 性能监控

  是否需要性能方面的监控，如过需要，请给出明确的监控指标项。

3. 限流和降级

  限流和降级是否需要，策略，及使用的技术方案。

4. 性能相关设计策略与性能需求的映射关系



5. 架构设计阶段提前做好快速定位性能问题或故障的预案。SkyWalking作为默认需要接入的。

​    对请求的各个环节、链路进行分析，找到可能出现瓶颈的地方，是前端需要优化，还是后端服务需要优化，还是存储需要优化。





# 应用性能设计原则



## 1.考虑使用分布式缓存原则

1.1设计cache集群化部署，集中更新缓存带来性能和资源开销；如果cache失效，大量请求命中DB带来服务性能雪崩，避免丢失过多数据造成服务压力陡增。避免单点问题，提供更加高可用，高性能的服务。

1.2 设计热点数据进行预热加载：高峰期来临前，将热点数据提前存入缓存，提高高峰期的服务性能。

1.3 不存在的数据并定期清理：防止查询不到，导致cache无法命中而频繁访问DB的场景

1.4 分布式缓存集中管理，保证可扩展性，降低系统复杂度



## 2.考虑异步化设计原则

通过分布式消息队列来实现削峰的目的，通过业务配合技术来解决问题。一般合理使用消息队列，可有效抵御促销活动大量涌入的订单对系统造成的冲击



## 3. 考虑集群策略原则

使用负载均衡技术为一个应用构建一个由多台服务器组成的服务器集群，将并发请求分发到多台服务器上处理，避免单一服务器因负载压力过大而响应缓慢，使用户请求具有更好的响应延迟特性



## 4.代码性能优化原则

4.1 多线程中的密集型计算：线程数不宜超过CPU核数。如果是IO处理，则线程数=[任务执行时间/(任务执行时间-IO等待时间)] * CPU核数

4.2将对象设计成无状态对象，多采用局部对象，并发访问资源时使用锁

4.3 资源复用原则：系统运行时，尽量减少那些开销很大的资源的创建和销毁

4.4合理设置JVM参数，以最大程度避免不合理的full gc



## 5.存储性能优化原则

5.1 硬件选择——机械硬盘VS固态硬盘

5.2 B+树 vs LSM树（数据结构）：关系型数据库的索引采用B+树进行实现，nosql数据库采用了LSM树进行存储。所以对于读写操作较多，LSM树其性能远高于b+树

5.3 存储和备份方式选择（RAID vs HDFS），采用HDFS结合map reduce进行海量数据存储和分析，能自动进行并发访问和冗余备份，具有很高的可靠性



# 一致性

在业务系统中，数据一致性非常的重要，总体上说，有2种方式来保证一致性

- 事务性的强一致性
- 数据的最终一致性



- 事务性的强一致性

事务性的强一致，实施的代价比较高，基本局限于服务应用内部，并且一个应用如果事务太多，比如降低并发性，增加数据库的负载；如果在分布式情况下，要实现事务一致性，还需要引入复杂的分布式事务解决方案；所以，不建议一般的业务系统采用事务一致性方案，只对资金类要求很严格的业务有限使用。



- 数据的最终一致性

数据的最终一致性，需要处理好几个问题

1. 业务调用的幂等处理
2. 业务失败的重试（补偿）处理

3. 业务异步处理的握手处理
4. 数据不一致的检测和报警



前3个步骤是保证一致性的关键，需要开发在开发过程中重点把握；第4个步骤是事后止损措施。



要求：

- 明确系统内部哪些数据需要一致
- 明确系统和外部系统之间哪些数据需要保持数据一致性

- 保证数据一致的策略和实现方式



# 可靠性

**I.避免单点（重要）**：集群+LB、容器化部署(k8s的编排管理保证了pod的数量和健康,并且支持弹性伸缩、滚动升级)

**II.熔断**：快速失败，避免服务雪崩，保护整个服务链路；（dubbo+hystrix）

**III.降级**： 不同的业务采用不同的降级逻辑，保证核心服务的正常运行；（在dubbo消费端可以配置mock对调用进行降级）

**IV.限流**： 防止流量超出系统所能承受的阈值；（sentinel）

**V.缓存**： 避免同一时间大量请求直接落到数据库，将数据库击垮；（本地缓存、分布式缓存）

**VI.超时和重试机制**： 设置超时时间避免请求堆积，重试避免偶尔的网络抖动；（配置dubbo的timeout和retry次数，注意服务接口的幂等）



## 一、什么时候需要读写分离？



- 高频读，低频写
- 读请求单节点数据库性能难以支撑（通常每秒QPS吞吐量可能超过3w，IOPS超过2w，建议考虑）

- 读请求有弹性伸缩的要求（是否需要高峰扩容，闲时回收）
- 缓存存在的情况下，仍旧可能因为命中率，首次加载等场景，存在集中查询的场合



## 二、读写分离前提



- 对主从同步导致性能的少量下降有一定的容忍性（性能：同步复制<半同步复制<异步复制）
- 对主从分离的数据可见性延迟有一定的容忍性

- 对业务中读取后更新等场景有严格的把控评估和解决方案
- 对代码中可读写分离的功能有明确的把控

- 事务中查询不应读写分离
- 读写分离可能加剧业务脏写问题，因此从根本上规避此类问题接入读写分离的系统应当有数据写入一致性方案，例如version版本控制



## 三、读写分离方案



1. 阿里云数据库读写分离方案：

https://help.aliyun.com/document_detail/96073.html?spm=a2c4g.11186623.2.13.54582e9bkHFr2j#concept-ptl-fl4-wdb



1. ShardingJDBC及ShardingProxy：

https://shardingsphere.apache.org/document/current/en/features/replica-query/



1. 业务系统实现可控读写分离

自行实现`



## 四、方案比较

|               | 阿里云数据库读写分离                                         | 数据库中间件    | 业务系统实现读写分离                     |
| ------------- | ------------------------------------------------------------ | --------------- | ---------------------------------------- |
| 部署方式      | 仅公有云                                                     | 公有云/专有云   | 公有云/专有云                            |
| 代码耦合      | 无侵入/标记侵入                                              | 无侵入/标记侵入 | 标记侵入/强耦合                          |
| 可控性        | 自动分发：代理层通过SELECT及UPDATE关键字自动分发，业务不可控标记分发：通过force hint标记分发控制，对业务有侵入控制 | 同左            | 业务完全控制，指定本次查询是读库或者写库 |
| 事务          | 不支持事务                                                   | 不支持事务      | 不支持事务                               |
| 可用区/多中心 | 不支持，读写节点不可跨可用区                                 | 支持            | 支持                                     |



## 一、什么时候需要分库分表

- 预估单表记录数大于500w，且可能持续增长
- 预估单库容量大于1TB，且可能持续增长

- 预估单库或者单表存在读写热点问题，尤其是写热点问题
- 预估存在多中心场合



## 二、分库分表的作用

- 水平扩展，理论上数据库容量无限扩展
- 热点分散，合理设计分表，缓解单表中频繁访问，行锁及I/O争抢的问题

- 易于维护，单表DDL可操作，不因为表体积过大导致无法维护
- 提升性能，相较大体积表，即使表上出现skip等耗时操作，仍旧可以等待响应，不至于挂起

- 多中心部署技术路径必须项



## 三、分库分表方案

### 1. 设计分片键及分片策略

1. 1. 考虑最频繁查询业务字段，且全局唯一（真正的全局唯一，支持多中心架构）
   2. 分片策略下，预估单表容量大小

1. 1. 分片策略下，预估单表查询热度



### 2. 动态分片 or 静态分片

|          | 静态分片                                                     | 动态分片                                                   |
| -------- | ------------------------------------------------------------ | ---------------------------------------------------------- |
| 分片算法 | Hash等取模法                                                 | 时间片算法，雪花算法，范围算法，检索表等                   |
| 节点数   | 预设固定                                                     | 执行中可变                                                 |
| 节点变化 | 成本极大，需数据迁移重排                                     | 可适应算法变更                                             |
| 单点查询 | 性能极好                                                     | 根据算法不同，理论上最好情况可达静态分片同等性能           |
| 跨表查询 | 少量分片无需构建索引表分片数较多需要构建索引表或者其他数据整合方案 | 需要构建动态索引表或者其他数据整合方案                     |
| 跨库分片 | 跨库算法和跨表算法可以与业务无关                             | 跨库算法和跨表算法需要根据业务设计                         |
| 维护性   | 较差，无法直观获知数据位于哪个分片中                         | 可设计，可以通过算法将分片信息维护于分片键本身或者检索表中 |



### 3. 跨表业务查询方案设计

需要考虑业务跨表数据连接、查询和排序等场景。设计全局静态索引表，或者数据聚合查询方案（例如ElasticSearch等）



### 4. 维护可行性

- 数据迁移可行性
- 分片重排可行性

- 数据聚合可行性

### 

## 四、可执行参考方案

### 1. 阿里云集群数据库

#### 1.1 PolarDB

PolarDB是阿里云提供的基于计算与存储分离理念设计的原生关系型数据库，其已经提供了大容量存储及读写分离特性，支持最大容量100T，16个计算节点，每节点最高88vCPU（理论值）。

可参考：https://www.aliyun.com/product/polardb?spm=5176.13910061.J_8058803260.128.467830f1cXm7rR



#### 1.2 PolarDB-X（原DRDS，水平分片型）

PolarDB-X是阿里云提供的基于DRDS分布式SQL模型以及X-DB分布式存储设计的云分布式原生关系型数据库，支持PB级存储，峰值8700wTPS（理论值），基于Paxos一致性协议确保跨可用区数据一致性。

可参考：https://www.aliyun.com/product/drds?spm=5176.155538.J_8058803260.129.59baee1fsN3PbW



### 2. 分库分表中间件

#### 2.1 ShardingJDBC 

可参考：https://shardingsphere.apache.org/document/current/en/overview/#shardingsphere-jdbc

#### 2.2 ShardingProxy

可参考：https://shardingsphere.apache.org/document/current/en/overview/#shardingsphere-proxy



|          | shardingJDBC                                     | shardingProxy                          |
| -------- | ------------------------------------------------ | -------------------------------------- |
| 架构     | 分布式无状态设计                                 | 中心式有状态设计                       |
| 性能     | 本地执行，静态算法，性能较好                     | 云服务管理，代理模式，多一跳，性能稍差 |
| 可靠性   | 无单点故障                                       | 有单点故障                             |
| 可运维性 | 节点变更、路由切换存在一致性风险（根据算法决定） | 节点变更代理统一管理，算法保障一致性   |
| 编码     | 引入jar包，配置数据                              | 需要部署独立进程                       |



### 3. 业务定制化分库分表（不推荐）

在一些特殊场合下，可以考虑业务引入定制化分库分表策略。

优点：

1. 1. 数据分布贴近业务，可以最合理设计
   2. 性能可定制

1. 1. 数据可视性较好

缺点：

1. 1. 可运维性差
   2. 需要人力维护成本

1. 1. 后期变更需要完全定制





#### 监控报警



监控事项分为服务监控，业务监控，性能监控。

每类监控需要明确：

- 监控项（服务状态，业务埋点，性能指标等）
- 监控的实现方式（skywalking，metric，日志等）

- 感知方式

- - 定期查看监控页面
  - 报警通知

- - - 报警阈值，通知方式，通知频次等