## 花旗面经

#### API的安全性怎么保障？

1. HTTP 请求中的来源识别

2. 数据加密
3. 数据签名

4. 时间戳
5.  AppID

6. 参数整体加密

#### 对外[API](https://so.csdn.net/so/search?q=API&spm=1001.2101.3001.7020)接口的安全性设计及鉴权方式

- - [API鉴权方式](https://blog.csdn.net/qq_35524157/article/details/116494536#API_6)
  - - [API Key + API Secret实现API鉴权](https://blog.csdn.net/qq_35524157/article/details/116494536#API_Key__API_SecretAPI_9)
    - [Cookie + Session实现API鉴权](https://blog.csdn.net/qq_35524157/article/details/116494536#Cookie__SessionAPI_22)
    - [token机制实现API鉴权](https://blog.csdn.net/qq_35524157/article/details/116494536#tokenAPI_49)
  - [API接口的安全措施](https://blog.csdn.net/qq_35524157/article/details/116494536#API_63)
  - - [数据加密](https://blog.csdn.net/qq_35524157/article/details/116494536#_67)
    - [数据签名](https://blog.csdn.net/qq_35524157/article/details/116494536#_78)
    - [添加时间戳](https://blog.csdn.net/qq_35524157/article/details/116494536#_84)
    - [限流机制](https://blog.csdn.net/qq_35524157/article/details/116494536#_88)
    - [黑名单机制](https://blog.csdn.net/qq_35524157/article/details/116494536#_94)
    - [数据合法性校验](https://blog.csdn.net/qq_35524157/article/details/116494536#_98)

#### URL请求的整个流程 

1、DNS解析

2、TCP连接

3、发送HTTP请求

4、服务器处理请求并返回HTTP报文

5、浏览器解析渲染页面

6、连接结束

#### HTTP和 HTTPS

**HTTP**（HyperText Transfer Protocol：超文本传输协议）是一种用于分布式、协作式和超媒体信息系统的应用层协议。 简单来说就是一种发布和接收 HTML 页面的方法，被用于在 Web 浏览器和网站服务器之间传递信息。

HTTP 默认工作在 TCP 协议 80 端口，用户访问网站 **http://** 打头的都是标准 HTTP 服务。

HTTP 协议以明文方式发送内容，不提供任何方式的数据加密，如果攻击者截取了Web浏览器和网站服务器之间的传输报文，就可以直接读懂其中的信息，因此，HTTP协议不适合传输一些敏感信息，比如：信用卡号、密码等支付信息。

**HTTPS**（Hypertext Transfer Protocol Secure：超文本传输安全协议）是一种透过计算机网络进行安全通信的传输协议。HTTPS 经由 HTTP 进行通信，但利用 SSL/TLS 来加密数据包。HTTPS 开发的主要目的，是提供对网站服务器的身份认证，保护交换数据的隐私与完整性。

HTTPS 默认工作在 TCP 协议443端口，它的工作流程一般如以下方式：

- 1、TCP 三次同步握手
- 2、客户端验证服务器数字证书
- 3、DH 算法协商对称加密算法的密钥、hash 算法的密钥
- 4、SSL 安全加密隧道协商完成
- 5、网页以加密的方式传输，用协商的对称加密算法和密钥加密，保证数据机密性；用协商的hash算法进行数据完整性保护，保证数据不被篡改。

#### HTTP 与 HTTPS 区别

- HTTP 明文传输，数据都是未加密的，安全性较差，HTTPS（SSL+HTTP） 数据传输过程是加密的，安全性较好。
- 使用 HTTPS 协议需要到 CA（Certificate Authority，数字证书认证机构） 申请证书，一般免费证书较少，因而需要一定费用。证书颁发机构如：Symantec、Comodo、GoDaddy 和 GlobalSign 等。
- HTTP 页面响应速度比 HTTPS 快，主要是因为 HTTP 使用 TCP 三次握手建立连接，客户端和服务器需要交换 3 个包，而 HTTPS除了 TCP 的三个包，还要加上 ssl 握手需要的 9 个包，所以一共是 12 个包。
- http 和 https 使用的是完全不同的连接方式，用的端口也不一样，前者是 80，后者是 443。
- HTTPS 其实就是建构在 SSL/TLS 之上的 HTTP 协议，所以，要比较 HTTPS 比 HTTP 要更耗费服务器资源。

#### TCP和UDP的区别

**参考回答**

  TCP和UDP有如下区别：

1. 连接：TCP面向连接的传输层协议，即传输数据之前必须先建立好连接；UDP无连接。
2. 服务对象：TCP点对点的两点间服务，即一条TCP连接只能有两个端点；UDP支持一对一，一对多，多对一，多对多的交互通信。
3. 可靠性：TCP可靠交付：无差错，不丢失，不重复，按序到达；UDP尽最大努力交付，不保证可靠交付。
4. 拥塞控制/流量控制：有拥塞控制和流量控制保证数据传输的安全性；UDP没有拥塞控制，网络拥塞不会影响源主机的发送效率。
5. 报文长度：TCP动态报文长度，即TCP报文长度是根据接收方的窗口大小和当前网络拥塞情况决定的；UDP面向报文，不合并，不拆分，保留上面传下来报文的边界。
6. 首部开销：TCP首部开销大，首部20个字节；UDP首部开销小，8字节（源端口，目的端口，数据长度，校验和）。
7. 适用场景（由特性决定）：数据完整性需让位于通信实时性，则应该选用TCP 协议（如文件传输、重要状态的更新等）；反之，则使用 UDP 协议（如视频传输、实时通信等）。

#### Cookie和Session的区别

(1)cookie数据存放在客户的浏览器上，session数据放在服务器上
(2)cookie不是很安全，别人可以分析存放在本地的COOKIE并进行COOKIE欺骗,如果主要考虑到安全应当使用session
(3)session会在一定时间内保存在服务器上。当访问增多，会比较占用你服务器的性能，如果主要考虑到减轻服务器性能方面，应当使用COOKIE
(4)单个cookie在客户端的限制是3K，就是说一个站点在客户端存放的COOKIE不能3K。
(5)所以：将登陆信息等重要信息存放为SESSION;其他信息如果需要保留，可以放在COOKIE中

#### TCP是怎么控制流量的？

**参考回答**

1. 所谓**流量控制**就是让发送发送速率不要过快，让接收方来得及接收。

2. TCP控制流量的方法

     利用**滑动窗口机制**就可以实施流量控制。

     **原理**就是运用TCP报文段中的窗口大小字段来控制，发送方的发送窗口不可以大于接收方发回的窗口大小。考虑一种特殊的情况，就是接收方若没有缓存足够使用，就会发送零窗口大小的报文，此时发送放将发送窗口设置为0，停止发送数据。之后接收方有足够的缓存，发送了非零窗口大小的报文，但是这个报文在中途丢失的，那么发送方的发送窗口就一直为零导致死锁。

      解决这个问题，TCP为每一个连接设置一个持续计时器（persistence timer）。只要TCP的一方收到对方的零窗口通知，就启动该计时器，周期性的发送一个零窗口探测报文段。对方就在确认这个报文的时候给出现在的窗口大小（注意：TCP规定，即使设置为零窗口，也必须接收以下几种报文段：零窗口探测报文段、确认报文段和携带紧急数据的报文段）。

 TCP协议保证数据传输可靠性的方式主要有：**校验和、序列号、确认应答、超时重传、连接管理、流量控制、拥塞控制**。

#### TCP 三次握手

- 第一次握手：客户端尝试连接服务器，向服务器发送 syn 包（同步序列编号Synchronize Sequence Numbers），syn=j，客户端进入 SYN_SEND 状态等待服务器确认
- 第二次握手：服务器接收客户端syn包并确认（ack=j+1），同时向客户端发送一个 SYN包（syn=k），即 SYN+ACK 包，此时服务器进入 SYN_RECV 状态
- 第三次握手：第三次握手：客户端收到服务器的SYN+ACK包，向服务器发送确认包ACK(ack=k+1），此包发送完毕，客户端和服务器进入ESTABLISHED状态，完成三次握手

#### tcp的四次挥手

1. 客户端进程发出连接释放报文，并且停止发送数据。释放数据报文首部，FIN=1，其序列号为seq=u（等于前面已经传送过来的数据的最后一个字节的序号加1），此时，客户端进入FIN-WAIT-1（终止等待1）状态。 TCP规定，FIN报文段即使不携带数据，也要消耗一个序号。
2. 服务器收到连接释放报文，发出确认报文，ACK=1，ack=u+1，并且带上自己的序列号seq=v，此时，服务端就进入了CLOSE-WAIT（关闭等待）状态。TCP服务器通知高层的应用进程，客户端向服务器的方向就释放了，这时候处于半关闭状态，即客户端已经没有数据要发送了，但是服务器若发送数据，客户端依然要接受。这个状态还要持续一段时间，也就是整个CLOSE-WAIT状态持续的时间。
3. 客户端收到服务器的确认请求后，此时，客户端就进入FIN-WAIT-2（终止等待2）状态，等待服务器发送连接释放报文（在这之前还需要接受服务器发送的最后的数据）。
4. 服务器将最后的数据发送完毕后，就向客户端发送连接释放报文，FIN=1，ack=u+1，由于在半关闭状态，服务器很可能又发送了一些数据，假定此时的序列号为seq=w，此时，服务器就进入了LAST-ACK（最后确认）状态，等待客户端的确认。
5. 客户端收到服务器的连接释放报文后，必须发出确认，ACK=1，ack=w+1，而自己的序列号是seq=u+1，此时，客户端就进入了TIME-WAIT（时间等待）状态。注意此时TCP连接还没有释放，必须经过2∗∗MSL（最长报文段寿命）的时间后，当客户端撤销相应的TCB后，才进入CLOSED状态。
6. 服务器只要收到了客户端发出的确认，立即进入CLOSED状态。同样，撤销TCB后，就结束了这次的TCP连接。可以看到，服务器结束TCP连接的时间要比客户端早一些。

1. 四次挥手过程

   （1）客户端向服务器发送FIN控制报文段（首部中的 FIN 比特被置位）；

   （2）服务端收到FIN，回复ACK。服务器进入关闭等待状态，发送FIN;

   （3）客户端收到FIN，给服务器回复ACK，客户端进入等待状态（进入“等待”，以确保服务器收到ACK真正关闭连接）;

   （4）服务端收到ACK，链接关闭。

2. **四次挥手原因**

     TCP协议是一种**面向连接的、可靠的、基于字节流的**运输层通信协议。TCP是**全双工模式**，这就意味着，当客户端发出FIN报文段时，只是表示客户端已经没有数据要发送了，客户端告诉服务器，它的数据已经全部发送完毕了；但是，这个时候客户端还是可以接受来自服务端的数据；当服务端返回ACK报文段时，表示它已经知道客户端没有数据发送了，但是服务端还是可以发送数据到客户端的；当服务端也发送了FIN报文段时，这个时候就表示服务端也没有数据要发送了，就会告诉客户端，我也没有数据要发送了，之后彼此就会愉快的中断这次TCP连接。

     简单地说，前 2 次挥手用于关闭一个方向的数据通道，后两次挥手用于关闭另外一个方向的数据通道。

#### Java集合

Java集合类主要由两个根接口Collection和Map派生出来的，Collection派生出了三个子接口：List、Set、Queue（Java5新增的队列），因此Java集合大致也可分成List、Set、Queue、Map四种接口体系，（注意：Map不是Collection的子接口）。

　　其中List代表了有序可重复集合，可直接根据元素的索引来访问；Set代表无序不可重复集合，只能根据元素本身来访问；Queue是队列集合；Map代表的是存储key-value对的集合，可根据元素的key来访问value。

#### MySQL查询的执行过程

**一、客户端/服务端通信协议**

**二、查询缓存**

**三、语法解析和预处理**

**四、查询优化**

**五、查询执行引擎**

**六、返回结果给客户端**

### 项目面经

#### Dubbo

##### **dubbo的角色：**注册中心**、**服务提供者**、**服务消费者**、**监控中心

##### **dubbo版本:**2.7.2

##### **dubbo的工作原理:**

第一层：service层，接口层，给服务提供者和消费者来实现的
第二层：config层，配置层，主要是对dubbo进行各种配置的
第三层：proxy层，服务代理层，透明生成客户端的stub和服务单的skeleton
第四层：registry层，服务注册层，负责服务的注册与发现
第五层：cluster层，集群层，封装多个服务提供者的路由以及负载均衡，将多个实例组合成一个服务
第六层：monitor层，监控层，对rpc接口的调用次数和调用时间进行监控
第七层：protocol层，远程调用层，封装rpc调用
第八层：exchange层，信息交换层，封装请求响应模式，同步转异步
第九层：transport层，网络传输层，抽象mina和netty为统一接口
第十层：serialize层，数据序列化层

##### **Dubbo工作流程：**

1）第一步，provider向注册中心去注册
2）第二步，consumer从注册中心订阅服务，注册中心会通知consumer注册好的服务
3）第三步，consumer调用provider
4）第四步，consumer和provider都异步的通知监控中心

##### **注册中心挂了可以继续通信吗？**

可以，因为刚开始初始化的时候，消费者会将提供者的地址等信息拉取到本地缓存，所以注册中心挂了可以继续通信。

##### **为什么选用dubbo，解决了什么问题:**

在早期的项目中，代码全在一个工程中，对于简单的项目来说还好，如果后期涉及的功能增多。涉及订单、物流等多个功能模块，只是简单的一个项目的话，就变得十分糟糕。

那么如果项目具有多个系统，各个系统需要实现相互通讯，哪怎么办呢。一般来说使用RPC框架，如dubbo

为什么使用Dubbo

1、Dubbo一款优秀的分布式服务框架

2、Dubbo提供高性能的RPC服务

3、Dubbo具有注册中心、监控中心。

##### **什么是负载均衡？**

​        当一台服务器的性能达到极限时，我们可以使用服务器集群来提高网站的整体性能。那么，在服务器集群中，需要有一台服务器充当调度者的角色，用户的所有请求都会首先由它接收，调度者再根据每台服务器的负载情况将请求分配给某一台后端服务器去处理。

 		那么在这个过程中，调度者如何合理分配任务，保证所有后端服务器都将性能充分发挥，从而保持服务器集群的整体性能最优，这就是负载均衡问题。

##### **Dubbo的心跳机制：**

目的：
维持provider和consumer之间的长连接
实现：
dubbo心跳时间heartbeat默认是1s，超过heartbeat时间没有收到消息，就发送心跳消 息(provider，consumer一样),如果连着3次(heartbeatTimeout为heartbeat*3)没有收到心跳响应，provider会关闭channel，而consumer会进行重连;不论是provider还是consumer的心跳检测都是通过启动定时任务的方式实现；

Dubbo的zookeeper做注册中心，如果注册中心全部挂掉，发布者和订阅者还能通信吗？
可以通信的，启动dubbo时，消费者会从zk拉取注册的生产者的地址接口等数据，缓存在本地。每次调用时，按照本地存储的地址进行调用；
注册中心对等集群，任意一台宕机后，将会切换到另一台；注册中心全部宕机后，服务的提供者和消费者仍能通过本地缓存通讯。服务提供者无状态，任一台 宕机后，不影响使用；服务提供者全部宕机，服务消费者会无法使用，并无限次重连等待服务者恢复；
挂掉是不要紧的，但前提是你没有增加新的服务，如果你要调用新的服务，则是不能办到的。

##### Dubbo SPI机制

SPI 全称为 Service Provider Interface，是一种服务发现机制。SPI 的本质是将接口实现类的全限定名配置在文件中，并由服务加载器读取配置文件，加载实现类。这样可以在运行时，动态为接口替换实现类。正因此特性，我们可以很容易的通过 SPI 机制为我们的程序提供拓展功能。SPI 机制在第三方框架中也有所应用，比如 Dubbo 就是通过 SPI 机制加载所有的组件。不过，Dubbo 并未使用 Java 原生的 SPI 机制，而是对其进行了增强，使其能够更好的满足需求。在 Dubbo 中，SPI 是一个非常重要的模块。基于 SPI，我们可以很容易的对 Dubbo 进行拓展。

##### RPC与传统的HTTP对比

优点：

1. 传输效率高(二进制传输)

2. 发起调用的一方无需知道RPC的具体实现，如同调用本地函数般调用

缺点：

1. 通用性不如HTTP好(HTTP是标准协议)

总结：RPC适合内部服务间的通信调用；HTTP适合面向用户与服务间的通信调用

##### **介绍一下RPC流程:**

1、调用方持续把请求参数对象序列化成二进制数据，经过 TCP 传输到服务提供方；

2、服务提供方从 TCP 通道里面接收到二进制数据；

3、根据 RPC 协议，服务提供方将二进制数据分割出不同的请求数据，经过反序列化将二进制数据逆向还原出请求对象，找到对应的实现类，完成真正的方法调用；

4、然后服务提供方再把执行结果序列化后，回写到对应的 TCP 通道里面；

5、调用方获取到应答的数据包后，再反序列化成应答对象。

这样调用方就完成了一次 RPC 调用。

RPC 通信流程中的核心组成部分包括了协议、序列化与反序列化，以及网络通信。

#### Zookeeper

##### Zookeeper有什么用途

使用ZooKeeper作为「dubbo的注册中心」，使用ZooKeeper实现「分布式锁」。

ZooKeeper，它是一个开放源码的「分布式协调服务」，它是一个集群的管理者，它将简单易用的接口提供给用户。

可以基于Zookeeper 实现诸如数据发布/订阅、负载均衡、命名服务、分布式协调/通知、集群管理、Master 选举、分布式锁和分布式队列「等功能」。

Zookeeper的「用途」：命名服务、配置管理、集群管理、分布式锁、队列管理

##### zk分布式锁的实现原理

Zookeeper就是使用临时顺序节点特性实现分布式锁的。

获取锁过程 （创建临时节点，检查序号最小）

释放锁 （删除临时节点，监听通知）

##### Zookeeper的特性

Zookeeper 保证了如下分布式一致性特性：

「顺序一致性」：从同一客户端发起的事务请求，最终将会严格地按照顺序被应用到 ZooKeeper 中去。

「原子性」：所有事务请求的处理结果在整个集群中所有机器上的应用情况是一致的，也就是说，要么整个集群中所有的机器都成功应用了某一个事务，要么都没有应用。

「单一视图」：无论客户端连到哪一个 ZooKeeper 服务器上，其看到的服务端数据模型都是一致的。

「可靠性：」 一旦服务端成功地应用了一个事务，并完成对客户端的响应，那么该事务所引起的服务端状态变更将会被一直保留下来。

「实时性：」 Zookeeper 仅仅能保证在一定的时间段内，客户端最终一定能够从服务端上读取到最新的数据状态。

##### dubbo为什么选择Zookeeper作为注册中心

dubbo的注册中心可以选Zookeeper，memcached，redis等。为什么选择Zookeeper，因为它的功能特性咯~

命名服务，服务提供者向Zookeeper指定节点写入url，完成服务发布。

配置管理，实际项目开发中，我们经常使用.properties或者xml需要配置很多信息，如数据库连接信息、fps地址端口等等。因为你的程序一般是分布式部署在不同的机器上（如果你是单机应用当我没说），如果把程序的这些配置信息「保存在zk的znode节点」下，当你要修改配置，即znode会发生变化时，可以通过改变zk中某个目录节点的内容，利用「watcher通知给各个客户端」，从而更改配置。

负载均衡，注册中心的承载能力有限，而Zookeeper集群配合web应用很容易达到负载均衡。

zk支持监听事件，特别适合发布/订阅的场景，dubbo的生产者和消费者就类似这场景。

数据模型简单，数据存在内存，可谓高性能

#### Redis

##### Redis可以做什么

提到Redis 大多数人的第一想法就是做缓存，但是如果作为开发人员的我们，对于Redis的作用只停留在做缓存上，那么是不合格的。Redis还具有许多其他用途，例如：分布式锁，分布式系统唯一序列号生成器，计数器等等。

在不同的场景下，我们应该选择Redis不同的数据结构进行处理

##### **Redis的数据类型和用法**

1. String字符串 可以为整形、浮点型和字符串，统称为元素，**点赞、计数、粉丝数**
2. Hash
   一个 string 类型的 field（字段） 和 value（值） 的映射表，hash 特别适合用于**存储对象、用户信息**
3. List 有序串列表，**粉丝列表、消息队列**。
4. Set 无序集合，集合成员是唯一的，这就意味着集合中不能出现重复的数据。**共同关注、喜好、好友，标签**。
5. ZSet 有序集合，集合成员是唯一的。**排行榜**。

##### Redis高可用模式——主从复制、哨兵模式、群集模式

1、主从复制：主从复制是高可用Redis的基础，哨兵和集群都是在主从复制基础上实现高可用的。主从复制主要实现了数据的多机备份，以及对于读操作的负载均衡和简单的故障恢复。
缺陷：
●故障恢复无法自动化；
●写操作无法负载均衡；
●存储能力受到单机的限制。
2、哨兵：在主从复制的基础上，哨兵实现了自动化的故障恢复。
缺陷：
●写操作无法负载均衡；
●存储能力受到单机的限制；
●哨兵无法对从节点进行自动故障转移，在读写分离场景下，从节点故障会导致读服务不可用，需要对从节点做额外的监控、切换操作。
3、集群：通过集群，Redis解决了写操作无法负载均衡，以及存储能力受到单机限制的问题，实现了较为完善的高可用方案。

##### 哈希槽介绍

Redis Cluster在设计中没有使用[一致性哈希（Consistency Hashing）](https://www.cnblogs.com/frankcui/p/15354596.html)，而是使用数据分片引入哈希槽（hash slot）来实现；

一个 Redis Cluster包含16384（0~16383）个哈希槽（补充：[为什么redis集群的最大槽数是16384个？](https://www.cnblogs.com/frankcui/p/15354682.html)），存储在Redis Cluster中的所有键都会被映射到这些slot中，集群中的每个键都属于这16384个哈希槽中的一个。按照槽来进行分片，通过为每个节点指派不同数量的槽，可以控制不同节点负责的数据量和请求数.

##### 常用的IO复用模型有三种：select，poll，[epoll](https://so.csdn.net/so/search?q=epoll&spm=1001.2101.3001.7020)

(1)select==>时间复杂度O(n)

它仅仅知道了，有I/O事件发生了，却并不知道是哪那几个流（可能有一个，多个，甚至全部），我们只能无差别轮询所有流，找出能读出数据，或者写入数据的流，对他们进行操作。所以select具有O(n)的无差别轮询复杂度，同时处理的流越多，无差别轮询时间就越长。

(2)poll==>时间复杂度O(n)

poll本质上和select没有区别，它将用户传入的数组拷贝到内核空间，然后查询每个fd对应的设备状态， 但是它没有最大连接数的限制，原因是它是基于链表来存储的.

(3)epoll==>时间复杂度O(1)

epoll可以理解为event poll，不同于忙轮询和无差别轮询，epoll会把哪个流发生了怎样的I/O事件通知我们。所以我们说epoll实际上是事件驱动（每个事件关联上fd）的，此时我们对这些流的操作都是有意义的。（复杂度降低到了O(1)）

select，poll，epoll都是IO多路复用的机制。I/O多路复用就通过一种机制，可以监视多个描述符，一旦某个描述符就绪（一般是读就绪或者写就绪），能够通知程序进行相应的读写操作。但select，poll，epoll本质上都是同步I/O，因为他们都需要在读写事件就绪后自己负责进行读写，也就是说这个读写过程是阻塞的，而异步I/O则无需自己负责进行读写，异步I/O的实现会负责把数据从内核拷贝到用户空间。  

epoll跟select都能提供多路I/O复用的解决方案。在现在的Linux内核里有都能够支持，其中epoll是Linux所特有，而select则应该是POSIX所规定，一般操作系统均有实现

##### **热点发现**

本地缓存的方案中，有一个问题需要解决，**那就是怎么知道哪些数据是热点数据？**因为本地缓存资源有限，不可能把所有的商品数据进行缓存，**它只会缓存热点的数据**。那怎么知道数据是热点数据呢？

**人为预测**

> 就是人工标记，预测这个商品会成为热点，打个标记。web应用根据这个标记把此商品保存到本地缓存中

这个方案，是根据运营人员的经验进行预测，太不靠谱了。

**系统推算**

这个方案是根据**实实在在的数据访问量进行推算**形成，网上也介绍了用访问日志的什么算法，推算哪些是热点数据。 老顾这里分享一个比较简单的方式，就是**利用redis4.x自身特性，LFU机制发现热点数据**。实现很简单，只要把redis内存淘汰机制设置为allkeys-lfu或者volatile-lfu方式，再执行

```text
./redis-cli --hotkeys
```

**会返回访问频率高的key，并从高到底的排序**

##### 线程模型

多个 socket 可能会并发产生不同的操作，每个操作对应不同的文件事件，但是 IO多路复用程序会监听多个 socket，会将产生事件的 socket 放入队列中排队，事件分派器每次从队列中取出一个 socket，根据 socket 的事件类型交给对应的事件处理器进行处理。

##### 文件事件处理器的结构：

- 多个 socket
- IO 多路复用程序
- 文件事件分派器
- 事件处理器（连接应答处理器、命令请求处理器、命令回复处理器）

##### Redis是单线程吗

Redis的演变历程

1、Redis 4之前的版本是单线程

2、Redis 4.x 版本不是严格意思的删除，处理客户端请求的是单线程，添加了异步删除的功能

3、Redis 5.x 版本采用多线程解决问题

##### Redis的单线程指什么

Redis 单线程主要指的是网络IO和键值对读写是由一个线程来完成的，Redis在处理客户端的请求的时候包括获取(Socket)，解析，执行，内容返回(Socket写)等由一个顺序串行的主线程处理，这即为单线程 但Redis的其它功能，比如持久化，异步删除，集群数据同步等等，都是由额外的线程执行的，是多线程 即Redis工作线程是单线程的，但是，整个Redis来说是多线程的

##### Redis单线程为什么很快

1、基于内存操作：Redis的所有数据都存在内存中，因此所有的运算都是内存级别

2、数据结构简单：Redis的数据结构简单，查找和操作时间大部分时间复杂度是O(1)

3、多路复用和非阻塞：Redis使用多路复用功能来监听多个Socket链接客服端，这样可以一个线程处理多个请求，减少线程切换带来的开销，同时也避免了IO阻塞操作

4、避免上下文切换：因为是单线程模型，因此避免了多线程切换和多线程竞争，减少时间和性能的消耗

##### Redis之前为什么采用单线程

1、单线程易于开发和维护

2、单线程模型也可以并发处理多客户端的请求，主要使用多路复用和非阻塞IO

3、对于Redis来说，主要的性能瓶颈是内存或者网络IO而不是CPU

##### Redis为什么要引用多线程

大key删除可以会造成Redis主线程卡顿 当被删除的key是一个非常大的对象时，例如几十兆的对象时，那么删除将是一个非常耗时的操作，其他命令将会不能执行发生阻塞，造成Redis主线程卡顿。如果是在一个高并发的环境下，将会产生十分严重的问题。

这就是redis3.x单线程时代最经典的故障，大key删除的头疼问题。

**那么如何解决大key删除问题呢**

1、惰性删除

2、当删除大key时，因为是单线程，所以会造成Redis服务卡顿，于是在4.0版本新增了多线程的模块用于解决删除数据效率低的问题。处理读写请求仍然只是一个线程

3、unlink key 、flushdb async 、flushall async 异步删除，新起子线程进行删除工作

##### 引入多线程后能够解决大key删除阻塞问题吗

如果是同步删除，那么同样会面临阻塞问题。因为Redis的工作线程（执行命令）任然是单线程。因此在实际工作中应该避免大key的出现



##### **redis的角色**

> Redis是一个可基于内存亦可持久化的日志型、Key-Value数据库。

论持久化，我们平时使用的MySQL就足够了，那为什么还需要引入Redis呢？无法就是 ：**性能** 。

> 数据获取的流程，一般是前端请求，后台先从缓存中取数据，缓存取不到则去数据库中取，数据库取到了则返回给前端，然后更新缓存，如果数据库取不到则返回空数据给前端。

那Redis的性能表现在哪方面呢——**快** 和 **并发**。

##### **redis和数据库的数据一致性**

3种方案保证数据库与缓存的一致性

- 延时双删策略：延时双删的步骤：

  > 1 先删除缓存
  > 2 再更新数据库
  > 3 休眠一会（比如1秒），再次删除缓存。

- 删除缓存重试机制：删除缓存重试机制

  不管是延时双删还是Cache-Aside的先操作数据库再删除缓存，如果第二步的删除缓存失败呢?

  > 删除失败会导致脏数据哦~

  删除失败就多删除几次呀,保证删除缓存成功呀~ 所以可以引入删除缓存重试机制

- 读取biglog异步删除缓存：同步biglog异步删除缓存

  重试删除缓存机制还可以，就是会造成好多业务代码入侵。还可以通过数据库的binlog来异步淘汰key。以mysql为例 可以使用阿里的canal将binlog日志采集发送到MQ队列里面，然后编写一个简单的缓存删除消息者订阅binlog日志，根据更新log删除缓存，并且通过ACK机制确认处理这条更新log，保证数据缓存一致性

在分布式系统中，缓存和数据库同时存在时，如果有写操作的时候，「先操作数据库，再操作缓存」。如下：

1.读取缓存中是否有相关数据
2.如果缓存中有相关数据value，则返回
3.如果缓存中没有相关数据，则从数据库读取相关数据放入缓存中key->value，再返回
4.如果有更新数据，则先更新数据库，再删除缓存
5.为了保证第四步删除缓存成功，使用binlog异步删除
6.如果是主从数据库，binglog取自于从库
7.如果是一主多从，每个从库都要采集binlog，然后消费端收到最后一台binlog数据才删除缓存，或者为了简单，收到一次更新log，删除一次缓存

##### 缓存的问题，击穿，穿透和血崩

- 缓存穿透是指**缓存和数据库中都没有的数据**，而用户不断发起请求，如发起为id为“-1”的数据或id为特别大（不存在的数据）。这时的用户很可能是攻击者，攻击会导致数据库压力过大。
  解决：

1. 接口层增加校验，如用户鉴权校验，id做基础校验，比如 id<=0的直接拦截； 最常见的则是采用**布隆过滤器**，将所有可能存在的数据哈希到一个足够大的bitmap中，一个一定不存在的数据会被这个bitmap拦截掉，从而避免了对底层存储系统的查询压力。

2. 另外也有一个更为**简单粗暴的方法**，如果一个查询返回的数据为空（不管是数据不存在，还是系统故障），我们仍然把这个空结果进行缓存，但它的过期时间会很短，最长不超过五分钟。通过这个直接设置的默认值存放到缓存，这样第二次到缓冲中获取就有值了，而不会继续访问数据库，这种办法最简单粗暴。

- 缓存击穿是指**缓存中没有但数据库中有的数据**，当一个key非常热点（类似于爆款），在不停的扛着大并发，大并发集中对这一个点进行访问；当这个key在失效的瞬间，持续的大并发就穿破缓存，直接请求数据库，就像在一个屏障上凿开了一个洞。
  解决：

1. 设置热点数据永远不过期。
2. 加互斥锁。

- 缓存雪崩是指**缓存中数据大批量到过期时间**，大批量数据同一时间过期，导致请求量全部请求到数据库，造成数据库宕机。
  解决：

1. 给缓存失效时间，加上一个随机值，避免大量缓存集体失效。
2. 双缓存：缓存A和B，比如A的失效时间是20分钟，B不失效。比如从A中没读到，就去B中读，然后异步起一个线程同步到A。

##### **redis的内存淘汰策略**

**内存淘汰策略**

1. noeviction：当内存使用超过配置的时候会返回错误，不会驱逐任何键

2. allkeys-lru：加入键的时候，如果过限，首先通过LRU算法驱逐最久没有使用的键

3. volatile-lru：加入键的时候如果过限，首先从设置了过期时间的键集合中驱逐最久没有使用的键

4. allkeys-random：加入键的时候如果过限，从所有key随机删除

5. volatile-random：加入键的时候如果过限，从过期键的集合中随机驱逐

6. volatile-ttl：从配置了过期时间的键中驱逐马上就要过期的键

7. volatile-lfu：从所有配置了过期时间的键中驱逐使用频率最少的键

8. allkeys-lfu：从所有键中驱逐使用频率最少的键

##### redis过期键的删除策略

其实有三种不同的删除策略：
（1）：立即删除。在设置键的过期时间时，创建一个回调事件，当过期时间达到时，由时间处理器自动执行键的删除操作。
（2）：惰性删除。键过期了就过期了，不管。每次从dict字典中按key取值时，先检查此key是否已经过期，如果过期了就删除它，并返回nil，如果没过期，就返回键值。
（3）：定时删除。每隔一段时间，对expires字典进行检查，删除里面的过期键。
可以看到，第二种为被动删除，第一种和第三种为主动删除，且第一种实时性更高。下面对这三种删除策略进行具体分析。

#### Kafka

##### Zookeeper 对于 Kafka 的作用是什么？

Zookeeper 是一个开放源码的、高性能的协调服务，它用于 Kafka 的分布式应用。
Zookeeper 主要用于在集群中不同节点之间进行通信
在 Kafka 中，它被用于提交偏移量，因此如果节点在任何情况下都失败了，它都可以从之前提交的偏移量中获取除此之外，它还执行其他活动，如: leader 检测、分布式同步、配置管理、识别新节点何时离开或连接、集群、节点实时状态等等。

1、Broker注册与消费者注册以及Topic注册

**Broker是分布式部署并且相互之间相互独立，但是需要有一个注册系统能够将整个集群中的Broker管理起来**，此时就使用到了Zookeeper。在Zookeeper上会有一个专门**用来进行Broker服务器列表记录**的节点：

/brokers/ids

每个Broker在启动时，都会到Zookeeper上进行注册，即到/brokers/ids下创建属于自己的节点，如/brokers/ids/[0...N]。

Kafka使用了全局唯一的数字来指代每个Broker服务器，不同的Broker必须使用不同的Broker ID进行注册，创建完节点后，**每个Broker就会将自己的IP地址和端口信息记录**到该节点中去。其中，Broker创建的节点类型是临时节点，一旦Broker宕机，则对应的临时节点也会被自动删除。

每个消费者服务器启动时，都会到Zookeeper的指定节点下创建一个属于自己的消费者节点，例如/consumers/[group_id]/ids/[consumer_id]，完成节点创建后，消费者就会将自己订阅的Topic信息写入该临时节点。

**对 消费者分组 中的 消费者 的变化注册监听**

在Kafka中，同一个**Topic的消息会被分成多个分区**并将其分布在多个Broker上，**这些分区信息及与Broker的对应关系**也都是由Zookeeper在维护

2、生产者与消费者负载均衡

由于同一个Topic消息会被分区并将其分布在多个Broker上，因此，**生产者需要将消息合理地发送到这些分布式的Broker上**，那么如何实现生产者的负载均衡，Kafka支持传统的四层负载均衡，也支持Zookeeper方式实现负载均衡。

与生产者类似，Kafka中的消费者同样需要进行负载均衡来实现多个消费者合理地从对应的Broker服务器上接收消息，每个消费者分组包含若干消费者，**每条消息都只会发送给分组中的一个消费者**，不同的消费者分组消费自己特定的Topic下面的消息，互不干扰。

##### Kafka角色

kafka是一个分布式的基于发布/订阅模式的消息队列

学习kafka的架构前，我们Kafka每个角色：

　　（1）consumer group 消费者组：这是kafka消息队列特有的角色，它是一堆消费组组合成的。消费者组中的每个消费者负责消费不同分区的数据，一个分区只能一个消费者消费，它们互不影响。

　　（2）broker：一台kafka服务器就是一个broker，一个broker可以有多个topic。

　　（3）topic：可以看做是一个队列。

　　（4）partition：为了实现扩展性，一个非常大的topic可以有分成多个partition，它们可以分布在多个broker上。

##### 为什么要使用 kafka？ 

1. 缓冲和削峰：上游数据时有突发流量，下游可能扛不住，或者下游没有足够多的机器来保证冗余，kafka在中间可以起到一个缓冲的作用，把消息暂存在kafka中，下游服务就可以按照自己的节奏进行慢慢处理。
2. 解耦和扩展性：项目开始的时候，并不能确定具体需求。消息队列可以作为一个接口层，解耦重要的业务流程。只需要遵守约定，针对数据编程即可获取扩展能力。
3. 冗余：可以采用一对多的方式，一个生产者发布消息，可以被多个订阅topic的服务消费到，供多个毫无关联的业务使用。
4. 健壮性：消息队列可以堆积请求，所以消费端业务即使短时间死掉，也不会影响主要业务的正常进行。
5. 异步通信：很多时候，用户不想也不需要立即处理消息。消息队列提供了异步处理机制，允许用户把一个消息放入队列，但并不立即处理它。想向队列中放入多少消息就放多少，然后在需要的时候再去处理它们。

##### Kafka 与传统 MQ 消息系统之间有三个关键区别

(1).Kafka 持久化日志，这些日志可以被重复读取和无限期保留
(2).Kafka 是一个分布式系统：它以集群的方式运行，可以灵活伸缩，在内部通过复制数据提升容错能力和高可用性
(3).Kafka 支持实时的流式处理

##### Kafka 判断一个节点是否还活着的两个条件

（1）节点必须可以维护和 ZooKeeper 的连接，Zookeeper 通过心跳机制检查每个节点的连接
（2）如果节点是个 follower,他必须能及时的同步 leader 的写操作，延时不能太久

##### partition的数据文件（offffset，MessageSize，data）

partition中的每条Message包含了以下三个属性： offset，MessageSize，data，其中offset表示Message在这个partition中的偏移量，offset不是该Message在partition数据文件中的实际存储位置，而是逻辑上一个值，它唯一确定了partition中的一条Message，可以认为offset是partition中Message的 id； MessageSize表示消息内容data的大小；data为Message的具体内容。

##### 如何保证 Kafka 消息不重复消费？

1.保存并且查询 每个消息一个唯一key 消费国记录下来，每次消费查询是否消费过，没有消费过才进行消费

2.利用幂等

将消费的业务设计成幂等性，比如利用数据库的唯一约束条件进行实现（比如转账操作 在转账流水记录中相同的账单id和相同的账户id视为唯一约束条件 重复操作直接失败）

3.设置前置条件的形式

比如通过数据加一个版本号的属性，每次更新数据前比较当前版本是否和消息中版本一致 如果不一致可以拒绝操作

##### Kafka怎么保证消息不丢失（存入和读取）

从 Kafka 整体架构图我们可以得出有三次消息传递的过程：

**1）Producer 端发送消息给 Kafka Broker 端。**

解决方法

（1）网络抖动导致消息丢失，Producer 端可以进行重试。

（2）消息大小不合格，可以进行适当调整，符合 Broker 承受范围再发送。

 （3） **request.required.acks设置为 -1/ all**，-1/all 表示有多少个副本 Broker 全部收到消息，才认为是消息提交成功的标识。

kafka 的 ack 的三种机制

request.required.acks 有三个值 0 1 -1(all)
0:生产者不会等待 broker 的 ack，这个延迟最低但是存储的保证最弱当 server 挂掉的时候就会丢数据。
1：服务端会等待 ack 值 leader 副本确认接收到消息后发送 ack 但是如果 leader挂掉后他不确保是否复制完成新 leader 也会导致数据丢失。
-1(all)：服务端会等所有的 follower 的副本受到数据后才会受到 leader 发出的ack，这样数据不会丢失

**2）Kafka Broker 将消息进行同步并持久化数据。**

既然 Broker 端消息存储是通过异步批量刷盘的，那么这里就可能会丢数据的

- 由于 Kafka 中并没有提供「**同步刷盘**」的方式，所以说从单个 Broker 来看还是很有可能丢失数据的。
- kafka 通过「**多 Partition （分区）多 Replica（副本）机制」**已经可以最大限度的保证数据不丢失，如果数据已经写入 PageCache 中但是还没来得及刷写到磁盘，此时如果所在 Broker 突然宕机挂掉或者停电，极端情况还是会造成数据丢失。

3）Kafka Broker 将消息拉取并进行消费。

- 在剖析 Consumer 端丢失场景的时候，我们得出其拉取完消息后是需要提交 Offset 位移信息的，因此为了不丢数据，正确的做法是：**拉取数据、**业务逻辑处理、提交消费 Offset 位移信息。我们还需要设置参数**enable.auto.commit = false, 采用手动提交位移的方式。**

消费者如何不自动提交偏移量，由应用提交？

将 auto.commit.offset 设为 false，然后在处理一批消息后 commitSync() 或者异步提交 commitAsync()
即：

```java
ConsumerRecords<> records = consumer.poll();
for (ConsumerRecord<> record : records){
    。。。
    tyr{
        consumer.commitSync()
    }
    。。。
}
```

另外对于消费消息重复的情况，业务自己保证幂等性, **保证只成功消费一次即可**。

##### Kafka怎么处理消息堆积

+ 增加分区同时增加消费实例

+ 单个消费者线程使用异步消费(线程池)

##### kafka的isr机制

先来看几个概念

1、AR（Assigned Repllicas）一个partition的所有副本（就是replica，不区分leader或follower）

2、ISR（In-Sync Replicas）能够和 leader 保持同步的 follower + leader本身 组成的集合。

3、OSR（Out-Sync Relipcas）不能和 leader 保持同步的 follower 集合

4、公式：AR = ISR + OSR
**Kafka采用的就是一种完全同步的方案，而ISR是基于完全同步的一种优化机制。Kafka只保证对ISR集合中的所有副本保证完全同步。**处于ISR内部的follower都是可以和leader进行同步的，一旦出现故障或延迟，就会被踢出ISR。

##### Kafka如何保证顺序消费

如何保证Kafka消息的顺序执行

kafka只能保证同一个partition内的消息是顺序性的，但是整个topic下并不能保证是顺序的

1.因为kafka 天然存在是属性在同一个partion中消息是有顺序的 可以利用这种机制 同一类型的消息分配到一个分区partion中

2.消费者内部创建内存队列，对于需要顺序消费的业务数据，根据key或者业务数据放入同一个队列中，然后线程从对应的队列中取出数据

关于顺序消费的几点说明：

①、kafka的顺序消息仅仅是通过partitionKey，将某类消息写入同一个partition，一个partition只能对应一个消费线程，以保证数据有序。

②、除了发送消息需要指定partitionKey外，producer和consumer实例化无区别。

③、kafka broker宕机，kafka会有自选择，所以宕机不会减少partition数量，也就不会影响partitionKey的sharding。

那么问题来了：在1个topic中，有3个partition，那么如何保证数据的消费？

1、如顺序消费中的第①点说明，生产者在写的时候，可以指定一个 key，比如说我们指定了某个订单 id 作为 key，那么这个订单相关的数据，一定会被分发到同一个 partition 中去，而且这个 partition 中的数据一定是有顺序的。

2、消费者从 partition 中取出来数据的时候，也一定是有顺序的。到这里，顺序还是 ok 的，没有错乱。

3、但是消费者里可能会有多个线程来并发来处理消息。因为如果消费者是单线程消费数据，那么这个吞吐量太低了。而多个线程并发的话，顺序可能就乱掉了。K所以对于 Kafka 的消息顺序性保证，其实我们只需要保证同一个订单号的消息只被同一个线程处理的就可以了。由此我们可以在线程处理前增加个内存队列，每个线程只负责处理其中一个内存队列的消息，同一个订单号的消息发送到同一个内存队列中即可。

##### kafka 分布式（不是单机）的情况下，如何保证消息的顺序消费?

Kafka 分布式的单位是 partition，同一个 partition 用一个 write ahead log 组织，所以可以保证 FIFO 的顺序。不同 partition 之间不能保证顺序。但是绝大多数用户都可以通过 message key 来定义，因为同一个 key 的 message 可以保证只发送到同一个 partition。
Kafka 中发送 1 条消息的时候，可以指定(topic, partition, key) 3 个参数。partiton 和 key 是可选的。如果你指定了 partition，那就是所有消息发往同 1个 partition，就是有序的。并且在消费端，Kafka 保证，1 个 partition 只能被1 个 consumer 消费。或者你指定 key（ 比如 order id），具有同 1 个 key 的所有消息，会发往同 1 个 partition。

#### Spring相关

##### Spring容器的初始化过程

１、ResourceLoader从存储介质中加载Spring配置信息，并使用Resource表示这个配置文件的资源；

２、BeanDefinitionReader读取Resource所指向的配置文件资源，然后解析配置文件。配置文件中每一个解析成一个BeanDefinition对象，并保存到BeanDefinitionRegistry中；

３、容器扫描BeanDefinitionRegistry中的BeanDefinition，使用Java的反射机制自动识别出Bean工厂后处理后器（实现BeanFactoryPostProcessor接口）的Bean，然后调用这些Bean工厂后处理器对BeanDefinitionRegistry中的BeanDefinition进行加工处理。主要完成以下两项工作：

1）对使用到占位符的元素标签进行解析，得到最终的配置值，这意味对一些半成品式的BeanDefinition对象进行加工处理并得到成品的BeanDefinition对象；

2）对BeanDefinitionRegistry中的BeanDefinition进行扫描，通过Java反射机制找出所有属性编辑器的Bean（实现java.beans.PropertyEditor接口的Bean），并自动将它们注册到Spring容器的属性编辑器注册表中（PropertyEditorRegistry）；

4．Spring容器从BeanDefinitionRegistry中取出加工后的BeanDefinition，并调用InstantiationStrategy着手进行Bean实例化的工作；

5．在实例化Bean时，Spring容器使用BeanWrapper对Bean进行封装，BeanWrapper提供了很多以Java反射机制操作Bean的方法，它将结合该Bean的BeanDefinition以及容器中属性编辑器，完成Bean属性的设置工作；

6．利用容器中注册的Bean后处理器（实现BeanPostProcessor接口的Bean）对已经完成属性设置工作的Bean进行后续加工，直接装配出一个准备就绪的Bean。Spring框架中用到了哪些设计模式？

##### Spring框架在实现时运用的设计模式

1. 简单工厂

   Spring中的BeanFactory就是简单工厂模式的体现，根据传入一个唯一的标识来获得Bean对象，但是否是在传入参数后创建还是传入参数前创建这个要根据具体情况来定。

2. 工厂方法

   实现了FactoryBean接口的bean是一类叫做factory的bean。其特点是，spring会在使用getBean()调用获得该bean时，会自动调用该bean的getObject()方法，所以返回的不是factory这个bean，而是这个bean的getOjbect()方法的返回值。

3. 单例模式

   Spring依赖注入Bean实例默认是单例的。Spring的依赖注入（包括lazy-init方式）都是发生在AbstractBeanFactory的getBean里。getBean的doGetBean方法调用getSingleton进行bean的创建。

4. 适配器模式

   SpringMVC中的适配器HandlerAdatper，它会根据Handler规则执行不同的Handler。即DispatcherServlet根据HandlerMapping返回的handler，向HandlerAdatper发起请求处理Handler。HandlerAdapter根据规则找到对应的Handler并让其执行，执行完毕后Handler会向HandlerAdapter返回一个ModelAndView，最后由HandlerAdapter向DispatchServelet返回一个ModelAndView。

5. 装饰器模式

   Spring中用到的装饰器模式在类名上有两种表现：一种是类名中含有Wrapper，另一种是类名中含有Decorator。

6. 代理模式

   AOP底层就是动态代理模式的实现。即：切面在应用运行的时刻被织入。一般情况下，在织入切面时，AOP容器会为目标对象创建动态的创建一个代理对象。SpringAOP就是以这种方式织入切面的。

7. 观察者模式

   Spring的事件驱动模型使用的是观察者模式，Spring中Observer模式常用的地方是listener的实现。

8. 策略模式

   Spring框架的资源访问Resource接口。该接口提供了更强的资源访问能力，Spring 框架本身大量使用了 Resource 接口来访问底层资源。Resource 接口是具体资源访问策略的抽象，也是所有资源访问类所实现的接口。

9. 模板方法模式

   Spring模板方法模式的实质，是模板方法模式和回调模式的结合，是Template Method不需要继承的另一种实现方式。Spring几乎所有的外接扩展都采用这种模式。

##### Spring MVC的父子容器

如果spring.xml和spring-mvc.xml定义了相同id的bean会怎样？假设id=test。

1.首先Spring 初始化，Spring IOC 容器中生成一个id为test bean实例。

2.Spring MVC开始初始化，生成一个id为test bean实例。

此时，两个容器分别有一个相同id的bean。那用起来会不会混淆？

答案是不会。

当你在Spring MVC业务逻辑中使用该bean时，Spring MVC会直接返回自己容器的bean。

当你在Spring业务逻辑中使用该bean时，因为子容器的bean对父亲是不可见的，因此会直接返回Spring容器中的bean。

虽然上面的写法不会造成问题。但是在实际使用过程中，建议大家都把bean定义都写在spring.xml文件中。

因为使用单例bean的初衷是在IOC容器中只存在一个实例，如果两个配置文件都定义，会产生两个相同的实例，造成资源的浪费，也容易在某些场景下引发缺陷。

1. **应用中可以包含多个IOC容器。**
2. **DispatcherServlet的创建的子容器主要包含Controller、view resolvers等和web相关的一些bean。**
3. **父容器root WebApplicationContex主要包含包含一些基础的bean，比如一些需要在多个servlet共享的dao、service等bean。**
4. **如果在子容器中找不到bean的时候可以去父容器查找bean。**

##### Cglib和jdk动态代理的区别？

1、Jdk动态代理：利用拦截器（必须实现InvocationHandler）加上反射机制生成一个代理接口的匿名类，在调用具体方法前调用InvokeHandler来处理

2、 Cglib动态代理：利用ASM框架，对代理对象类生成的class文件加载进来，通过修改其字节码生成子类来处理

什么时候用cglib什么时候用jdk动态代理？

1、目标对象生成了接口 默认用JDK动态代理

2、如果目标对象使用了接口，可以强制使用cglib

3、如果目标对象没有实现接口，必须采用cglib库，Spring会自动在JDK动态代理和cglib之间转换

##### 谈谈自己对于 Spring IoC 的了解

**所谓IoC，对于spring框架来说，就是由spring来负责控制对象的生命周期和对象间的关系。**Spring所倡导的开发方式**就是如此，**所有的类都会在spring容器中登记，告诉spring你是个什么东西，你需要什么东西，然后spring会在系统运行到适当的时候，把你要的东西主动给你，同时也把你交给其他需要你的东西。所有的类的创建、销毁都由 spring来控制，也就是说控制对象生存周期的不再是引用它的对象，而是spring。对于某个具体的对象而言，以前是它控制其他对象，现在是所有对象都被spring控制，所以这叫控制反转。

##### 谈谈自己对于 AOP 的了解

AOP(Aspect-Oriented Programming，面向切面编程)：是一种新的方法论，是对传统 OOP(Object-Oriented Programming，面向对象编程)的补充。面向对象是纵向继承，面向切面是横向抽取。
AOP编程操作的主要对象是切面(aspect)，而切面用于模块化横切关注点（公共功能）。
面向切面编程，就是将交叉业务逻辑封装成切面，利用AOP的功能将切面织入到主业务逻辑中。所谓交叉业务逻辑是指，通用的，与主业务逻辑无关的代码，如安全检查，事物，日志等。若不使用AOP，则会出现代码纠缠，即交叉业务逻辑与主业务逻辑混合在一起。这样，会使业务逻辑变得混杂不清。
在应用AOP编程时，仍然需要定义公共功能，但可以明确的定义这个功能应用在哪里，以什么方式应用，并且不必修改受影响的类。这样一来横切关注点就被模块化到特殊的类里——这样的类我们通常称之为“切面”。
AOP的好处：
每个事物逻辑位于一个位置，代码不分散，便于维护和升级
业务模块更简洁，只包含核心业务代码

##### 将一个类声明为 bean 的注解有哪些?

我们一般使用 @Autowired 注解自动装配 bean，要想把类标识成可用于 @Autowired注解自动装配的 bean 的类,采用以下注解可实现：

@Component ：通用的注解，可标注任意类为 Spring 组件。如果一个Bean不知道属于哪个层，可以使用

@Repository : 对应持久层即 Dao 层，主要用于数据库相关操作。

@Service :对应服务层，主要涉及一些复杂的逻辑，需要用到 Dao层。

@Controller : 对应 Spring MVC控制层，主要用户接受用户请求并调用 Service 层返回数据给前端页面。

##### MyBatis中#{}和${}的作用与区别

在[mybatis](https://so.csdn.net/so/search?q=mybatis&spm=1001.2101.3001.7020)中#和$的主要区别是：#传入的参数在SQL中显示为字符串，#方式能够很大程度防止SQL注入；$传入的参数在SQL中直接显示为传入的值，$方式无法防止SQL注入。

**1、传入的参数在SQL中显示不同**

\#{} 将传入的参数（数据）在SQL中显示为字符串，会对自动传入的数据加一个双引号。
「对自动传入的数据加一个双引号」

2、#{}可以防止SQL注入的风险（语句的拼接）；但${}无法防止SQL注入。

3、${}方式一般用于传入数据库对象，例如：表名用参数传递进SQL。

4、大多数情况下还是经常使用#{}，一般能用#{}的就别用${}；但有些情况下必须使用${}，例：MyBatis排序时使用ORDER BY动态参数时需要注意，得用${}而不是#{}。

5、#{} 的参数替换是发生在 DBMS 中，而 ${} 则发生在动态解析过程中。

##### 说说bean 的生命周期?

1. 通过构造方法实例化 Bean 对象。
2. 通过 setter 方法设置对象的属性。
3. 通过Aware，也就是他的子类BeanNameAware，调用Bean的setBeanName()方法传递Bean的ID(XML里面注册的ID)，setBeanName方法是在bean初始化时调用的，通过这个方法可以得到BeanFactory和 Bean 在 XML 里面注册的ID。
4. 如果说 Bean 实现了 BeanFactoryAware,那么工厂调用setBeanFactory(BeanFactory var1) 传入的参数也是自身。
5. 把 Bean 实例传递给 BeanPostProcessor 中的 postProcessBeforeInitialization 前置方法。
6. 完成 Bean 的初始化
7. 把 Bean 实例传递给 BeanPostProcessor 中的 postProcessAfterInitialization 后置方法。
8. 此时 Bean 已经能够正常时候，在最后的时候调用 DisposableBean 中的 destroy 方法进行销毁处理。

##### SpringMVC的工作原理有了解嘛

1. 客户端发起请求（http）通过web.xml找到 DispatchServlet（前端控制器）；
2. 由DispatchServlet控制器通过配置文件（servletName-servlet.xml）寻找到一个或多个HandlerMapping（映射处理器），找到用于处理请求的controller（后端控制器）；
3. DispatchServlet将请求提交到controller；
4. Controller处理业务逻辑后，
5. controller返回数据 ModelAndVIew给DispatchServlet；
6. DispatchServlet寻找到一个或多个ViewResolver（视图解析器），找到ModelAndVIew指定的视图；
7. DispatchServle负责将结果返给View（客户端JSP页面），封装Http；
8. view响应页面的HTTP请求，返回响应数据，浏览器绘制页面。

##### Spring 框架中用到了哪些设计模式：

- **工厂设计模式** : Spring使用工厂模式通过 `BeanFactory`、`ApplicationContext` 创建 bean 对象。
- **代理设计模式** : Spring AOP 功能的实现。
- **单例设计模式** : Spring 中的 Bean 默认都是单例的。
- **模板方法模式** : Spring 中 `jdbcTemplate`、`hibernateTemplate` 等以 Template 结尾的对数据库操作的类，它们就使用到了模板模式。
- **包装器设计模式** : 我们的项目需要连接多个数据库，而且不同的客户在每次访问中根据需要会去访问不同的数据库。这种模式让我们可以根据客户的需求能够动态切换不同的数据源。
- **观察者模式:** Spring 事件驱动模型就是观察者模式很经典的一个应用。
- **适配器模式** :Spring AOP 的增强或通知(Advice)使用到了适配器模式、spring MVC 中也是用到了适配器模式适配`Controller`。

##### Spring 事务中有哪几种事务传播行为?

1、PROPAGATION_REQUIRED：如果当前没有事务，就创建一个新事务，如果当前存在事务，就加入该事务，该设置是最常用的设置。

2、PROPAGATION_SUPPORTS：支持当前事务，如果当前存在事务，就加入该事务，如果当前不存在事务，就以非事务执行。‘

3、PROPAGATION_MANDATORY：支持当前事务，如果当前存在事务，就加入该事务，如果当前不存在事务，就抛出异常。

4、PROPAGATION_REQUIRES_NEW：创建新事务，无论当前存不存在事务，都创建新事务。

5、PROPAGATION_NOT_SUPPORTED：以非事务方式执行操作，如果当前存在事务，就把当前事务挂起。

6、PROPAGATION_NEVER：以非事务方式执行，如果当前存在事务，则抛出异常。

7、PROPAGATION_NESTED：如果当前存在事务，则在嵌套事务内执行。如果当前没有事务，则执行与PROPAGATION_REQUIRED类似的操作。

##### springbootstarter的工作原理

利用starter实现自动化配置只需要两个条件——maven依赖、配置文件，这里简单介绍下starter实现自动化配置的流程。
引入maven实质上就是导入jar包，spring-boot启动的时候会找到starter jar包中的resources/META-INF/spring.factories文件，根据spring.factories文件中的配置，找到需要自动配置的类

##### bootstrap.yml和application.yml的区别

在 Spring Boot 中有两种上下文，一种是 bootstrap，另外一种是 application，下面列举这两种配置文件的区别

1.加载顺序
若application.yml 和bootstrap.yml 在同一目录下：bootstrap.yml 先加载 application.yml后加载

bootstrap.yml 用于应用程序上下文的引导阶段。bootstrap.yml 由父Spring ApplicationContext加载。

2.配置区别
bootstrap.yml 和 application.yml 都可以用来配置参数。

bootstrap.yml 用来程序引导时执行，应用于更加早期配置信息读取。可以理解成系统级别的一些参数配置，这些参数一般是不会变动的。一旦bootStrap.yml 被加载，则内容不会被覆盖。

application.yml 可以用来定义应用级别的， 应用程序特有配置信息，可以用来配置后续各个模块中需使用的公共参数等。

3.属性覆盖问题
启动上下文时，Spring Cloud 会创建一个 Bootstrap Context，作为 Spring 应用的 Application Context 的父上下文。

初始化的时候，Bootstrap Context 负责从外部源加载配置属性并解析配置。这两个上下文共享一个从外部获取的 Environment。Bootstrap 属性有高优先级，默认情况下，它们不会被本地配置覆盖。

也就是说如果加载的 application.yml 的内容标签与 bootstrap 的标签一致，application 也不会覆盖 bootstrap，而 application.yml 里面的内容可以动态替换。

##### springboot的监视器actuator

Spring boot actuator 是 spring 启动框架中的重要功能之一。
Spring boot 监视器可帮助您访 问生产环境中正在运行的应用程序的当前状态。有几个指标必须在生产环境中进行检查和 监控。即使一些外部应用程序可能正在使用这些服务来向相关人员触发警报消息。监视器 模块公开了一组可直接作为 HTTP URL 访问的 REST 端点来检查状态。

##### SpringBoot的自动配置原理

我们可以发现，在使用`main()`启动SpringBoot的时候，只有一个注解`@SpringBootApplication`，我们可以点击进去`@SpringBootApplication`注解中看看，可以发现有**三个注解**是比较重要的：

- `@SpringBootConfiguration`：我们点进去以后可以发现底层是**Configuration**注解，说白了就是支持**JavaConfig**的方式来进行配置(**使用Configuration配置类等同于XML文件**)。

- `@EnableAutoConfiguration`：开启**自动配置**功能

- `@ComponentScan`：这个注解，学过Spring的同学应该对它不会陌生，就是**扫描**注解，默认是扫描**当前类下**的package。将`@Controller/@Service/@Component/@Repository`等注解加载到IOC容器中。

  `@SpringBootApplication`等同于下面三个注解：

  - `@SpringBootConfiguration`
  - `@EnableAutoConfiguration`
  - `@ComponentScan`

  其中`@EnableAutoConfiguration`是关键(启用自动配置)，内部实际上就去加载`META-INF/spring.factories`文件的信息，然后筛选出以`EnableAutoConfiguration`为key的数据，加载到IOC容器中，实现自动配置功能！

##### springboot的全局异常处理

SpringBoot的项目已经对有一定的异常处理了，但是对于我们开发者而言可能就不太合适了，因此我们需要对这些异常进行统一的捕获并处理。SpringBoot中有一个`ControllerAdvice`的注解，使用该注解表示开启了全局异常的捕获，我们只需在自定义一个方法使用`ExceptionHandler`注解然后定义捕获异常的类型即可对这些捕获的异常进行统一的处理。

```java
@ControllerAdvice
public class MyExceptionHandler {

  @ExceptionHandler(value =Exception.class)
	public String exceptionHandler(Exception e){
		System.out.println("未知异常！原因是:"+e);
       	return e.getMessage();
    }
}
```

怎么去捕获异常

在 Spring Boot 应用中，系统中共存在以下 3 种异常情况：

- **`Controller`抛出的异常**：可以采用`@ControllerAdvice`进行全局捕获
- **其他异常**：会被全局异常处理器（比如：`BasicErrorController`）进行捕获
- **全局异常处理器抛出的异常**：对于非`/error`页面的异常，会被内置容器转发到`/error`进行捕获处理，而对于`/error`页面的异常，会先由`@ControllerAdvice`进行捕获，捕获不成功则交由 Spring Boot 内置的 Web 应用容器（比如：Tomcat）进行捕获。

##### java多线程同步的方法

（1）同步方法：即有synchronized关键字修饰的方法。 由于java的每个对象都有一个内置锁，当用此关键字修饰方法时，内置锁会保护整个方法。在调用该方法前，需要获得内置锁，否则就处于阻塞状态。

（2）同步代码块：即有synchronized关键字修饰的语句块。被该关键字修饰的语句块会自动被加上内置锁，从而实现同步

（3）使用特殊域变量(volatile)实现线程同步

  a.volatile关键字为域变量的访问提供了一种免锁机制 
  b.使用volatile修饰域相当于告诉虚拟机该域可能会被其他线程更新 
  c.因此每次使用该域就要重新计算，而不是使用寄存器中的值 
  d.volatile不会提供任何原子操作，它也不能用来修饰final类型的变量

（4）使用重入锁实现线程同步

  在JavaSE5.0中新增了一个java.util.concurrent包来支持同步。ReentrantLock类是可重入、互斥、实现了Lock接口的锁， 它与使用synchronized方法和快具有相同的基本行为和语义，并且扩展了其能力。
   ReenreantLock类的常用方法有：
     ReentrantLock() : 创建一个ReentrantLock实例 
     lock() : 获得锁 
     unlock() : 释放锁 
  注：ReentrantLock()还有一个可以创建公平锁的构造方法，但由于能大幅度降低程序运行效率，不推荐使用 

如果synchronized关键字能满足用户的需求，就用synchronized，因为它能简化代码 。如果需要更高级的功能，就用ReentrantLock类，此时要注意及时释放锁，否则会出现死锁，通常在finally代码释放锁 

（5）使用局部变量实现线程同步

如果使用ThreadLocal管理变量，则每一个使用该变量的线程都获得该变量的副本，副本之间相互独立，这样每一个线程都可以随意修改自己的变量副本，而不会对其他线程产生影响。

（7）使用阻塞队列实现线程同步

（8）使用原子变量实现线程同步

##### ConcurrentHashMap是如何保证线程安全的

印象中一直以为ConcurrentHashMap是基于Segment分段锁来实现的JDK1.8中的ConcurrentHashMap中仍然存在Segment这个类，而这个类的声明则是为了兼容之前的版本序列化而存在的。
JDK1.8中的ConcurrentHashMap不再使用Segment分段锁，而是以table数组的头结点作为synchronized的锁。和JDK1.8中的HashMap类似，对于hashCode相同的时候，在Node节点的数量少于8个时，这时的Node存储结构是链表形式，时间复杂度为O(N)，当Node节点的个数超过8个时，则会转换为红黑树，此时访问的时间复杂度为O(long(N))。
其实ConcurrentHashMap保证线程安全主要有三个地方。

一、使用volatile保证当Node中的值变化时对于其他线程是可见的
二、使用table数组的头结点作为synchronized的锁来保证写操作的安全
三、当头结点为null时，使用CAS操作来保证数据能正确的写入。

##### ConcurrentHashMap是怎么分段分组的？

get操作：

Segment的get操作实现非常简单和高效，先经过一次再散列，然后使用这个散列值通过散列运算定位到 Segment，再通过散列算法定位到元素。get操作的高效之处在于整个get过程都不需要加锁，除非读到空的值才会加锁重读。原因就是将使用的共享变量定义成 volatile 类型。

put操作：

当执行put操作时，会经历两个步骤：

1. 判断是否需要扩容；
2. 定位到添加元素的位置，将其放入 HashEntry 数组中。

插入过程会进行第一次 key 的 hash 来定位 Segment 的位置，如果该 Segment 还没有初始化，即通过 CAS 操作进行赋值，然后进行第二次 hash 操作，找到相应的 HashEntry 的位置，这里会利用继承过来的锁的特性，在将数据插入指定的 HashEntry 位置时（尾插法），会通过继承 ReentrantLock 的 tryLock() 方法尝试去获取锁，如果获取成功就直接插入相应的位置，如果已经有线程获取该Segment的锁，那当前线程会以自旋的方式去继续的调用 tryLock() 方法去获取锁，超过指定次数就挂起，等待唤醒。

##### 线程池工作原理

线程池是一种基于池化技术思想来管理线程的工具。在线程池中维护了多个线程，由线程池统一的管理调配线程来执行任务。通过线程复用，减少了频繁创建和销毁线程的开销。

##### threadlocal工作原理

`ThreadLocal`   即：线程 的 局部变量，主要是存放每个线程的私有数据。每当你创建一个  `ThreadLocal`  变量，那么访问这个变量的每个线程都会在当前线程存一份这个变量的本地副本，只有自身线程能够访问，和其他线程是不共享的，这样可以避免线程资源共享变量冲突的问题

##### threadlocal应用场景

（1）Spring采用Threadlocal的方式，来保证单个线程中的数据库操作使用的是同一个数据库连接，同时，采用这种方式可以使业务层使用事务时不需要感知并管理connection对象，通过传播级别，巧妙地管理多个事务配置之间的切换，挂起和恢复。

（2）一些需要单线程横跨若干方法的调用，也就是上下文（Context），它是一种状态，经常就是是用户身份、任务信息等，就会存在过渡传参的问题。

##### ThreadLocal是如何解决hash冲突

答：采用的开放地址法，不是hashmap的链地址法！

ThreadLocal是采用数组来存储的。ThreadLocalMap在存储的时候会给每一个ThreadLocal对象一个threadLocalHashCode，在插入过程中，根据ThreadLocal对象的hash值，定位到table中的位置i，**int i = key.threadLocalHashCode & (len-1)**。

##### 父子进程之间如何共享ThreadLocal中的值

使用inheritThreadLocals。在主线程中创建一个InheritableThreadLocal的实例，然后在子线程中得到这个InheritableThreadLocal实例设置的值。

##### **threadlocal内存泄露**

> 程序在申请内存后，无法释放已申请的内存空间，一次内存泄露危害可以忽略，但内存泄露堆积后果很严重，无论多少内存,迟早会被占光

Thread引用会引用一个ThreadLocalMap对象，这个map中的key是ThreadLocal对象（使用WeakReference包装），value是业务上变量的值。内存泄露 是由于 `ThreadLocalMap`  的 `key` 为弱引用导致的，弱引用对象，在没有被外部引用时，当发生GC 是 key 被回收为 null, 但是 value 还存在强引用，可能会存在 内存泄露问题

但其实，由于 Thread -> ThreadLocalMap -> Entry -> value 存在这样一条引用链 只要 `Thread` 不被退出，`ThreadLocalMap` 的生命周期将是一样长的，如果不进行手动删除，必然会出现内存泄露。更何况我们大多数是以线程池的方式去操作线程。

总结:
 threadLocal` 内存泄漏的根源是：由于 `ThreadLocalMap` 的生命周期跟 `Thread`一样长，如果没有手动删除对应 `key 就会导致内存泄漏，而不是因为弱引用。

**建议：在使用ThreadLocal的时候要养成及时 `remove()` 的习惯**

源码中分析防止内存泄露的清除操作

`ThreadLocal`  中有两种清除方式:

- expungeStaleEntry()  探测式清理
- cleanSomeSlots() 启发式清除

##### 为什么使用弱引用而不是强引用

key 使用强引用

当hreadLocalMap的key为强引用回收ThreadLocal时，因为ThreadLocalMap还持有ThreadLocal的强引用，如果没有手动删除，ThreadLocal不会被回收，导致Entry内存泄漏。

key 使用弱引用

当ThreadLocalMap的key为弱引用回收ThreadLocal时，由于ThreadLocalMap持有ThreadLocal的弱引用，即使没有手动删除，ThreadLocal也会被回收。当key为null，在下一次ThreadLocalMap调用set(),get()，remove()方法的时候会被清除value值。

由于Thread中包含变量ThreadLocalMap，因此ThreadLocalMap与Thread的生命周期是一样长，如果都没有手动删除对应key，都会导致内存泄漏。

但是使用**弱引用**可以多一层保障：弱引用ThreadLocal不会内存泄漏，对应的value在下一次ThreadLocalMap调用set(),get(),remove()的时候会被清除。

因此，ThreadLocal内存泄漏的根源是：由于ThreadLocalMap的生命周期跟Thread一样长，如果没有手动删除对应key就会导致内存泄漏，而不是因为弱引用。

##### ThreadLocal内存泄漏解决方案

- 每次使用完ThreadLocal，都调用它的remove()方法，清除数据。
- 将ThreadLocal变量定义成private static，这样就一直存在ThreadLocal的强引用，也就能保证任何时候都能通过ThreadLocal的弱引用访问到Entry的value值，进而清除掉 。
- 在使用线程池的情况下，没有及时清理ThreadLocal，不仅是内存泄漏的问题，更严重的是可能导致业务逻辑出现问题。所以，使用ThreadLocal就跟加锁完要解锁一样，用完就清理。

#### Mysql

##### 数据库表设计原则

1、数据库设计的三大范式：为了建立冗余较小、结构合理的数据库，设计数据库时必须遵循一定的规则。在关系型数据库中这种规则就称为范式。范式是符合某一种设计要求的总结。要想设计一个结构合理的关系型数据库，必须满足一定的范式。**第一范式(确保每列保持原子性)**；**第二范式(确保表中的每列都和主键相关)**；**第三范式(确保每列都和主键列直接相关,而不是间接相关)**。

2、不应该针对整个系统进行数据库设计，而应该根据系统架构中的组件划分，并且一个对象有且只有一项职责，如果一个对象要负责两个或两个以上的职责，应进行分拆。

3、根据建立的领域模型进行数据库表的映射，此时应参考数据库设计第二范式：一个表中的所有非关键字属性都依赖于整个关键字

4、数据库表结构设计从一开始即满足第三范式：一个表应满足第二范式，且属性间不存在传递依赖。

5、如果表结构中存在多值依赖，则证明领域模型中的对象具有至少两个以上的职责，应根据第一条进行设计修正。第四范式：一个表如果满足BCNF，不应存在多值依赖。

6、表和表之间的关联尽量采用弱关联以便于对表字段和表结构的调整和重构

7、应针对所有表的主键和外键建立索引，有针对性的（针对一些大数据量和常用检索方式）建立组合属性的索引，提高检索效率

##### MySQL索引结构

这里有一个很重要的一点就是 B+ 树的非叶子节点不保存数据，只有索引。一棵 m 阶的 B+ 树和 m 阶的 B 树的异同点在于：

1. 节点的子树数和关键字数相同（B 树是关键字数比子树数少一）；
2. 所有的叶子结点中包含了全部关键字的信息，及指向含有这些关键字记录的指针（节点的关键字表示的是子树中的最大数，在子树中同样含有这个数据），且叶子结点本身依关键字的大小自小而大的顺序链接。 (而 B 树的叶子节点并没有包括全部需要查找的信息)；
3. **所有的非终端结点可以看成是索引部分**，结点中仅含有其子树根结点中最大（或最小）关键字。 (而 B 树的非终节点也包含需要查找的有效信息)。
4. 叶子节点之间通过指针连接。

##### 数据库回表

对于主键索引和非主键索引，使用的数据结构都是 B+Tree，唯一的区别在于叶子结点中存储的内容不同：

- 主键索引的叶子结点存储的是一行完整的数据。
- 非主键索引的叶子结点存储的则是主键值。

这就是两者最大的区别。

所以，当我们需要查询的时候：

1. 如果是通过主键索引来查询数据，例如 `select * from user where id=100`，那么此时只需要搜索主键索引的 B+Tree 就可以找到数据。
2. 如果是通过非主键索引来查询数据，例如 `select * from user where username='javaboy'`，那么此时需要先搜索 username 这一列索引的 B+Tree，搜索完成后得到主键的值，然后再去搜索主键索引的 B+Tree，就可以获取到一行完整的数据。

对于第二种查询方式而言，一共搜索了两棵 B+Tree，**第一次搜索 B+Tree 拿到主键值后再去搜索主键索引的 B+Tree，这个过程就是所谓的回表。**

##### 索引的实现原理

在MySQL中，索引是在存储引擎层实现的，不同存储引擎对索引的实现方式是不同的，下面我们探讨一下MyISAM和InnoDB两个存储引擎的索引实现方式。

MyISAM索引实现：MyISAM引擎使用B+Tree作为索引结构，叶节点的data域存放的是数据记录的地址，MyISAM的索引文件仅仅保存数据记录的地址。在MyISAM中，主索引和辅助索引（Secondary key）在结构上没有任何区别，只是主索引要求key是唯一的，而辅助索引的key可以重复。

InnoDB索引实现：虽然InnoDB也使用B+Tree作为索引结构，但具体实现方式却与MyISAM截然不同。第一个重大区别是InnoDB的数据文件本身就是索引文件。MyISAM索引文件和数据文件是分离的，索引文件仅保存数据记录的地址。而在InnoDB中，表数据文件本身就是按B+Tree组织的一个索引结构，这棵树的叶节点data域保存了完整的数据记录。这个索引的key是数据表的主键，因此InnoDB表数据文件本身就是主索引。

第二个与MyISAM索引的不同是InnoDB的辅助索引data域存储相应记录主键的值而不是地址。换句话说，InnoDB的所有辅助索引都引用主键作为data域。

##### MyISAM与InnoDB 的区别

1. InnoDB支持事务，MyISAM不支持，对于InnoDB每一条SQL语言都默认封装成事务，自动提交，这样会影响速度，所以最好把多条SQL语言放在begin和commit之间，组成一个事务； 

2. InnoDB支持外键，而MyISAM不支持。对一个包含外键的InnoDB表转为MYISAM会失败； 

3. InnoDB是聚集索引，使用B+Tree作为索引结构，数据文件是和（主键）索引绑在一起的（表数据文件本身就是按B+Tree组织的一个索引结构），必须要有主键，通过主键索引效率很高。但是辅助索引需要两次查询，先查询到主键，然后再通过主键查询到数据。因此，主键不应该过大，因为主键太大，其他索引也都会很大。

       MyISAM是非聚集索引，也是使用B+Tree作为索引结构，索引和数据文件是分离的，索引保存的是数据文件的指针。主键索引和辅助索引是独立的。
        
       也就是说：InnoDB的B+树主键索引的叶子节点就是数据文件，辅助索引的叶子节点是主键的值；而MyISAM的B+树主键索引和辅助索引的叶子节点都是数据文件的地址指针。

##### 什么是MVCC

全称Multi-Version Concurrency Control，即`多版本并发控制`，主要是为了提高数据库的`并发性能`。以下文章都是围绕InnoDB引擎来讲，因为myIsam不支持事务。

##### MVCC解决并发哪些问题？

mvcc用来解决读—写冲突的无锁并发控制，就是为事务分配`单向增长`的`时间戳`。为每个数据修改保存一个`版本`，版本与事务时间戳`相关MVCC解决并发哪些问题？

mvcc用来解决读—写冲突的无锁并发控制，就是为事务分配`单向增长`的`时间戳`。为每个数据修改保存一个`版本`，版本与事务时间戳`相关联`。

读操作`只读取`该事务`开始前`的`数据库快照`。

**解决问题如下：**

- `并发读-写时`：可以做到读操作不阻塞写操作，同时写操作也不会阻塞读操作。
- 解决`脏读`、`幻读`、`不可重复读`等事务隔离问题，但不能解决上面的`写-写 更新丢失`问题。

**因此有了下面提高并发性能的`组合拳`：**

- `MVCC + 悲观锁`：MVCC解决读写冲突，悲观锁解决写写冲突
- `MVCC + 乐观锁`：MVCC解决读写冲突，乐观锁解决写写冲突

MVCC的实现原理

它的实现原理主要是`版本链`，`undo日志` ，`Read View `来实现的

#####  MySQL的索引为什么用B+树？

- 相对于二叉树，层级更少，搜索效率高
- 对于 B-Tree，无论是叶子节点还是非叶子节点，都会保存数据，这样导致一页中存储的键值减少，指针也跟着减少，要同样保存大量数据，只能增加树的高度，导致性能降低
- 相对于 Hash 索引，B+Tree 支持范围匹配及排序操作

B+树由B树和索引顺序访问方法演化而来，它是为磁盘或其他直接存取辅助设备设计的一种平衡查找树，在B+树中，所有记录节点都是按键值的大小顺序存放在同一层的叶子节点，各叶子节点通过指针进行链接。

B+树索引在数据库中的一个特点就是高扇出性，例如在InnoDB存储引擎中，每个页的大小为16KB。在数据库中，B+树的高度一般都在2～4层，这意味着查找某一键值最多只需要2到4次IO操作，这还不错。因为现在一般的磁盘每秒至少可以做100次IO操作，2～4次的IO操作意味着查询时间只需0.02～0.04秒。

##### MySQL的B+树索引为什么只需要2-4层？

假设数据库中一条记录是 1KB，那么一个页就可以存 16 条数据（叶子结点）；对于非叶子结点存储的则是主键值+指针，在 InnoDB 中，一个指针的大小是 6 个字节，假设我们的主键是 bigint ，那么主键占 8 个字节，**当然还有其他一些头信息也会占用字节我们这里就不考虑了**，我们大概算一下，小伙伴们心里有数即可：

```
16*1024/(8+6)=1170
```

即一个非叶子结点可以指向 1170 个页，那么一个三层的 B+Tree 可以存储的数据量为：

```
1170*1170*16=21902400
```

可以存储 2100万 条数据。

在 InnoDB 存储引擎中，B+Tree 的高度一般为 2-4 层，这就可以满足千万级的数据的存储，查找数据的时候，一次页的查找代表一次 IO，那我们通过主键索引查询的时候，其实最多只需要 2-4 次 IO 操作就可以了。

##### MySQL事务隔离级别

SQL 标准定义了四种隔离级别，这四种隔离级别分别是：

- 读未提交（READ UNCOMMITTED）；
- 读提交 （READ COMMITTED）；
- 可重复读 （REPEATABLE READ）；
- 串行化 （SERIALIZABLE）。

事务隔离是为了解决脏读、不可重复读、幻读问题，上述4种隔离级别MySQL都支持，并且InnoDB存储引擎默认的支持隔离级别是REPEATABLE READ，但是与标准SQL不同的是，InnoDB存储引擎在REPEATABLE READ事务隔离级别下，使用Next-Key Lock的锁算法，因此避免了幻读的产生。所以，InnoDB存储引擎在默认的事务隔离级别下已经能完全保证事务的隔离性要求，即达到SQL标准的SERIALIZABLE隔离级别。

##### **MySQL 中RC和RR隔离级别的区别**

**RC 与 RR 在锁方面的区别**

1> 显然 RR 支持 gap lock(next-key lock)，而RC则没有gap lock。因为MySQL的RR需要gap lock来解决幻读问题。而RC隔离级别则是允许存在不可重复读和幻读的。所以RC的并发一般要好于RR；

2> RC 隔离级别，通过 where 条件过滤之后，不符合条件的记录上的行锁，会释放掉(虽然这里破坏了“两阶段加锁原则”)；但是RR隔离级别，即使不符合where条件的记录，也不会是否行锁和gap lock；所以从锁方面来看，RC的并发应该要好于RR；

**RC 与 RR 在复制方面的区别**

1> RC 隔离级别不支持 statement 格式的bin log，因为该格式的复制，会导致主从数据的不一致；只能使用 mixed 或者 row 格式的bin log; 这也是为什么MySQL默认使用RR隔离级别的原因。复制时，我们最好使用：**binlog_format=row**

**5.3 RC 与 RR 在一致性读方面的区别**

简单而且，RC隔离级别时，事务中的每一条select语句会读取到他自己执行时已经提交了的记录，也就是每一条select都有自己的一致性读ReadView; 而RR隔离级别时，事务中的一致性读的ReadView是以第一条select语句的运行时，作为本事务的一致性读snapshot的建立时间点的。只能读取该时间点之前已经提交的数据。

**5.4 RC 支持半一致性读，RR不支持**

RC隔离级别下的update语句，使用的是半一致性读(semi consistent)；而RR隔离级别的update语句使用的是当前读；当前读会发生锁的阻塞。



##### 脏读，不可重复读，幻读

1. 脏读：当前事务(A)中可以读到其他事务(B)未提交的数据（脏数据），这种现象是脏读。
2. 不可重复读：在事务A中先后两次读取同一个数据，两次读取的结果不一样，这种现象称为不可重复读。脏读与不可重复读的区别在于：前者读到的是其他事务未提交的数据，后者读到的是其他事务已提交的数据。
3. 幻读：在事务A中按照某个条件先后两次查询数据库，两次查询结果的条数不同，这种现象称为幻读。不可重复读与幻读的区别可以通俗的理解为：前者是数据变了，后者是数据的行数变了。

##### MySQL 中有哪几种锁

一、按照对数据操作的锁粒度来分：行级锁、表级锁、页级锁、间隙锁

1 行级锁

2 表级锁

3 页级锁

二、按照锁的共享策略来分：共享锁、排他锁、意向共享锁、意向排他锁

innodb的意向锁有什么作用？

三、从加锁策略上分：乐观锁和悲观锁

四、其他：自增锁

自增锁（AUTO-INC锁）

外键检测的加锁策略

#### Java语言

##### 数组和链表的区别

数组和链表的区别主要表现在以下几个方面：
逻辑结构	

（1）数组在内存中连续； (2)使用数组之前，必须事先固定数组长度，不支持动态改变数组大小；(3) 数组元素增加时，有可能会数组越界；(4) 数组元素减少时，会造成内存浪费；（5）数组增删时需要移动其它元素	

（1）链表采用动态内存分配的方式，在内存中不连续 (2)支持动态增加或者删除元素 (3)需要时可以使用malloc或者new来申请内存，不用时使用free或者delete来释放内存
内存结构	数组从栈上分配内存，使用方便，但是自由度小	链表从堆上分配内存，自由度大，但是要注意内存泄漏
访问效率	数组在内存中顺序存储，可通过下标访问，访问效率高	链表访问效率低，如果想要访问某个元素，需要从头遍历
越界问题	数组的大小是固定的，所以存在访问越界的风险	只要可以申请得到链表空间，链表就无越界风险

##### int数组和Integer数组以及List＜Integer＞集合三者的相互转化

ArrayList 类是一个可以动态修改的[数组](https://so.csdn.net/so/search?q=数组&spm=1001.2101.3001.7020)，与普通数组的区别就是它是没有固定大小的限制，我们可以添加或删除元素。
ArrayList 继承了 AbstractList ，并实现了 List 接口。

int数组转List<Integer>集合 以及 List<Integer>集合转int数组

```java
int[] intArr = { 0, 1, 2, 3, 4, 5, 6, 7, 8, 9, };

// int[] -> List<Integer>
List<Integer> integerList = Arrays.stream(intArr).boxed().collect(Collectors.toList());
// List<Integer> -> int[]
intArr = integerList.stream().mapToInt(Integer::intValue).toArray();
```

int数组转Integer[] 数组 以及 Integer[] 转int 数组

```java
// int[] -> Integer[]
Integer[] integerArr = Arrays.stream(intArr).boxed().toArray(Integer[]::new);
// Integer[] -> int[]
intArr  = Arrays.stream(integerArr).mapToInt(Integer::valueOf).toArray();
```

Integer数组转List<Integer>集合 以及 List<Integer> 集合转Integer数组

```java
// Integer[] -> List<Integer>
integerList = Arrays.asList(integerArr);
// List<Integer> -> Integer[]
integerArr = integerList.toArray(new Integer[integerList.size()]);
```



##### BeanFactory和FactoryBean区别

BeanFactory:所有Spring Bean的容器根接口，给Spring 的容器定义一套规范，给IOC容器提供了一套完整的规范，比如我们常用到的getBean方法等

FactoryBean:SpringIOC容器是创建Bean的一种形式，这种方式创建Bean会有加成方式，融合了简单的工厂设计模式于装饰器模式

区别

1. BeanFactory:负责生产和管理Bean的一个工厂接口，提供一个Spring Ioc容器规范,
2. FactoryBean: 一种Bean创建的一种方式，对Bean的一种扩展。对于复杂的Bean对象初始化创建使用其可封装对象的创建细节。

##### extends与implements的不同

1、在类的声明中，通过关键字extends来创建一个类的子类。 

一个类通过关键字implements声明自己使用一个或者多个接口。 

extends 是继承某个类, 继承之后可以使用父类的方法, 也可以重写父类的方法; 

implements 是实现多个接口, 接口的方法一般为空的, 必须重写才能使用 

2、extends是继承父类，只要那个类不是声明为final或者那个类定义为abstract的就能继承

JAVA中不支持多重继承，但是可以用接口 来实现，这样就要用到implements，继承只能继承一个类，

但implements可以实现多个接口，用逗号分开就行了 比如 ：

class A extends B implements C,D,E

接口实现的注意点：  

a.实现一个接口就是要实现该接口的所有的方法(抽象类除外)。 

b.接口中的方法都是抽象的。  

c.多个无关的类可以实现同一个接口，一个类可以实现多个无关的接口。

##### 原型模式和单例模式的区别

1.1. 原型模式

用**原型模式**是在已指定对象的基础上，然后通过拷贝这些**原型**对象创建新的对象。

当要实例化的类是在运行时刻指定或者为了避免创建一个与产品类层次平行的工厂类层次时或者当一个类的实例只能有几个不同状态组合中的一种时 —— 建立相应数目的**原型**并**克隆**它们可能比每次用合适的状态手工实例化该类更方便一些。 

1.2. 单例模式

单态**设计模式**的核心就是：将类的构造方法私有化，之后在类的内部产生实例化对象，并通过静态方法返回实例化对象的应用。

如果不希望一个类产生更多对象的情况下，必须使用**单态模式**，所谓单态就是在对象的入口处（构造方法）限制了对象的实例化操作。

##### hashCode与equals的区别与联系

1、equals方法用于比较对象的内容是否相等（覆盖以后）

2、hashcode方法只有在集合中用到

3、当覆盖了equals方法时，比较对象是否相等将通过覆盖后的equals方法进行比较（判断对象的内容是否相等）。

4、将对象放入到集合中时，首先判断要放入对象的hashcode值与集合中的任意一个元素的hashcode值是否相等，如果不相等直接将该对象放入集合中。如果hashcode值相等，然后再通过equals方法判断要放入对象与集合中的任意一个对象是否相等，如果equals判断不相等，直接将该元素放入到集合中，否则不放入。

##### 进程和线程的区别与联系

【区别】：

调度：线程作为调度和分配的基本单位，进程作为拥有资源的基本单位；

并发性：不仅进程之间可以并发执行，同一个进程的多个线程之间也可并发执行；

拥有资源：进程是拥有资源的一个独立单位，线程不拥有系统资源，但可以访问隶属于进程的资源。进程所维护的是程序所包含的资源（静态资源）， 如：地址空间，打开的文件句柄集，文件系统状态，信号处理handler等；线程所维护的运行相关的资源（动态资源），如：运行栈，调度相关的控制信息，待处理的信号集等；

系统开销：在创建或撤消进程时，由于系统都要为之分配和回收资源，导致系统的开销明显大于创建或撤消线程时的开销。但是进程有独立的地址空间，一个进程崩溃后，在保护模式下不会对其它进程产生影响，而线程只是一个进程中的不同执行路径。线程有自己的堆栈和局部变量，但线程之间没有单独的地址空间，一个进程死掉就等于所有的线程死掉，所以多进程的程序要比多线程的程序健壮，但在进程切换时，耗费资源较大，效率要差一些。

【联系】：

+ 一个线程只能属于一个进程，而一个进程可以有多个线程，但至少有一个线程；

+ 资源分配给进程，同一进程的所有线程共享该进程的所有资源；

+ 处理机分给线程，即真正在处理机上运行的是线程；

+ 线程在执行过程中，需要协作同步。不同进程的线程间要利用消息通信的办法实现同步。

  协程，是一种比线程更加轻量级的存在，协程不是被操作系统内核所管理，而完全是由程序所控制（也就是在用户态执行）。这样带来的好处就是性能得到了很大的提升，不会像线程切换那样消耗资源。

  子程序，或者称为函数，在所有语言中都是层级调用，比如A调用B，B在执行过程中又调用了C，C执行完毕返回，B执行完毕返回，最后是A执行完毕。所以子程序调用是通过栈实现的，一个线程就是执行一个子程序。子程序调用总是一个入口，一次返回，调用顺序是明确的。而协程的调用和子程序不同。

  协程的特点在于是一个线程执行，那和多线程比，协程有何优势？

极高的执行效率：因为子程序切换不是线程切换，而是由程序自身控制，因此，没有线程切换的开销，和多线程比，线程数量越多，协程的性能优势就越明显；

不需要多线程的锁机制：因为只有一个线程，也不存在同时写变量冲突，在协程中控制共享资源不加锁，只需要判断状态就好了，所以执行效率比多线程高很多。

##### 线程的 run() 和 start() 有什么区别？

调用 start() 方法是用来启动线程的，轮到该线程执行时，会自动调用 run()；直接调用 run() 方法，无法达到启动多线程的目的，相当于主线程线性执行 Thread 对象的 run() 方法。
一个线程对线的 start() 方法只能调用一次，多次调用会抛出 java.lang.IllegalThreadStateException 异常；run() 方法没有限制。

##### 线程的5种状态

1. **新建(NEW)**：新创建了一个线程对象。

2. **可运行(RUNNABLE)**：线程对象创建后，其他线程(比如main线程）调用了该对象的start()方法。该状态的线程位于可运行[线程池](https://so.csdn.net/so/search?q=线程池&spm=1001.2101.3001.7020)中，等待被线程调度选中，获取cpu 的使用权 。

3. **运行(RUNNING)**：可运行状态(runnable)的线程获得了cpu 时间片（timeslice） ，执行程序代码。

4. **阻塞(BLOCKED)**：阻塞状态是指线程因为某种原因放弃了cpu 使用权，也即让出了cpu timeslice，暂时停止运行。直到线程进入可运行(runnable)状态，才有机会再次获得cpu timeslice 转到运行(running)状态。阻塞的情况分三种： 

> (一). 等待阻塞：运行(running)的线程执行o.wait()方法，JVM会把该线程放入等待队列(waitting queue)中。
> (二). 同步阻塞：运行(running)的线程在获取对象的同步锁时，若该同步锁被别的线程占用，则JVM会把该线程放入锁池(lock pool)中。
> (三). 其他阻塞：运行(running)的线程执行Thread.sleep(long ms)或t.join()方法，或者发出了I/O请求时，JVM会把该线程置为阻塞状态。当sleep()状态超时、join()等待线程终止或者超时、或者I/O处理完毕时，线程重新转入可运行(runnable)状态。

5. **死亡(DEAD)**：线程run()、main() 方法执行结束，或者因异常退出了run()方法，则该线程结束生命周期。死亡的线程不可再次复生。

##### 线程池的五种状态

线程池一共有五种状态, 分别是：

1. RUNNING ：能接受新提交的任务，并且也能处理阻塞队列中的任务。
2. SHUTDOWN：关闭状态，不再接受新提交的任务，但却可以继续处理阻塞队列中已保存的任务。在线程池处于 RUNNING 状态时，调用 shutdown()方法会使线程池进入到该状态。
3. STOP：不能接受新任务，也不处理队列中的任务，会中断正在处理任务的线程。在线程池处于 RUNNING 或 SHUTDOWN 状态时，调用 shutdownNow() 方法会使线程池进入到该状态。
4. TIDYING：如果所有的任务都已终止了，workerCount (有效线程数) 为0，线程池进入该状态后会调用 terminated() 方法进入TERMINATED 状态。
5. TERMINATED：在terminated() 方法执行完后进入该状态，默认terminated()方法中什么也没有做。进入TERMINATED的条件如下：
   - 线程池不是RUNNING状态；
   - 线程池状态不是TIDYING状态或TERMINATED状态；
   - 如果线程池状态是SHUTDOWN并且workerQueue为空；
   - workerCount为0；
   - 设置TIDYING状态成功。

##### 线程池中的几种重要的参数及流程

```java
public ThreadPoolExecutor(int corePoolSize,
                          int maximumPoolSize,
                          long keepAliveTime,
                          TimeUnit unit,
                          BlockingQueue<Runnable> workQueue,
                          ThreadFactory threadFactory,
                          RejectedExecutionHandler handler) {
    if (corePoolSize < 0 ||
        maximumPoolSize <= 0 ||
        maximumPoolSize < corePoolSize ||
        keepAliveTime < 0)
        throw new IllegalArgumentException();
    if (workQueue == null || threadFactory == null || handler == null)
        throw new NullPointerException();
    this.corePoolSize = corePoolSize;
    this.maximumPoolSize = maximumPoolSize;
    this.workQueue = workQueue;
    this.keepAliveTime = unit.toNanos(keepAliveTime);
    this.threadFactory = threadFactory;
    this.handler = handler;
}
```

`corePoolSize`：核心池的大小，在创建了线程池后，默认情况下，线程池中并没有任何线程，而是等待有任务到来才创建线程去执行任务，当有任务来之后，就会创建一个线程去执行任务，当线程池中的线程数目达到corePoolSize后，就会把到达的任务放到缓存队列当中

`maximumPoolSize`：线程池最大线程数最大线程数

`keepAliveTime`：表示线程没有任务执行时最多保持多久时间会终止

`unit`：参数keepAliveTime的时间单位TimeUtil类的枚举类（DAYS、HOURS、MINUTES、SECONDS 等）

`workQueue`：阻塞队列，用来存储等待执行的任务

`threadFactory`：线程工厂，主要用来创建线程

`handler`：拒绝处理任务的策略

- `AbortPolicy`：丢弃任务并抛出 RejectedExecutionException 异常。（默认这种）
- `DiscardPolicy`：也是丢弃任务，但是不抛出异常
- `DiscardOldestPolicy`：丢弃队列最前面的任务，然后重新尝试执行任务（重复此过程）
- `CallerRunsPolicy`：由调用线程处理该任务

**执行流程**

1. 当有任务进入时，线程池创建线程去执行任务，直到核心线程数满为止
2. 核心线程数量满了之后，任务就会进入一个缓冲的任务队列中
   1. 当任务队列为无界队列时，任务就会一直放入缓冲的任务队列中，不会和最大线程数量进行比较
   2. 当任务队列为有界队列时，任务先放入缓冲的任务队列中，当任务队列满了之后，才会将任务放入线程池，此时会拿当前线程数与线程池允许的最大线程数进行比较，如果超出了，则默认会抛出异常。如果没超出，然后线程池才会创建线程并执行任务，当任务执行完，又会将缓冲队列中的任务放入线程池中，然后重复此操作。

##### CAS原理

**什么是CAS？**

CAS：Compare and Swap，即比较再交换。

jdk5增加了并发包java.util.concurrent.*,其下面的类使用CAS算法实现了区别于synchronouse同步锁的一种乐观锁。JDK 5之前Java语言是靠synchronized关键字保证同步的，这是一种独占锁，也是是悲观锁。

**2、CAS算法理解**

对CAS的理解，CAS是一种无锁算法，CAS有3个操作数，内存值V，旧的预期值A，要修改的新值B。当且仅当预期值A和内存值V相同时，将内存值V修改为B，否则什么都不做。

##### Java 实现线程安全的方式

（1）同步方法：即有synchronized关键字修饰的方法。 由于java的每个对象都有一个内置锁，当用此关键字修饰方法时，内置锁会保护整个方法。在调用该方法前，需要获得内置锁，否则就处于阻塞状态。

（2）同步代码块：即有synchronized关键字修饰的语句块。被该关键字修饰的语句块会自动被加上内置锁，从而实现同步

（3）使用特殊域变量(volatile)实现线程同步

  a.volatile关键字为域变量的访问提供了一种免锁机制 
  b.使用volatile修饰域相当于告诉虚拟机该域可能会被其他线程更新 
  c.因此每次使用该域就要重新计算，而不是使用寄存器中的值 
  d.volatile不会提供任何原子操作，它也不能用来修饰final类型的变量

（4）使用重入锁实现线程同步

  在JavaSE5.0中新增了一个java.util.concurrent包来支持同步。ReentrantLock类是可重入、互斥、实现了Lock接口的锁， 它与使用synchronized方法和快具有相同的基本行为和语义，并且扩展了其能力。
   ReenreantLock类的常用方法有：
     ReentrantLock() : 创建一个ReentrantLock实例 
     lock() : 获得锁 
     unlock() : 释放锁 
  注：ReentrantLock()还有一个可以创建公平锁的构造方法，但由于能大幅度降低程序运行效率，不推荐使用 

如果synchronized关键字能满足用户的需求，就用synchronized，因为它能简化代码 。如果需要更高级的功能，就用ReentrantLock类，此时要注意及时释放锁，否则会出现死锁，通常在finally代码释放锁 

（5）使用局部变量实现线程同步

如果使用ThreadLocal管理变量，则每一个使用该变量的线程都获得该变量的副本，副本之间相互独立，这样每一个线程都可以随意修改自己的变量副本，而不会对其他线程产生影响。

（7）使用阻塞队列实现线程同步

（8）使用原子变量实现线程同步



##### java中的final关键字的作用：

1、用来修饰一个引用；2、用来修饰一个方法；3、用来修饰类。当final修饰方法时，这个方法会成为最终方法，无法被子类重写。

1、用来修饰一个引用

如果引用为基本数据类型，则该引用为常量，该值无法修改； 如果引用为引用数据类型，比如对象、数组，则该对象、数组本身可以修改，但指向该对象或数组的地址的引用不能修改。 如果引用时类的成员变量，则必须当场赋值，否则编译会报错。

2、用来修饰一个方法

当使用final修饰方法时，这个方法将成为最终方法，无法被子类重写。但是，该方法仍然可以被继承。

3、用来修饰类

当用final修改类时，该类成为最终类，无法被继承。简称为“断子绝孙类”。

**JDK 和 CGLib动态代理区别**

**1、JDK动态代理具体实现原理：**

- 通过实现InvocationHandler接口创建自己的调用处理器；
- 通过为Proxy类指定ClassLoader对象和一组interface来创建动态代理；
- 通过反射机制获取动态代理类的构造函数，其唯一参数类型就是调用处理器接口类型；
- 通过构造函数创建动态代理类实例，构造时调用处理器对象作为参数参入；

JDK动态代理是面向接口的代理模式，如果被代理目标没有接口那么Spring也无能为力，Spring通过Java的反射机制生产被代理接口的新的匿名实现类，重写了其中AOP的增强方法。

**2、CGLib动态代理：**

CGLib是一个强大、高性能的Code生产类库，可以实现运行期动态扩展java类，Spring在运行期间通过 CGlib继承要被动态代理的类，重写父类的方法，实现AOP面向切面编程呢。

**3、****两者对比：**

- JDK动态代理是面向接口的。
- CGLib动态代理是通过字节码底层继承要代理类来实现（如果被代理类被final关键字所修饰，那么抱歉会失败）。

##### 接口与抽象类的区别与联系

- 接口里只能包含抽象方法、静态方法、默认方法和私有方法，不能为普通方法提供方法实现；抽象类则完全可以包含普通方法。
- 接口里只能定义静态常量，不能定义普通成员变量；抽象类里则既可以定义普通成员变量，也可以定义静态常量。
- 接口里不包含构造器；抽象类里可以包含构造器，抽象类里的构造器并不是用于创建对象，而是让其子类调用这些构造器来完成属于抽象类的初始化操作。
- 接口里不能包含初始化块；但抽象类则完全可以包含初始化块。
- 一个类最多只能有一个直接父类，包括抽象类；但一个类可以直接实现多个接口，通过实现多个接口可以弥补Java单继承的不足。

接口和抽象类很像，它们都具有如下共同的特征：

- 接口和抽象类都不能被实例化，它们都位于继承树的顶端，用于被其他类实现和继承。
- 接口和抽象类都可以包含抽象方法，实现接口或继承抽象类的普通子类都必须实现这些抽象方法。

#####  描述一下Map put的过程

1. 首次扩容：

   先判断数组是否为空，若数组为空则进行第一次扩容（resize）；

2. 计算索引：

   通过hash算法，计算键值对在数组中的索引；

3. 插入数据：

   - 如果当前位置元素为空，则直接插入数据；
   - 如果当前位置元素非空，且key已存在，则直接覆盖其value；
   - 如果当前位置元素非空，且key不存在，则将数据链到链表末端；
   - 若链表长度达到8，则将链表转换成红黑树，并将数据插入树中；

4. 再次扩容

   如果数组中元素个数（size）超过threshold，则再次进行扩容操作。

##### synchronized与Lock的区别

**参考答案**

1. synchronized是Java关键字，在JVM层面实现加锁和解锁；Lock是一个接口，在代码层面实现加锁和解锁。
2. synchronized可以用在代码块上、方法上；Lock只能写在代码里。
3. synchronized在代码执行完或出现异常时自动释放锁；Lock不会自动释放锁，需要在finally中显示释放锁。
4. synchronized会导致线程拿不到锁一直等待；Lock可以设置获取锁失败的超时时间。
5. synchronized无法得知是否获取锁成功；Lock则可以通过tryLock得知加锁是否成功。
6. synchronized锁可重入、不可中断、非公平；Lock锁可重入、可中断、可公平/不公平，并可以细分读写锁以提高效率。

##### 偏向锁/轻量级锁/重量级锁

**这三种锁是指锁的状态**，并且是针对Synchronized。在Java 5通过引入锁升级的机制来实现高效Synchronized。**这三种锁的状态是通过对象监视器在对象头中的字段来表明的**。

**偏向锁是指一段同步代码一直被一个线程所访问，那么该线程会自动获取锁。降低获取锁的代价**。

**轻量级锁是指当锁是偏向锁的时候，被另一个线程所访问，偏向锁就会升级为轻量级锁，其他线程会通过自旋的形式尝试获取锁**，不会阻塞，提高性能。

**重量级锁是指当锁为轻量级锁的时候，另一个线程虽然是自旋，但自旋不会一直持续下去，当自旋一定次数(默认10次)的时候，还没有获取到锁，就会进入阻塞，该锁膨胀为重量级锁。**重量级锁会让其他申请的线程进入阻塞，性能降低。

##### 什么是字节码?采用字节码的好处是什么?

字节码：Java源代码经过虚拟机编译器编译后产生的文件（即扩展为.class的文件），它不面向任何特定的处理器，只面向虚拟机。

采用字节码的好处：Java语言通过字节码的方式，在一定程度上解决了传统解释型语言执行效率低的问题，同时又保留了解释型语言可移植的特点。所以Java程序运行时比较高效，而且，由于字节码并不专对一种特定的机器，因此，Java程序无须重新编译便可在多种不同的计算机上运行。

##### **varchar和char 的区别：**

区别一，定长和变长

char 表示定长，长度固定，varchar表示变长，即长度可变。当所插入的字符串超出它们的长度时，视情况来处理，如果是严格模式，则会拒绝插入并提示错误信息，如果是宽松模式，则会截取然后插入。如果插入的字符串长度小于定义长度时，则会以不同的方式来处理，如char（10），表示存储的是10个字符，无论你插入的是多少，都是10个，如果少于10个，则用空格填满。而varchar（10），小于10个的话，则插入多少个字符就存多少个。
varchar怎么知道所存储字符串的长度呢？实际上，对于varchar字段来说，需要使用一个（如果字符串长度小于255）或两个字节（长度大于255）来存储字符串的长度。但是因为他需要有一个prefix来表示他具体bytes数是多少（因为varchar是变长的，没有这个长度值他不知道如何读取数据）。

区别之二，存储的容量不同

对 char 来说，最多能存放的字符个数 255，和编码无关。
而 varchar 呢，最多能存放 65532 个字符。VARCHAR 的最大有效长度由最大行大小和使用的字符集确定。整体最大长度是 65,532字节

##### 为什么说 Java 语言“编译与解释并存”？

一、你可以说它是编译型的。因为所有的Java代码都是要编译的，.java不经过编译就什么用都没有。
二、你可以说它是解释型的。因为java代码编译后不能直接运行，它是解释运行在[JVM](https://so.csdn.net/so/search?q=JVM&spm=1001.2101.3001.7020)上的，所以它是解释运行的，那也就算是解释的了。
三、但是，现在的JVM为了效率，都有一些JIT优化。它又会把.class的[二进制](https://so.csdn.net/so/search?q=二进制&spm=1001.2101.3001.7020)代码编译为本地的代码直接运行，所以，又是编译的。

##### 一个类的构造方法的作用是什么，若一个类没有声明构造方法，该程序能正确执行吗？为什么？

构造方法主要作用是完成对类对象的初始化工作。

如果一个类没有声明构造方法，也可以执行！因为一个类即使没有声明构造方法也会有默认的不带参数的构造方法。如果我们自己添加了类的构造方法（无论是否有参），Java 就不会再添加默认的无参数的构造方法了，这时候，就不能直接 new 一个对象而不传递参数了，所以我们一直在不知不觉地使用构造方法，这也是为什么我们在创建对象的时候后面要加一个括号（因为要调用无参的构造方法）。

##### 字符型常量和字符串常量的区别?

1.从形式上

> [字符常量](https://so.csdn.net/so/search?q=字符常量&spm=1001.2101.3001.7020)是单引号引起来的一个字符，而字符串常量是双引号引起来的若干字符。

2.从含义上

> 字符常量相当于一个整数型（ASCII值），可以参加[表达式](https://so.csdn.net/so/search?q=表达式&spm=1001.2101.3001.7020)运算；字符串常量代表一个地址值（该字符串在内存中存放的地址）。

3.从占[内存](https://so.csdn.net/so/search?q=内存&spm=1001.2101.3001.7020)大小

> 字符常量只占两个字节，字符串常量占若干字节。（在Java中char占两个字节）

##### 静态方法为什么不能调用非静态成员?

静态成员在类的初始化的时候就已经加载到了内存，可以通过类名.访问，而非静态成员是在类实例化后出现的。所以在非静态成员不存在的时候，静态方法就已经存在了，此时调用非静态成员是非法操作。

##### Java8有哪些新特性

(1)Lambda 表达式 (2) 方法引用通过方法的名字来指向一个方法 (3) 函数式接口(FunctionalInterface)就是一个有且仅有一个抽象方法，但是可以有多个非抽象方法的接口 (4) Java 8 新增了接口的默认方法 (5) Java 8 API添加了一个新的抽象称为流Stream (6) Optional 类是一个可以为null的容器对象

##### 数组 (Array) 和列表 (ArrayList) 有什么区别？什么时候应该使用 Array 而不是ArrayList？
Array可以包含基本类型和对象类型，ArrayList只能包含对象类型。
Array大小是固定的，ArrayList的大小是动态变化的。
ArrayList提供了更多的方法和特性，比如：addAll()，removeAll()，iterator()等等。
对于基本类型数据，集合使用自动装箱来减少编码工作量。但是，当处理固定大小的基本数据类型的时候，这种方式相对比较慢。

#### JVM

##### jvm内存结构

- 堆（Heap）：线程共享。所有的对象实例以及数组都要在堆上分配。回收器主要管理的对象。

堆的作用是存放对象实例和数组。从结构上来分，可以分为新生代和老年代。垃圾回收机制有三种，minor gc，major gc 和full gc。针对于堆的就是前两种。年轻代的叫 minor gc，老年代的叫major gc。而新生代又可以分为Eden 空间、From Survivor 空间（s0）、To Survivor 空间（s1）。 所有新生成的对象首先都是放在新生代的。需要注意，Survivor的两个区是对称的，没先后关系，所以同一个区中可能同时存在从Eden复制过来的对象，和从前一个Survivor复制过来的对象，而复制到老年代的只有从第一个Survivor区过来的对象。而且，Survivor区总有一个是空的。

- 方法区（Method Area）：线程共享。存储类信息、常量、静态变量、即时编译器编译后的代码。

永久代是hotspot虚拟机，也就是我们使用的java虚拟机的特有的概念，他不属于堆内存，是方法区的一种实现，各大厂商对方法区有各自的实现。永久代存放jvm运行时，需要的类，包含java库的类和方法，在触发full gc的情况下，永久代也会被进行垃圾回收。永久代的内存溢出也就是 pergen space。

- 方法栈（JVM Stack）：线程私有。存储局部变量表、操作栈、动态链接、方法出口，对象指针。
- 本地方法栈（Native Method Stack）：线程私有。为虚拟机使用到的Native 方法服务。如Java使用c或者c++编写的接口服务时，代码在此区运行。
- 程序计数器（Program Counter Register）：线程私有。有些文章也翻译成PC寄存器（PC Register），同一个东西。它可以看作是当前线程所执行的字节码的行号指示器。指向下一条要执行的指令。

##### 如何设置JVM内存大小：

具体来讲：

Java整个堆大小设置，Xmx 和 Xms设置为老年代存活对象的3-4倍，即FullGC之后的老年代内存占用的3-4倍

永久代 PermSize和MaxPermSize设置为老年代存活对象的1.2-1.5倍。

年轻代Xmn的设置为老年代存活对象的1-1.5倍。

老年代的内存大小设置为老年代存活对象的2-3倍。

##### JVM的符号引用和直接引用

1.符号引用（Symbolic References）：

符号引用以一组符号来描述所引用的目标，符号可以是任何形式的字面量，只要使用时能够无歧义的定位到目标即可。

符号引用与[虚拟机](https://so.csdn.net/so/search?q=虚拟机&spm=1001.2101.3001.7020)的内存布局无关，引用的目标并不一定加载到内存中。在Java中，一个java类将会编译成一个class文件。在编译时，java类并不知道所引用的类的实际地址，因此只能使用符号引用来代替。

2.直接引用：
直接引用可以是
（1）直接指向目标的指针（比如，指向“类型”【Class对象】、类变量、类方法的直接引用可能是指向方法区的指针）
（2）相对偏移量（比如，指向实例变量、实例方法的直接引用都是偏移量）
（3）一个能间接定位到目标的句柄
直接引用是和虚拟机的布局相关的，同一个符号引用在不同的虚拟机实例上翻译出来的直接引用一般不会相同。如果有了直接引用，那引用的目标必定已经被加载入内存中了。

##### JVM的类加载机制

 全盘负责：当一个类加载器加载某个Class时，该Class所依赖和引用的其它Class也将由该类加载器负责载入，除非显式的使用另外一个类加载器来载入。

双亲委派：当一个类加载器收到了类加载请求，它会把这个请求委派给父（parent）类加载器去完成，依次递归，因此所有的加载请求最终都被传送到顶层的启动类加载器中。只有在父类加载器无法加载该类时子类才尝试从自己类的路径中加载该类。（注意：类加载器中的父子关系并不是类继承上的父子关系，而是类加载器实例之间的关系。）

缓存机制：缓存机制会保证所有加载过的Class都会被缓存，当程序中需要使用某个类时，类加载器先从缓冲区中搜寻该类，若搜寻不到将读取该类的二进制数据，并转换成Class对象存入缓冲区中。这就是为什么修改了Class后需重启JVM才能生效的原因。
JVM的类加载是通过ClassLoader及其子类来完成的，类的层次关系和加载顺序可以由下图来描述：

1）**Bootstrap ClassLoader** 负责加载$JAVA_HOME中 jre/lib/rt.jar 里所有的class或Xbootclassoath选项指定的jar包。由C++实现，不是ClassLoader子类。

2）**Extension ClassLoader** 负责加载java平台中扩展功能的一些jar包，包括$JAVA_HOME中jre/lib/*.jar 或 -Djava.ext.dirs指定目录下的jar包。

3）**App ClassLoader** 负责加载classpath中指定的jar包及 Djava.class.path 所指定目录下的类和jar包。

4）**Custom ClassLoader** 通过java.lang.ClassLoader的子类自定义加载class，属于应用程序根据自身需要自定义的ClassLoader，如tomcat、jboss都会根据j2ee规范自行实现ClassLoader。

加载过程中会先检查类是否被已加载，检查顺序是自底向上，从Custom ClassLoader到BootStrap ClassLoader逐层检查，只要某个classloader已加载，就视为已加载此类，保证此类只所有ClassLoader加载一次。而加载的顺序是自顶向下，也就是由上层来逐层尝试加载此类。

##### G1垃圾回收器

G1垃圾回收器是在Java7 update 4之后引入的一个新的垃圾回收器。G1是一个分代的，增量的，并行与并发的标记-复制垃圾回收器。它的设计目标是为了适应现在不断扩大的内存和不断增加的处理器数量，进一步降低暂停时间（pause time），同时兼顾良好的吞吐量。G1回收器和CMS比起来，有以下不同：

1. G1垃圾回收器是compacting的，因此其回收得到的空间是连续的。这避免了CMS回收器因为不连续空间所造成的问题。如需要更大的堆空间，更多的floating garbage。连续空间意味着G1垃圾回收器可以不必采用空闲链表的内存分配方式，而可以直接采用bump-the-pointer的方式；
2. G1回收器的内存与CMS回收器要求的内存模型有极大的不同。G1将内存划分一个个固定大小的region，每个region可以是年轻代、老年代的一个。内存的回收是以region作为基本单位的；

G1还有一个及其重要的特性：软实时（soft real-time）。所谓的实时垃圾回收，是指在要求的时间内完成垃圾回收。“软实时”则是指，用户可以指定垃圾回收时间的限时，G1会努力在这个时限内完成垃圾回收，但是G1并不担保每次都能在这个时限内完成垃圾回收。通过设定一个合理的目标，可以让达到90%以上的垃圾回收时间都在这个时限内。

##### JVM性能调优实战——UseParallelGC

jdk1.8默认使用ParallelGC。新生代采用的是Parallel Scavenge，Parallel Scavenge是Java1.8默认的收集器，特点是并行的多线程回收，以吞吐量优先。老年代Parallel Old。Parallel Old:是Parallel Scavenge收集器的老年代版本，用于老年代的垃圾回收，但与Parallel Scavenge不同的是，它使用的是“标记-整理算法”。适用于注重于吞吐量及CPU资源敏感的场合。并发垃圾收集器调优的内容一般为：
1）关闭jvm自动分配策略。
2）survivior空间调优。
通过这两点调整，使创建的对象按照设定的阈值执行。

1. G1在jdk6的时候是已经出现了，JDK 7 u9 或更高版本可以使用，在jdk9的时候成为默认的垃圾回收器。因为我们是jdk8所以是需要设置参数指定的。

```text
-Xms24g -Xmx24g -XX:+UseG1GC -XX:MaxGCPauseMillis=95
//最大堆内存24G 使用G1GC，设置预期停顿时间是95ms
```

1. 使用G1的主要原因是：G1的Stop The World(STW)更可控，G1在停顿时间上添加了预测机制，用户可以指定期望停顿时间。
   目标很明确，可控的GC时间。
2. 升级启用了G1后解惑不尽人意，甚至比CMS的结果还差，我们来看下G1，几个优于CMS的几个特点，以及实现。

##### volatile关键字有什么用？

**参考答案**

当一个变量被定义成volatile之后，它将具备两项特性：

1. 保证可见性

   当写一个volatile变量时，JMM会把该线程本地内存中的变量强制刷新到主内存中去，这个写会操作会导致其他线程中的volatile变量缓存无效。

2. 禁止指令重排

   使用volatile关键字修饰共享变量可以禁止指令重排序，volatile禁止指令重排序有一些规则：

   - 当程序执行到volatile变量的读操作或者写操作时，在其前面的操作的更改肯定全部已经进行，且结果已经对后面的操作可见，在其后面的操作肯定还没有进行；
   - 在进行指令优化时，不能将对volatile变量访问的语句放在其后面执行，也不能把volatile变量后面的语句放到其前面执行。

   即执行到volatile变量时，其前面的所有语句都执行完，后面所有语句都未执行。且前面语句的结果对volatile变量及其后面语句可见。

注意，虽然volatile能够保证可见性，但它不能保证原子性。volatile变量在各个线程的工作内存中是不存在一致性问题的，但是Java里面的运算操作符并非原子操作，这导致volatile变量的运算在并发下一样是不安全的。

##### volatile的实现原理

volatile可以保证线程可见性且提供了一定的有序性，但是无法保证原子性。在JVM底层volatile是采用“内存屏障”来实现的。观察加入volatile关键字和没有加入volatile关键字时所生成的汇编代码发现，加入volatile关键字时，会多出一个lock前缀指令，lock前缀指令实际上相当于一个内存屏障，内存屏障会提供3个功能：

1. 它确保指令重排序时不会把其后面的指令排到内存屏障之前的位置，也不会把前面的指令排到内存屏障的后面；即在执行到内存屏障这句指令时，在它前面的操作已经全部完成；
2. 它会强制将对缓存的修改操作立即写入主存；
3. 如果是写操作，它会导致其他CPU中对应的缓存行无效。

##### volatile和synchronized的区别

1. volatile本质是在告诉jvm当前变量在寄存器（工作内存）中的值是不确定的，需要从主存中读取； synchronized则是锁定当前变量，只有当前线程可以访问该变量，其他线程被阻塞住。
2. volatile仅能使用在变量级别；synchronized则可以使用在变量、方法、和类级别的
3. volatile仅能实现变量的修改可见性，不能保证原子性；而synchronized则可以保证变量的修改可见性和原子性
4. volatile不会造成线程的阻塞；synchronized可能会造成线程的阻塞。
5. volatile标记的变量不会被编译器优化；synchronized标记的变量可以被编译器优化

##### PECS原则：Producer Extends Consumer Super

`<? extends T>`和`<? super T>`是Java泛型中的**“通配符（Wildcards）”**和**“边界（Bounds）”**的概念。

- <? extends T>：是指 **“上界通配符（Upper Bounds Wildcards）”**

上界<? extends T>不能往里存，只能往外取

- <? super T>：是指 **“下界通配符（Lower Bounds Wildcards）”**

下界<? super T>不影响往里存，但往外取只能放在Object对象里

**如果参数化类型表示一个生产者，就使用<? extends T>；如果它表示一个消费者，就使用<? super T>**

最后看一下什么是PECS（Producer Extends Consumer Super）原则，已经很好理解了：

- **频繁往外读取内容的，适合用上界Extends。**
- **经常往里插入的，适合用下界Super。**

在`List<? extends Fruit>`的泛型集合中,对于元素的类型,编译器只能知道元素是继承自Fruit,具体是Fruit的哪个子类,这是无法知道的,所以向一个无法知道具体类型的泛型集合中插入元素是不能通过编译的.但是,由于知道元素是继承自Fruit,所以从这个泛型集合中取Fruit类型的元素是可以的.

在`List<? super Apple>`的泛型集合中,元素的类型是Apple的父类,但无法知道是哪个具体的父类,因此读取元素时无法确定以哪个父类进行读取.插入元素时,可以插入Apple与Apple的父类,因为这个集合中的元素都是Apple的父类.

**总结**

只读不可写时,使用`List<? extends Fruit>`:Producer
只写不可读时,使用`List<? super Apple>`:Consumer

##### NIO/BIO

三种IO模型即为BIO【同步阻塞IO】：在BIO模式下，数据的写入和读取都必须阻塞在一个线程中执行，在写入完成或读取完成前，线程阻塞。

NIO【同步非阻塞IO】：NIO相对于BIO来说出现了几个核心的组件，分别是 Selector（选择器） 、 Channle（通道） 和 Buffer（缓冲区） 。NIO出现于JDK 1.4之后。

缓冲区([Buffer](https://so.csdn.net/so/search?q=Buffer&spm=1001.2101.3001.7020))就是在内存中预留指定大小的存储空间用来对输入/输出(I/O)的数据作临时存储，这部分预留的内存空间就叫做缓冲区：

使用缓冲区有这么两个好处：

1、减少实际的物理读写次数

2、缓冲区在创建时就被分配[内存](https://so.csdn.net/so/search?q=内存&spm=1001.2101.3001.7020)，这块内存区域一直被重用，可以减少动态分配和回收内存的次数

AIO【异步非阻塞IO】

##### 两种 NIO 实现：[Selector](https://so.csdn.net/so/search?q=Selector&spm=1001.2101.3001.7020) 与 Epoll

Selector 管理被注册的通道的集合的信息和其就绪状态，同时也更新通道的就绪状态。并且一个通道可以被注册到多个选择器上，而对于同一个选择器则只能被注册一次。**Selector** 一般称 为**选择器** ，当然你也可以翻译为 **多路复用器** 。它是Java NIO核心组件中的一个，用于检查一个或多个NIO Channel（通道）的状态是否处于可读、可写。如此可以实现单线程管理多个channels,也就是可以管理多个网络链接。

[Epoll](https://so.csdn.net/so/search?q=Epoll&spm=1001.2101.3001.7020)是Linux下多路复用IO接口select/poll的增强版本，它能显著提高程序在大量并发连接中只有少量活跃的情况下的系统CPU利用率，因为它会复用文件描述符集合来传递结果而不用迫使开发者每次等待事件之前都必须重新准备要被侦听的文件描述符集合，另一点原因就是获取事件的时候，它无须遍历整个被侦听的描述符集，只要遍历那些被内核IO事件异步唤醒而加入Ready队列的描述符集合就行了。epoll除了提供select/poll那种IO事件的电平触发（Level Triggered）外，还提供了边沿触发（Edge Triggered），这就使得用户空间程序有可能缓存IO状态，减少epoll_wait/epoll_pwait的调用，提高应用程序效率。

##### API接口安全性设计

**1. Token授权机制**

**2. 时间戳超时机制**

**3. API签名机制**

API接口签名生成算法
主要步骤如下：

（1）将所有业务请求参数按字母先后顺序排序。

（2）参数名称和参数值链接成一个字符串A。

（3）在字符串A的首尾加上apiSecret接口密匙组成一个新字符串B。

（4）对字符串进行MD5散列运算得到API签名sign，然后再进行Base64编码。
签名验证算法（接口提供方验证接口请求是否可信，主要算法跟生成API签名的算法是一样的）
主要步骤如下：

1、得到请求方携带的API签名。

2、将所有业务请求参数按字母先后顺序排序。

3、参数名称和参数值链接成一个字符串A。

4、在字符串A的首尾加上apiSecret接口密匙组成一个新字符串B。

5、对新字符串B进行MD5散列运算生成服务器端的API签名，将客户端的API签名进行Base64解码，然后开始验证签名。

6、如果服务器端生成的API签名与客户端请求的API签名是一致的，则请求是可信的，否则就是不可信的。

##### 二分查找和[AVL树](https://so.csdn.net/so/search?q=AVL树&spm=1001.2101.3001.7020)查找

二分查找要求元素可以随机访问，所以决定了需要把元素存储在连续内存。这样查找确实很快，但是插入和删除元素的时候，为了保证元素的有序性，就需要大量的移动元素了。
如果需要的是一个能够进行二分查找，又能**快速添加和删除元素**的数据结构，首先就是二叉查找树，二叉查找树在最坏情况下可能变成一个链表。
于是，就出现了平衡二叉树，根据平衡算法的不同有AVL树，B-Tree，B+Tree，红黑树等，但是AVL树实现起来比较复杂，平衡操作较难理解，这时候就可以用SkipList跳跃表结构。

##### skiplist

跳跃表其实也是一种通过“**空间来换取时间**”的一个[算法](http://lib.csdn.net/base/datastructure)，通过在每个节点中增加了向前的指针，从而提升查找的效率。跳跃表使用**概率均衡技术**而不是使用强制性均衡技术，***因此，对于插入和删除结点比传统上的平衡树算法更为简洁高效***。 

跳表是一种随机化的[数据结构](http://lib.csdn.net/base/datastructure)，目前开源软件 [Redis](http://lib.csdn.net/base/redis) 和 LevelDB 都有用到它。

Key-Value数据结构

目前常用的key-value数据结构有三种：Hash表、红黑树、SkipList，它们各自有着不同的优缺点（不考虑删除操作）：
**Hash表**：插入、查找最快，为O(1)；如使用链表实现则可实现无锁；数据有序化需要显式的排序操作。
**红黑树**：插入、查找为O(logn)，但常数项较小；无锁实现的复杂性很高，一般需要加锁；数据天然有序。
**SkipList**：插入、查找为O(logn)，但常数项比红黑树要大；底层结构为链表，可无锁实现；数据天然有序。

如果要实现一个key-value结构，需求的功能有插入、查找、迭代、修改，那么首先Hash表就不是很适合了，因为迭代的时间复杂度比较高；而红黑树的插入很可能会涉及多个结点的旋转、变色操作，因此需要在外层加锁，这无形中降低了它可能的并发度。而SkipList底层是用链表实现的，可以实现为lock free，同时它还有着不错的性能（单线程下只比红黑树略慢），非常适合用来实现我们需求的那种key-value结构。

##### redis使用跳表(ziplist)?

首先，跳表是skiplist？不是ziplist。ziplist在redis中是一个非常省内存的**链表**（代价是性能略低），所以在hash元素的个数很少（比如只有几十个），那么用这个结构来存储则可以在性能损失很小的情况下节约很多内存（redis是内存数据库啊，能省还是要省的）。好这个问题清楚了。

如果单纯比较性能，跳跃表和红黑树可以说相差不大，但是加上并发的环境就不一样了，如果要更新数据，跳跃表需要更新的部分就比较少，锁的东西也就比较少，所以不同线程争锁的代价就相对少了，而红黑树有个平衡的过程，牵涉到大量的节点，争锁的代价也就相对较高了。性能也就不如前者了。



#### 面试真题

##### 接口的幂等性怎么设计？

**幂等性：**多次调用方法或者接口不会改变业务状态，可以保证重复调用的结果和单次调用的结果一致。

##### **使用幂等的场景**

**1、前端重复提交**

用户注册，用户创建商品等操作，前端都会提交一些数据给后台服务，后台需要根据用户提交的数据在数据库中创建记录。如果用户不小心多点了几次，后端收到了好几次提交，这时就会在数据库中重复创建了多条记录。这就是接口没有幂等性带来的 bug。

**2、接口超时重试**

对于给第三方调用的接口，有可能会因为网络原因而调用失败，这时，一般在设计的时候会对接口调用加上失败重试的机制。如果第一次调用已经执行了一半时，发生了网络异常。这时再次调用时就会因为脏数据的存在而出现调用异常。

**3、消息重复消费**

在使用消息中间件来处理消息队列，且手动 ack 确认消息被正常消费时。如果消费者突然断开连接，那么已经执行了一半的消息会重新放回队列。当消息被其他消费者重新消费时，如果没有幂等性，就会导致消息重复消费时结果异常，如数据库重复数据，数据库数据冲突，资源重复等。

##### **接口的幂等性解决方案**

**1、token 机制实现**

通过token 机制实现接口的幂等性,这是一种比较通用性的实现方法。

**2、基于 mysql 实现**

这种实现方式是利用 mysql 唯一索引的特性。

**3、基于 redis 实现**

这种实现方式是基于 SETNX 命令实现的

SETNX key value：将 key 的值设为 value ，当且仅当 key 不存在。若给定的 key 已经存在，则 SETNX 不做任何动作。

该命令在设置成功时返回 1，设置失败时返回 0。

**总结**

这几种实现幂等的方式其实都是大同小异的，类似的还有使用状态机、悲观锁、乐观锁的方式来实现，都是比较简单的。

总之，当你去设计一个接口的时候，幂等都是首要考虑的问题，特别是当你负责设计转账、支付这种涉及到 money 的接口，你要格外注意喽！

#####  kafka 如何解决消息队列重复消费

**1、消息重复消费场景**
kafka实际上有个offset的概念，就是每个消息写进去，都有一个offset，代表他的序号，然后consumer消费了数据之后，每隔一段时间，会把自己消费过的消息的offset提交一下，代表已经消费过了，下次消费时，会继续从上次消费到的最后一次offset来继续消费。但是凡事总有意外，比如我们之前生产经常遇到的，就是你有时候重启系统，看你怎么重启了，如果碰到点着急的，直接kill进程了，再重启。这会导致consumer有些消息处理了，但是没来得及提交offset。重启之后，少数消息会再次消费一次。
**2、如何保证消息重复消费后的幂等性**
其实重复消费不可怕，可怕的是没考虑到重复消费之后，怎么保证幂等性（一个数据，或者一个请求，给你重复来多次，你得确保对应的数据是不会改变的，不能出错）。

假设你有个系统，消费一条往数据库里插入一条，要是你一个消息重复两次，你不就插入了两条，这数据不就错了？但是你要是消费到第二次的时候，自己判断一下是否已经消费过了，则直接扔了。一条数据重复出现两次，数据库里就只有一条数据，这就保证了系统的幂等性。

 结合业务来思考，我这里给几个思路：

（1）数据写库时，你先根据主键查询一下，如果这数据都有了，则不进行插入，而直接进行update处理，如果是写redis，那没问题了，反正每次都是set，具有天然幂等性。

（2）让生产者发送每条数据的时候，数据里面加一个全局唯一的id，类似订单id之类的东西，然后你这里消费到了之后，先根据这个id 去数据库中查询，如果没有消费过，将该数据写入。如果消费过了，就不进行处理， 保证别重复处理相同的消息即可。

（3）基于数据库的唯一键来保证重复数据不会重复插入多条，因为有唯一键约束了，所以重复数据只会插入报错，不会导致数据库中出现脏数据。

##### hash冲突

就是键(key)经过hash函数得到的结果作为地址去存放当前的键值对(key-value)(这个是hashmap的存值方式)，但是却发现该地址已经有人先来了，一山不容二虎，就会产生冲突。这个冲突就是hash冲突了。
一句话说就是：如果两个不同对象的hashCode相同，这种现象称为hash冲突。

解决hash冲突的办法
开发定址法（线性探测再散列，二次探测再散列，伪随机探测再散列）
再哈希法
链地址法
建立一个公共溢出区
java中hashmap采用的是链地址法

##### 其他面试题


spring的原理，I0C时 ，如何解决bean循环依赖的问题? BeanFactoryPostProcessor的作用? BeanPostProcessor的作用? 对象初始化得到具体的实例对象的时机是什么时候,以及注入的方式有哪些?构造? Setter?

项目中有进行重构迁移的操作?这部分怎么解决的?数据如何迁移?全量迁移还是增量迁移?

Redis中的数据扩容怎么实现?

队列的实现原理? Queue的实现原理?如果数组长度都不够了，如何操作?是移除头部元素?还是扩容?又或循环数组?

分布式事务的思想?如何实现? 2PC是什么? TCC怎么实现补偿机制的?3PC呢?

若有相互调用的系统,位于一个分布式事务中，若-一个 系统宕机了，整个分布式事务如何进行回滚的?逻辑怎么进行?

CountDown (闭锁)怎么实现线程阻塞的?最后一同执行，怎么保证同时唤醒操作?

Map的put方法详解? size方法怎么操作的?

●主要面了项目深挖(整体架构，技术对比和选择原因，负载均衡策略，几种io模型,

●这块比较熟悉说了很多，面试官也没有打断，还追问了epoll具体实现，触发方式等)数据库隔离级别，锁，mvcc的MySQL查询比较慢的话，通过什么方式来优化

●多线程，juc包里的具体实现

●JVM内存模型、垃圾收集算法、判断是否可回收



boolean isOdd(int i,Integer j)和booleanisOdd(Integer i,int j)构成重载吗?如果传int类型和包装类型会调用哪个方法?会报错吗?编译期错误还是运行时错误?具体报什么错?如果入参是两个int类型参数呢? 

问手写非递归线索遍历二叉树算法。

●一面主要是基本技术能力考察，涉及Java基础、多线程、锁、常用中间件、开发框架以及算法。

●整体由浅入深，会结合实际项目进行技术考察，对于中间件如Redis、mq、es都有 所涉及,

●数据库主要是MySQL的InnoDB引擎， 涉及sq|调优内容，框架基本就是spring那-套,常见的源码，也会问问spring cloud。

●算法题不是很难，需要手写。

●一面大概是40-60分钟，沟通比较顺畅。

1二面

●二面是架构师/CTO面，基本围绕原理层面的东西考察。

##### 前中后序递归遍历

- 前序遍历

```java
public List<Integer> preorderTraversal(TreeNode root) {
    List<Integer> list = new ArrayList<Integer>();
    if(root == null) return list;
    Stack<TreeNode> stack = new Stack<TreeNode>();
    while(root != null || !stack.isEmpty()) {
    	// 初始时，先将这棵树的所有最左侧的节点入栈，并添加到list中（因为是先序遍历）
        while(root != null){
            stack.push(root);
            list.add(root.val);
            root = root.left;
        }
        // 此时root已经为空，获取栈顶元素，就是最后一个入栈的左侧节点
        root = stack.pop();
        // 如果栈顶元素的右节点不为空，那么就指向右节点
        if(root.right != null) {
            root = root.right;
        }else{
        // 如果栈顶元素右节点为空，此时当前节点已经被添加过list中了，所以，将他设置为空，然后等待新的栈顶元素赋给他
            root = null;
        }
    }
    return list;
}
```

+ 中序遍历

```java
public List<Integer> inorderTraversal(TreeNode root) {
    List<Integer> list = new ArrayList<Integer>();
    if(root == null) return list;
    Stack<TreeNode> stack = new Stack<TreeNode>();
    while(root != null || !stack.isEmpty()) {
        while(root != null) {
            stack.push(root);
            root = root.left;
        }
        root = stack.pop();
        list.add(root.val);
        if(root.right == null) {
            root = null;
        }else{
            root = root.right;
        }
    }
    return list;
}
```

+ 后序遍历

```java
public List<Integer> postorderTraversal(TreeNode root) {
    List<Integer> list = new ArrayList<Integer>();
    if(root == null) return list;
    // 栈
    Stack<TreeNode> stack = new Stack<TreeNode>();
    TreeNode pre = null;
    while(root != null || !stack.isEmpty()) {
        while(root != null) {
            stack.push(root);
            root = root.left;
        }
        // 说明上一个节点的左子树为空
        root = stack.pop();
        // 然后判断右子树,如果右子树为空或者右子树已经遍历过
        if(root.right == null || root.right == pre) {
            list.add(root.val);
            pre = root;
            root = null;
        }else{
            // 如果还有右子树，那就遍历右子树
            stack.push(root);
            root = root.right;
        }
    }
    return list;
}
```







##### 锁竞争

**锁竞争**

影响锁竞争性的条件有两个：锁被请求的频率和每次持有锁的时间。显然当而这二者都很小的时候，锁竞争不会成为主要的瓶颈。但是如果锁使用不当，导致二者都比较大，那么很有可能CPU不能有效的处理任务，任务被大量堆积。

所以减少锁竞争的方式有下面三种：

1. 减少锁持有的时间
2. 减少锁请求的频率
3. 采用共享锁取代独占锁

**死锁**

1.一种情况是线程A永远不释放锁，结果B一直拿不到锁，所以线程B就“死掉”了
2.第二种情况下，线程A拥有线程B需要的锁Y，同时线程B拥有线程A需要的锁X，那么这时候线程A/B互相依赖对方释放锁，于是二者都“死掉”了。
3.如果一个线程总是不能被调度，那么等待此线程结果的线程可能就死锁了。这种情况叫做线程饥饿死锁。比如说非公平锁中，如果某些线程非常活跃，在高并发情况下这类线程可能总是拿到锁，那么那些活跃度低的线程可能就一直拿不到锁，这样就发生了“饥饿死”。

避免死锁的解决方案是：
1.尽可能的按照锁的使用规范请求锁，另外锁的请求粒度要小（不要在不需要锁的地方占用锁，锁不用了尽快释放）；
2.在高级锁里面总是使用tryLock或者定时机制（就是指定获取锁超时的时间，如果时间到了还没有获取到锁那么就放弃）。高级锁（Lock）里面的这两种方式可以有效的避免死锁。

##### HashMap性能分析

引入红黑树的原因
 HashMap的查询、插入、修改、删除平均时间复杂度都是O(1)。最坏的情况是所有的key都散列到一个Entry中，时间复杂度会退化成O(N)。这就是为什么Java8的HashMap引入了红黑树的原因。当Entry中的链表长度超过8，链表会进化成红黑树。红黑树是一个自平衡二叉查找树，它的查询/插入/修改/删除的平均时间复杂度为O(log(N))。

小结
1）扩容是一个特别耗性能的操作，所以当程序员在使用HashMap的时候，估算map的大小，初始化的时候给一个大致的数值，避免map进行频繁的扩容。
2）负载因子是可以修改的，也可以大于1，但是建议不要轻易修改，除非情况非常特殊。
3）HashMap是线程不安全的，不要在并发的环境中同时操作HashMap，建议使用ConcurrentHashMap。
4）JDK1.8引入红黑树大程度优化了HashMap的性能。
5）HashMap的key为null时不会报空指针异常，但Hashtable会。 

##### 单例模式

**1、懒汉式，线程不安全**:这种方式是最基本的实现方式，这种实现最大的问题就是不支持多线程。因为没有加锁 synchronized，所以严格意义上它并不算单例模式。
这种方式 lazy loading 很明显，不要求线程安全，在多线程不能正常工作。

```java
public class Singleton {  
    private static Singleton instance;  
    private Singleton (){}  
  
    public static Singleton getInstance() {  
        if (instance == null) {  
            instance = new Singleton();  
        }  
        return instance;  
    }  
}
```

**2、懒汉式，线程安全**：这种方式具备很好的 lazy loading，能够在多线程中很好的工作，但是，效率很低，99% 情况下不需要同步。
优点：第一次调用才初始化，避免内存浪费。
缺点：必须加锁 synchronized 才能保证单例，但加锁会影响效率。
getInstance() 的性能对应用程序不是很关键（该方法使用不太频繁）。

```java
public class Singleton {  
    private static Singleton instance;  
    private Singleton (){}  
    public static synchronized Singleton getInstance() {  
        if (instance == null) {  
            instance = new Singleton();  
        }  
        return instance;  
    }  
}
```

**3、饿汉式**:这种方式比较常用，但容易产生垃圾对象。
优点：没有加锁，执行效率会提高。
缺点：类加载时就初始化，浪费内存。
它基于 classloader 机制避免了多线程的同步问题，不过，instance 在类装载时就实例化，虽然导致类装载的原因有很多种，在单例模式中大多数都是调用 getInstance 方法， 但是也不能确定有其他的方式（或者其他的静态方法）导致类装载，这时候初始化 instance 显然没有达到 lazy loading 的效果。

```java
public class Singleton {  
    private static Singleton instance = new Singleton();  
    private Singleton (){}  
    public static Singleton getInstance() {  
    return instance;  
    }  
}
```

**4、双检锁/双重校验锁（DCL，即 double-checked locking）****：这种方式采用双锁机制，安全且在多线程情况下能保持高性能。
getInstance() 的性能对应用程序很关键。

```java
public class Singleton {  
    private volatile static Singleton singleton;  
    private Singleton (){}  
    public static Singleton getSingleton() {  
    if (singleton == null) {  
        synchronized (Singleton.class) {  
            if (singleton == null) {  
                singleton = new Singleton();  
            }  
        }  
    }  
    return singleton;  
    }  
}
```

反转链表

```java
import java.util.*;
public class Solution {
    public ListNode ReverseList(ListNode head) {
        Stack<ListNode> stack=new Stack();
        while(head!=null){
            stack.push(head);
            head=head.next;
        }
        if(stack.isEmpty()){
            return null;
        }
        ListNode node=stack.pop();
        ListNode dummy=node;
        while(!stack.isEmpty()){
            node.next=stack.pop();
            node=node.next;
        }
        node.next=null;
        return dummy;
    }
}
```

##### 排序算法

+ 冒泡排序及其优化

```java
public class bubble_Sort {
    public static void sort(int arr[]){
        for( int i = 0 ; i < arr.length - 1 ; i++ ){
            for(int j = 0;j < arr.length - 1 - i ; j++){
                int temp = 0;
                if(arr[j] > arr[j + 1]){
                    temp = arr[j];
                    arr[j] = arr[j + 1];
                    arr[j + 1] = temp;
                }
            }
        }
    }
}
// 优化
public class Bubble_Sort_optimization {
    public static void sort(int arr[]){
        for( int i = 0;i < arr.length - 1 ; i++ ){
            boolean isSort = true;
            for( int j = 0;j < arr.length - 1 - i ; j++ ){
                int temp = 0;
                if(arr[j] > arr[j + 1]){
                    temp = arr[j];
                    arr[j] = arr[j + 1];
                    arr[j + 1] = temp;
                    isSort = false;
                }
            }
            if(isSort){
                break;
            }
        }
    }
}
```

+ 插入排序

```java
//  插入排序，比较有效地排序方法
    public static void insertionSort(int[] arr) {
        if (arr == null || arr.length < 2) {
            return;
        }
        for (int i = 1; i < arr.length; i++) {
            //使0到i范围内有序
            for (int j = i - 1; j >= 0 && arr[j] > arr[j + 1]; j--) {
                swap(arr, j, j + 1);
            }
        }
    }
//  交换数组中的i, j位置上的元素
    private static void swap(int[] arr, int i, int j) {
        int temp = arr[i];
        arr[i] = arr[j];
        arr[j] = temp;
    }
```

+ 选择排序

```java
public static void selectioinSort(int[] arr) {
    if(arr == null || arr.length < 2) {
        return;
    }
    for (int i = 0; i < arr.length - 1; i++) {
        int minIndex = i;
        for (int j = i + 1; j < arr.length; j++) {
            minIndex = arr[j] < arr[minIndex] ? j : minIndex;
        }
        swap(arr, i, minIndex);
    }
}
```

+ 快速排序

```java
    static void quickSort(int[] nums,int l,int r){
        if(l>=r){
            return;
        }
        int x=nums[l];
        int i=l-1,j=r+1;
        while (i<j){
            do i++;while(nums[i]<x);
            do j--;while(nums[j]>x);
            if(i<j){
                int temp=nums[i];
                nums[i]=nums[j];
                nums[j]=temp;
            }
        }
        quickSort(nums, l, j);
        quickSort(nums,j+1,r);
    }
```

+ 第k个数

```java
public static void main(String[] args){
    int N=100010;
    Scanner sc=new Scanner(System.in);
    int n=sc.nextInt();
    int k=sc.nextInt();
    int[] nums=new int[N];
    for(int i=0;i<n;i++){
        nums[i]=sc.nextInt();
    }
    System.out.println(quickSort(nums,0,n-1,k-1));
}
static int quickSort(int[] nums,int l,int r,int k){
    if(l>=r){
        return nums[k];
    }
    int x=nums[l];
    int i=l-1;
    int j=r+1;
    while(i<j){
        do i++;while(nums[i]<x);
        do j--;while(nums[j]>x);
        if(i<j){
            int temp=nums[i];
            nums[i]=nums[j];
            nums[j]=temp;
        }
    }
    if(k<=j) return quickSort(nums,l,j,k);
    else return quickSort(nums,j+1,r,k);
}
```

+ 归并排序

```java
static void mergeSort(int[] nums,int l,int r){
    if(l>=r){
        return;
    }
    int mid=l+((r-l)>>1);
    mergeSort(nums, l, mid);
    mergeSort(nums, mid+1, r);
    int i=l,j=mid+1,k=0;
    int[] temp=new int[r-l+1];
    while(i<=mid&&j<=r){
        if(nums[i]<=nums[j]){
            temp[k++]=nums[i++];
        }else{
            temp[k++]=nums[j++];
        }
    }
    while(i<=mid){
        temp[k++]=nums[i++];
    }
    while(j<=r){
        temp[k++]=nums[j++];
    }
    for(i=l,j=0;i<=r;i++,j++){
        nums[i]=temp[j];
    }
}
```

+ 逆序对的数量

```java
public class NixuduiNum {
    static long mergeSort(int[] nums,int l,int r){
        if(l>=r){
            return 0;
        }
        int mid = l+((r-l)>>1);
        long res = 0;
        res += mergeSort(nums, l, mid)+mergeSort(nums, mid+1, r);
        int[] temp=new int[r-l+1];
        int i=l,j=mid+1,k=0;
        while(i<=mid&&j<=r){
            if(nums[i]<=nums[j]){
                temp[k++]=nums[i++];
            }else{
                temp[k++]=nums[j++];
                res+=mid-i+1;
            }
        }
        while(i<=mid) temp[k++]=nums[i++];
        while(j<=r) temp[k++] = nums[j++];
        for(i=l,j=0;i<=r;i++,j++){
            nums[i]=temp[j];
        }
        return res;
    }
    public static void main(String[] args) {
        Scanner sc = new Scanner(System.in);
        int n = sc.nextInt();
        int[] nums=new int[n];
        int i=0;
        while(i<n){
            nums[i++]=sc.nextInt();
        }
        System.out.println(mergeSort(nums, 0, nums.length - 1));
    }
}
```

##### 常见Linux指令

+ 常用指令
  ls　　        显示文件或目录

     -l           列出文件详细信息l(list)
  
     -a          列出当前目录下所有文件及目录，包括隐藏的a(all)

mkdir         创建目录

     -p           创建目录，若无父目录，则创建p(parent)

cd               切换目录

touch          创建空文件

echo            创建带有内容的文件。

cat              查看文件内容

cp                拷贝

mv               移动或重命名

rm               删除文件

     -r            递归删除，可删除子目录及文件
    
     -f            强制删除

find              在文件系统中搜索某文件

wc                统计文本中行数、字数、字符数

grep             在文本文件中查找某个字符串

rmdir           删除空目录

tree             树形结构显示目录，需要安装tree包

pwd              显示当前目录

ln                  创建链接文件

more、less  分页显示文本文件内容

head、tail    显示文件头、尾内容

ctrl+alt+F1  命令行全屏模式

+ 系统管理命令

  stat              显示指定文件的详细信息，比ls更详细

who               显示在线登陆用户

whoami          显示当前操作用户

hostname      显示主机名

uname           显示系统信息

top                动态显示当前耗费资源最多进程信息

ps                  显示瞬间进程状态 ps -aux

du                  查看目录大小 du -h /home带有单位显示目录信息

df                  查看磁盘大小 df -h 带有单位显示磁盘信息

ifconfig          查看网络情况

ping                测试网络连通

netstat          显示网络状态信息

man                命令不会用了，找男人  如：man ls

clear              清屏

alias               对命令重命名 如：alias showmeit="ps -aux" ，另外解除使用unaliax showmeit

kill                 杀死进程，可以先用ps 或 top命令查看进程的id，然后再用kill命令杀死进程。


+ 打包压缩相关命令
  gzip：

bzip2：

tar:                打包压缩

     -c              归档文件
    
     -x              压缩文件
    
     -z              gzip压缩文件
    
     -j              bzip2压缩文件
    
     -v              显示压缩或解压缩过程 v(view)
    
     -f              使用档名

例：

tar -cvf /home/abc.tar /home/abc              只打包，不压缩

tar -zcvf /home/abc.tar.gz /home/abc        打包，并用gzip压缩

tar -jcvf /home/abc.tar.bz2 /home/abc      打包，并用bzip2压缩

当然，如果想解压缩，就直接替换上面的命令  tar -cvf  / tar -zcvf  / tar -jcvf 中的“c” 换成“x” 就可以了。

+ 关机/重启机器
  shutdown

     -r             关机重启
  
     -h             关机不重启
  
     now          立刻关机

halt               关机

reboot          重启


+ Linux管道
  将一个命令的标准输出作为另一个命令的标准输入。也就是把几个命令组合起来使用，后一个命令除以前一个命令的结果。

例：grep -r "close" /home/* | more       在home目录下所有文件中查找，包括close的文件，并分页输出。

+ Linux软件包管理
  dpkg (Debian Package)管理工具，软件包名以.deb后缀。这种方法适合系统不能联网的情况下。

比如安装tree命令的安装包，先将tree.deb传到Linux系统中。再使用如下命令安装。

sudo dpkg -i tree_1.5.3-1_i386.deb         安装软件

sudo dpkg -r tree                                     卸载软件

注：将tree.deb传到Linux系统中，有多种方式。VMwareTool，使用挂载方式；使用winSCP工具等；

APT（Advanced Packaging Tool）高级软件工具。这种方法适合系统能够连接互联网的情况。

依然以tree为例

sudo apt-get install tree                         安装tree

sudo apt-get remove tree                       卸载tree

sudo apt-get update                                 更新软件

sudo apt-get upgrade        

将.rpm文件转为.deb文件

.rpm为RedHat使用的软件格式。在Ubuntu下不能直接使用，所以需要转换一下。

sudo alien abc.rpm

+ vim使用
  vim三种模式：命令模式、插入模式、编辑模式。使用ESC或i或：来切换模式。

命令模式下：

:q                      退出

:q!                     强制退出

:wq                   保存并退出

:set number     显示行号

:set nonumber  隐藏行号

/apache            在文档中查找apache 按n跳到下一个，shift+n上一个

yyp                   复制光标所在行，并粘贴

h(左移一个字符←)、j(下一行↓)、k(上一行↑)、l(右移一个字符→)

+ 用户及用户组管理
  /etc/passwd    存储用户账号

/etc/group       存储组账号

/etc/shadow    存储用户账号的密码

/etc/gshadow  存储用户组账号的密码

useradd 用户名

userdel 用户名

adduser 用户名

groupadd 组名

groupdel 组名

passwd root     给root设置密码

su root

su - root 

/etc/profile     系统环境变量

bash_profile     用户环境变量

.bashrc              用户环境变量

su user              切换用户，加载配置文件.bashrc

su - user            切换用户，加载配置文件/etc/profile ，加载bash_profile

更改文件的用户及用户组
sudo chown [-R] owner[:group] {File|Directory}

例如：还以jdk-7u21-linux-i586.tar.gz为例。属于用户hadoop，组hadoop

要想切换此文件所属的用户及组。可以使用命令。

sudo chown root:root jdk-7u21-linux-i586.tar.gz