## 花旗面经

#### API的安全性怎么保障？

1. HTTP 请求中的来源识别

2. 数据加密
3. 数据签名

4. 时间戳
5.  AppID

6. 参数整体加密

#### 对外[API](https://so.csdn.net/so/search?q=API&spm=1001.2101.3001.7020)接口的安全性设计及鉴权方式

- - [API鉴权方式](https://blog.csdn.net/qq_35524157/article/details/116494536#API_6)
  - - [API Key + API Secret实现API鉴权](https://blog.csdn.net/qq_35524157/article/details/116494536#API_Key__API_SecretAPI_9)
    - [Cookie + Session实现API鉴权](https://blog.csdn.net/qq_35524157/article/details/116494536#Cookie__SessionAPI_22)
    - [token机制实现API鉴权](https://blog.csdn.net/qq_35524157/article/details/116494536#tokenAPI_49)
  - [API接口的安全措施](https://blog.csdn.net/qq_35524157/article/details/116494536#API_63)
  - - [数据加密](https://blog.csdn.net/qq_35524157/article/details/116494536#_67)
    - [数据签名](https://blog.csdn.net/qq_35524157/article/details/116494536#_78)
    - [添加时间戳](https://blog.csdn.net/qq_35524157/article/details/116494536#_84)
    - [限流机制](https://blog.csdn.net/qq_35524157/article/details/116494536#_88)
    - [黑名单机制](https://blog.csdn.net/qq_35524157/article/details/116494536#_94)
    - [数据合法性校验](https://blog.csdn.net/qq_35524157/article/details/116494536#_98)

#### URL请求的整个流程 

1、DNS解析

2、TCP连接

3、发送HTTP请求

4、服务器处理请求并返回HTTP报文

5、浏览器解析渲染页面

6、连接结束

#### HTTP和 HTTPS

**HTTP**（HyperText Transfer Protocol：超文本传输协议）是一种用于分布式、协作式和超媒体信息系统的应用层协议。 简单来说就是一种发布和接收 HTML 页面的方法，被用于在 Web 浏览器和网站服务器之间传递信息。

HTTP 默认工作在 TCP 协议 80 端口，用户访问网站 **http://** 打头的都是标准 HTTP 服务。

HTTP 协议以明文方式发送内容，不提供任何方式的数据加密，如果攻击者截取了Web浏览器和网站服务器之间的传输报文，就可以直接读懂其中的信息，因此，HTTP协议不适合传输一些敏感信息，比如：信用卡号、密码等支付信息。

**HTTPS**（Hypertext Transfer Protocol Secure：超文本传输安全协议）是一种透过计算机网络进行安全通信的传输协议。HTTPS 经由 HTTP 进行通信，但利用 SSL/TLS 来加密数据包。HTTPS 开发的主要目的，是提供对网站服务器的身份认证，保护交换数据的隐私与完整性。

HTTPS 默认工作在 TCP 协议443端口，它的工作流程一般如以下方式：

- 1、TCP 三次同步握手
- 2、客户端验证服务器数字证书
- 3、DH 算法协商对称加密算法的密钥、hash 算法的密钥
- 4、SSL 安全加密隧道协商完成
- 5、网页以加密的方式传输，用协商的对称加密算法和密钥加密，保证数据机密性；用协商的hash算法进行数据完整性保护，保证数据不被篡改。

#### HTTP 与 HTTPS 区别

- HTTP 明文传输，数据都是未加密的，安全性较差，HTTPS（SSL+HTTP） 数据传输过程是加密的，安全性较好。
- 使用 HTTPS 协议需要到 CA（Certificate Authority，数字证书认证机构） 申请证书，一般免费证书较少，因而需要一定费用。证书颁发机构如：Symantec、Comodo、GoDaddy 和 GlobalSign 等。
- HTTP 页面响应速度比 HTTPS 快，主要是因为 HTTP 使用 TCP 三次握手建立连接，客户端和服务器需要交换 3 个包，而 HTTPS除了 TCP 的三个包，还要加上 ssl 握手需要的 9 个包，所以一共是 12 个包。
- http 和 https 使用的是完全不同的连接方式，用的端口也不一样，前者是 80，后者是 443。
- HTTPS 其实就是建构在 SSL/TLS 之上的 HTTP 协议，所以，要比较 HTTPS 比 HTTP 要更耗费服务器资源。

#### TCP和UDP的区别

**参考回答**

  TCP和UDP有如下区别：

1. 连接：TCP面向连接的传输层协议，即传输数据之前必须先建立好连接；UDP无连接。
2. 服务对象：TCP点对点的两点间服务，即一条TCP连接只能有两个端点；UDP支持一对一，一对多，多对一，多对多的交互通信。
3. 可靠性：TCP可靠交付：无差错，不丢失，不重复，按序到达；UDP尽最大努力交付，不保证可靠交付。
4. 拥塞控制/流量控制：有拥塞控制和流量控制保证数据传输的安全性；UDP没有拥塞控制，网络拥塞不会影响源主机的发送效率。
5. 报文长度：TCP动态报文长度，即TCP报文长度是根据接收方的窗口大小和当前网络拥塞情况决定的；UDP面向报文，不合并，不拆分，保留上面传下来报文的边界。
6. 首部开销：TCP首部开销大，首部20个字节；UDP首部开销小，8字节（源端口，目的端口，数据长度，校验和）。
7. 适用场景（由特性决定）：数据完整性需让位于通信实时性，则应该选用TCP 协议（如文件传输、重要状态的更新等）；反之，则使用 UDP 协议（如视频传输、实时通信等）。

#### Cookie和Session的区别

(1)cookie数据存放在客户的浏览器上，session数据放在服务器上
(2)cookie不是很安全，别人可以分析存放在本地的COOKIE并进行COOKIE欺骗,如果主要考虑到安全应当使用session
(3)session会在一定时间内保存在服务器上。当访问增多，会比较占用你服务器的性能，如果主要考虑到减轻服务器性能方面，应当使用COOKIE
(4)单个cookie在客户端的限制是3K，就是说一个站点在客户端存放的COOKIE不能3K。
(5)所以：将登陆信息等重要信息存放为SESSION;其他信息如果需要保留，可以放在COOKIE中

#### TCP是怎么控制流量的？

**参考回答**

1. 所谓**流量控制**就是让发送发送速率不要过快，让接收方来得及接收。

2. TCP控制流量的方法

     利用**滑动窗口机制**就可以实施流量控制。

     **原理**就是运用TCP报文段中的窗口大小字段来控制，发送方的发送窗口不可以大于接收方发回的窗口大小。考虑一种特殊的情况，就是接收方若没有缓存足够使用，就会发送零窗口大小的报文，此时发送放将发送窗口设置为0，停止发送数据。之后接收方有足够的缓存，发送了非零窗口大小的报文，但是这个报文在中途丢失的，那么发送方的发送窗口就一直为零导致死锁。

      解决这个问题，TCP为每一个连接设置一个持续计时器（persistence timer）。只要TCP的一方收到对方的零窗口通知，就启动该计时器，周期性的发送一个零窗口探测报文段。对方就在确认这个报文的时候给出现在的窗口大小（注意：TCP规定，即使设置为零窗口，也必须接收以下几种报文段：零窗口探测报文段、确认报文段和携带紧急数据的报文段）。

 TCP协议保证数据传输可靠性的方式主要有：**校验和、序列号、确认应答、超时重传、连接管理、流量控制、拥塞控制**。

#### TCP 三次握手

- 第一次握手：客户端尝试连接服务器，向服务器发送 syn 包（同步序列编号Synchronize Sequence Numbers），syn=j，客户端进入 SYN_SEND 状态等待服务器确认
- 第二次握手：服务器接收客户端syn包并确认（ack=j+1），同时向客户端发送一个 SYN包（syn=k），即 SYN+ACK 包，此时服务器进入 SYN_RECV 状态
- 第三次握手：第三次握手：客户端收到服务器的SYN+ACK包，向服务器发送确认包ACK(ack=k+1），此包发送完毕，客户端和服务器进入ESTABLISHED状态，完成三次握手

#### tcp的四次挥手

1. 客户端进程发出连接释放报文，并且停止发送数据。释放数据报文首部，FIN=1，其序列号为seq=u（等于前面已经传送过来的数据的最后一个字节的序号加1），此时，客户端进入FIN-WAIT-1（终止等待1）状态。 TCP规定，FIN报文段即使不携带数据，也要消耗一个序号。
2. 服务器收到连接释放报文，发出确认报文，ACK=1，ack=u+1，并且带上自己的序列号seq=v，此时，服务端就进入了CLOSE-WAIT（关闭等待）状态。TCP服务器通知高层的应用进程，客户端向服务器的方向就释放了，这时候处于半关闭状态，即客户端已经没有数据要发送了，但是服务器若发送数据，客户端依然要接受。这个状态还要持续一段时间，也就是整个CLOSE-WAIT状态持续的时间。
3. 客户端收到服务器的确认请求后，此时，客户端就进入FIN-WAIT-2（终止等待2）状态，等待服务器发送连接释放报文（在这之前还需要接受服务器发送的最后的数据）。
4. 服务器将最后的数据发送完毕后，就向客户端发送连接释放报文，FIN=1，ack=u+1，由于在半关闭状态，服务器很可能又发送了一些数据，假定此时的序列号为seq=w，此时，服务器就进入了LAST-ACK（最后确认）状态，等待客户端的确认。
5. 客户端收到服务器的连接释放报文后，必须发出确认，ACK=1，ack=w+1，而自己的序列号是seq=u+1，此时，客户端就进入了TIME-WAIT（时间等待）状态。注意此时TCP连接还没有释放，必须经过2∗∗MSL（最长报文段寿命）的时间后，当客户端撤销相应的TCB后，才进入CLOSED状态。
6. 服务器只要收到了客户端发出的确认，立即进入CLOSED状态。同样，撤销TCB后，就结束了这次的TCP连接。可以看到，服务器结束TCP连接的时间要比客户端早一些。

1. 四次挥手过程

   （1）客户端向服务器发送FIN控制报文段（首部中的 FIN 比特被置位）；

   （2）服务端收到FIN，回复ACK。服务器进入关闭等待状态，发送FIN;

   （3）客户端收到FIN，给服务器回复ACK，客户端进入等待状态（进入“等待”，以确保服务器收到ACK真正关闭连接）;

   （4）服务端收到ACK，链接关闭。

2. **四次挥手原因**

     TCP协议是一种**面向连接的、可靠的、基于字节流的**运输层通信协议。TCP是**全双工模式**，这就意味着，当客户端发出FIN报文段时，只是表示客户端已经没有数据要发送了，客户端告诉服务器，它的数据已经全部发送完毕了；但是，这个时候客户端还是可以接受来自服务端的数据；当服务端返回ACK报文段时，表示它已经知道客户端没有数据发送了，但是服务端还是可以发送数据到客户端的；当服务端也发送了FIN报文段时，这个时候就表示服务端也没有数据要发送了，就会告诉客户端，我也没有数据要发送了，之后彼此就会愉快的中断这次TCP连接。

     简单地说，前 2 次挥手用于关闭一个方向的数据通道，后两次挥手用于关闭另外一个方向的数据通道。

#### Java集合

Java集合类主要由两个根接口Collection和Map派生出来的，Collection派生出了三个子接口：List、Set、Queue（Java5新增的队列），因此Java集合大致也可分成List、Set、Queue、Map四种接口体系，（注意：Map不是Collection的子接口）。

　　其中List代表了有序可重复集合，可直接根据元素的索引来访问；Set代表无序不可重复集合，只能根据元素本身来访问；Queue是队列集合；Map代表的是存储key-value对的集合，可根据元素的key来访问value。

#### MySQL查询的执行过程

**一、客户端/服务端通信协议**

**二、查询缓存**

**三、语法解析和预处理**

**四、查询优化**

**五、查询执行引擎**

**六、返回结果给客户端**

### 项目面经

#### Dubbo

##### **dubbo的角色：**注册中心**、**服务提供者**、**服务消费者**、**监控中心

##### **dubbo版本:**2.7.2

##### **dubbo的工作原理:**

第一层：service层，接口层，给服务提供者和消费者来实现的
第二层：config层，配置层，主要是对dubbo进行各种配置的
第三层：proxy层，服务代理层，透明生成客户端的stub和服务单的skeleton
第四层：registry层，服务注册层，负责服务的注册与发现
第五层：cluster层，集群层，封装多个服务提供者的路由以及负载均衡，将多个实例组合成一个服务
第六层：monitor层，监控层，对rpc接口的调用次数和调用时间进行监控
第七层：protocol层，远程调用层，封装rpc调用
第八层：exchange层，信息交换层，封装请求响应模式，同步转异步
第九层：transport层，网络传输层，抽象mina和netty为统一接口
第十层：serialize层，数据序列化层

##### **Dubbo工作流程：**

1）第一步，provider向注册中心去注册
2）第二步，consumer从注册中心订阅服务，注册中心会通知consumer注册好的服务
3）第三步，consumer调用provider
4）第四步，consumer和provider都异步的通知监控中心

##### **注册中心挂了可以继续通信吗？**

可以，因为刚开始初始化的时候，消费者会将提供者的地址等信息拉取到本地缓存，所以注册中心挂了可以继续通信。

##### **为什么选用dubbo，解决了什么问题:**

在早期的项目中，代码全在一个工程中，对于简单的项目来说还好，如果后期涉及的功能增多。涉及订单、物流等多个功能模块，只是简单的一个项目的话，就变得十分糟糕。

那么如果项目具有多个系统，各个系统需要实现相互通讯，哪怎么办呢。一般来说使用RPC框架，如dubbo

为什么使用Dubbo

1、Dubbo一款优秀的分布式服务框架

2、Dubbo提供高性能的RPC服务

3、Dubbo具有注册中心、监控中心。

##### **什么是负载均衡？**

​        当一台服务器的性能达到极限时，我们可以使用服务器集群来提高网站的整体性能。那么，在服务器集群中，需要有一台服务器充当调度者的角色，用户的所有请求都会首先由它接收，调度者再根据每台服务器的负载情况将请求分配给某一台后端服务器去处理。

 		那么在这个过程中，调度者如何合理分配任务，保证所有后端服务器都将性能充分发挥，从而保持服务器集群的整体性能最优，这就是负载均衡问题。

##### **Dubbo的心跳机制：**

目的：
维持provider和consumer之间的长连接
实现：
dubbo心跳时间heartbeat默认是1s，超过heartbeat时间没有收到消息，就发送心跳消 息(provider，consumer一样),如果连着3次(heartbeatTimeout为heartbeat*3)没有收到心跳响应，provider会关闭channel，而consumer会进行重连;不论是provider还是consumer的心跳检测都是通过启动定时任务的方式实现；

Dubbo的zookeeper做注册中心，如果注册中心全部挂掉，发布者和订阅者还能通信吗？
可以通信的，启动dubbo时，消费者会从zk拉取注册的生产者的地址接口等数据，缓存在本地。每次调用时，按照本地存储的地址进行调用；
注册中心对等集群，任意一台宕机后，将会切换到另一台；注册中心全部宕机后，服务的提供者和消费者仍能通过本地缓存通讯。服务提供者无状态，任一台 宕机后，不影响使用；服务提供者全部宕机，服务消费者会无法使用，并无限次重连等待服务者恢复；
挂掉是不要紧的，但前提是你没有增加新的服务，如果你要调用新的服务，则是不能办到的。

##### Dubbo SPI机制

SPI 全称为 Service Provider Interface，是一种服务发现机制。SPI 的本质是将接口实现类的全限定名配置在文件中，并由服务加载器读取配置文件，加载实现类。这样可以在运行时，动态为接口替换实现类。正因此特性，我们可以很容易的通过 SPI 机制为我们的程序提供拓展功能。SPI 机制在第三方框架中也有所应用，比如 Dubbo 就是通过 SPI 机制加载所有的组件。不过，Dubbo 并未使用 Java 原生的 SPI 机制，而是对其进行了增强，使其能够更好的满足需求。在 Dubbo 中，SPI 是一个非常重要的模块。基于 SPI，我们可以很容易的对 Dubbo 进行拓展。

##### RPC与传统的HTTP对比

优点：

1. 传输效率高(二进制传输)

2. 发起调用的一方无需知道RPC的具体实现，如同调用本地函数般调用

缺点：

1. 通用性不如HTTP好(HTTP是标准协议)

总结：RPC适合内部服务间的通信调用；HTTP适合面向用户与服务间的通信调用

##### **介绍一下RPC流程:**

1、调用方持续把请求参数对象序列化成二进制数据，经过 TCP 传输到服务提供方；

2、服务提供方从 TCP 通道里面接收到二进制数据；

3、根据 RPC 协议，服务提供方将二进制数据分割出不同的请求数据，经过反序列化将二进制数据逆向还原出请求对象，找到对应的实现类，完成真正的方法调用；

4、然后服务提供方再把执行结果序列化后，回写到对应的 TCP 通道里面；

5、调用方获取到应答的数据包后，再反序列化成应答对象。

这样调用方就完成了一次 RPC 调用。

RPC 通信流程中的核心组成部分包括了协议、序列化与反序列化，以及网络通信。



#### Redis

##### Redis可以做什么

提到Redis 大多数人的第一想法就是做缓存，但是如果作为开发人员的我们，对于Redis的作用只停留在做缓存上，那么是不合格的。Redis还具有许多其他用途，例如：分布式锁，分布式系统唯一序列号生成器，计数器等等。

在不同的场景下，我们应该选择Redis不同的数据结构进行处理

##### **Redis的数据类型和用法**

1. String字符串 可以为整形、浮点型和字符串，统称为元素，**点赞、计数、粉丝数**
2. Hash
   一个 string 类型的 field（字段） 和 value（值） 的映射表，hash 特别适合用于**存储对象、用户信息**
3. List 有序串列表，**粉丝列表、消息队列**。
4. Set 无序集合，集合成员是唯一的，这就意味着集合中不能出现重复的数据。**共同关注、喜好、好友，标签**。
5. ZSet 有序集合，集合成员是唯一的。**排行榜**。

##### Redis高可用模式——主从复制、哨兵模式、群集模式

1、主从复制：主从复制是高可用Redis的基础，哨兵和集群都是在主从复制基础上实现高可用的。主从复制主要实现了数据的多机备份，以及对于读操作的负载均衡和简单的故障恢复。
缺陷：
●故障恢复无法自动化；
●写操作无法负载均衡；
●存储能力受到单机的限制。
2、哨兵：在主从复制的基础上，哨兵实现了自动化的故障恢复。
缺陷：
●写操作无法负载均衡；
●存储能力受到单机的限制；
●哨兵无法对从节点进行自动故障转移，在读写分离场景下，从节点故障会导致读服务不可用，需要对从节点做额外的监控、切换操作。
3、集群：通过集群，Redis解决了写操作无法负载均衡，以及存储能力受到单机限制的问题，实现了较为完善的高可用方案。

##### 哈希槽介绍

Redis Cluster在设计中没有使用[一致性哈希（Consistency Hashing）](https://www.cnblogs.com/frankcui/p/15354596.html)，而是使用数据分片引入哈希槽（hash slot）来实现；

一个 Redis Cluster包含16384（0~16383）个哈希槽（补充：[为什么redis集群的最大槽数是16384个？](https://www.cnblogs.com/frankcui/p/15354682.html)），存储在Redis Cluster中的所有键都会被映射到这些slot中，集群中的每个键都属于这16384个哈希槽中的一个。按照槽来进行分片，通过为每个节点指派不同数量的槽，可以控制不同节点负责的数据量和请求数.

##### 常用的IO复用模型有三种：select，poll，[epoll](https://so.csdn.net/so/search?q=epoll&spm=1001.2101.3001.7020)

(1)select==>时间复杂度O(n)

它仅仅知道了，有I/O事件发生了，却并不知道是哪那几个流（可能有一个，多个，甚至全部），我们只能无差别轮询所有流，找出能读出数据，或者写入数据的流，对他们进行操作。所以select具有O(n)的无差别轮询复杂度，同时处理的流越多，无差别轮询时间就越长。

(2)poll==>时间复杂度O(n)

poll本质上和select没有区别，它将用户传入的数组拷贝到内核空间，然后查询每个fd对应的设备状态， 但是它没有最大连接数的限制，原因是它是基于链表来存储的.

(3)epoll==>时间复杂度O(1)

epoll可以理解为event poll，不同于忙轮询和无差别轮询，epoll会把哪个流发生了怎样的I/O事件通知我们。所以我们说epoll实际上是事件驱动（每个事件关联上fd）的，此时我们对这些流的操作都是有意义的。（复杂度降低到了O(1)）

select，poll，epoll都是IO多路复用的机制。I/O多路复用就通过一种机制，可以监视多个描述符，一旦某个描述符就绪（一般是读就绪或者写就绪），能够通知程序进行相应的读写操作。但select，poll，epoll本质上都是同步I/O，因为他们都需要在读写事件就绪后自己负责进行读写，也就是说这个读写过程是阻塞的，而异步I/O则无需自己负责进行读写，异步I/O的实现会负责把数据从内核拷贝到用户空间。  

epoll跟select都能提供多路I/O复用的解决方案。在现在的Linux内核里有都能够支持，其中epoll是Linux所特有，而select则应该是POSIX所规定，一般操作系统均有实现

##### **热点发现**

本地缓存的方案中，有一个问题需要解决，**那就是怎么知道哪些数据是热点数据？**因为本地缓存资源有限，不可能把所有的商品数据进行缓存，**它只会缓存热点的数据**。那怎么知道数据是热点数据呢？

**人为预测**

> 就是人工标记，预测这个商品会成为热点，打个标记。web应用根据这个标记把此商品保存到本地缓存中

这个方案，是根据运营人员的经验进行预测，太不靠谱了。

**系统推算**

这个方案是根据**实实在在的数据访问量进行推算**形成，网上也介绍了用访问日志的什么算法，推算哪些是热点数据。 老顾这里分享一个比较简单的方式，就是**利用redis4.x自身特性，LFU机制发现热点数据**。实现很简单，只要把redis内存淘汰机制设置为allkeys-lfu或者volatile-lfu方式，再执行

```text
./redis-cli --hotkeys
```

**会返回访问频率高的key，并从高到底的排序**

##### 线程模型

多个 socket 可能会并发产生不同的操作，每个操作对应不同的文件事件，但是 IO多路复用程序会监听多个 socket，会将产生事件的 socket 放入队列中排队，事件分派器每次从队列中取出一个 socket，根据 socket 的事件类型交给对应的事件处理器进行处理。

##### 文件事件处理器的结构：

- 多个 socket
- IO 多路复用程序
- 文件事件分派器
- 事件处理器（连接应答处理器、命令请求处理器、命令回复处理器）

##### Redis是单线程吗

Redis的演变历程

1、Redis 4之前的版本是单线程

2、Redis 4.x 版本不是严格意思的删除，处理客户端请求的是单线程，添加了异步删除的功能

3、Redis 5.x 版本采用多线程解决问题

##### Redis的单线程指什么

Redis 单线程主要指的是网络IO和键值对读写是由一个线程来完成的，Redis在处理客户端的请求的时候包括获取(Socket)，解析，执行，内容返回(Socket写)等由一个顺序串行的主线程处理，这即为单线程 但Redis的其它功能，比如持久化，异步删除，集群数据同步等等，都是由额外的线程执行的，是多线程 即Redis工作线程是单线程的，但是，整个Redis来说是多线程的

##### Redis单线程为什么很快

1、基于内存操作：Redis的所有数据都存在内存中，因此所有的运算都是内存级别

2、数据结构简单：Redis的数据结构简单，查找和操作时间大部分时间复杂度是O(1)

3、多路复用和非阻塞：Redis使用多路复用功能来监听多个Socket链接客服端，这样可以一个线程处理多个请求，减少线程切换带来的开销，同时也避免了IO阻塞操作

4、避免上下文切换：因为是单线程模型，因此避免了多线程切换和多线程竞争，减少时间和性能的消耗

##### Redis之前为什么采用单线程

1、单线程易于开发和维护

2、单线程模型也可以并发处理多客户端的请求，主要使用多路复用和非阻塞IO

3、对于Redis来说，主要的性能瓶颈是内存或者网络IO而不是CPU

##### Redis为什么要引用多线程

大key删除可以会造成Redis主线程卡顿 当被删除的key是一个非常大的对象时，例如几十兆的对象时，那么删除将是一个非常耗时的操作，其他命令将会不能执行发生阻塞，造成Redis主线程卡顿。如果是在一个高并发的环境下，将会产生十分严重的问题。

这就是redis3.x单线程时代最经典的故障，大key删除的头疼问题。

**那么如何解决大key删除问题呢**

1、惰性删除

2、当删除大key时，因为是单线程，所以会造成Redis服务卡顿，于是在4.0版本新增了多线程的模块用于解决删除数据效率低的问题。处理读写请求仍然只是一个线程

3、unlink key 、flushdb async 、flushall async 异步删除，新起子线程进行删除工作

##### 引入多线程后能够解决大key删除阻塞问题吗

如果是同步删除，那么同样会面临阻塞问题。因为Redis的工作线程（执行命令）任然是单线程。因此在实际工作中应该避免大key的出现



##### **redis的角色**

> Redis是一个可基于内存亦可持久化的日志型、Key-Value数据库。

论持久化，我们平时使用的MySQL就足够了，那为什么还需要引入Redis呢？无法就是 ：**性能** 。

> 数据获取的流程，一般是前端请求，后台先从缓存中取数据，缓存取不到则去数据库中取，数据库取到了则返回给前端，然后更新缓存，如果数据库取不到则返回空数据给前端。

那Redis的性能表现在哪方面呢——**快** 和 **并发**。

##### **redis和数据库的数据一致性**

3种方案保证数据库与缓存的一致性

- 延时双删策略：延时双删的步骤：

  > 1 先删除缓存
  > 2 再更新数据库
  > 3 休眠一会（比如1秒），再次删除缓存。

- 删除缓存重试机制：删除缓存重试机制

  不管是延时双删还是Cache-Aside的先操作数据库再删除缓存，如果第二步的删除缓存失败呢?

  > 删除失败会导致脏数据哦~

  删除失败就多删除几次呀,保证删除缓存成功呀~ 所以可以引入删除缓存重试机制

- 读取biglog异步删除缓存：同步biglog异步删除缓存

  重试删除缓存机制还可以，就是会造成好多业务代码入侵。还可以通过数据库的binlog来异步淘汰key。以mysql为例 可以使用阿里的canal将binlog日志采集发送到MQ队列里面，然后编写一个简单的缓存删除消息者订阅binlog日志，根据更新log删除缓存，并且通过ACK机制确认处理这条更新log，保证数据缓存一致性

在分布式系统中，缓存和数据库同时存在时，如果有写操作的时候，「先操作数据库，再操作缓存」。如下：

1.读取缓存中是否有相关数据
2.如果缓存中有相关数据value，则返回
3.如果缓存中没有相关数据，则从数据库读取相关数据放入缓存中key->value，再返回
4.如果有更新数据，则先更新数据库，再删除缓存
5.为了保证第四步删除缓存成功，使用binlog异步删除
6.如果是主从数据库，binglog取自于从库
7.如果是一主多从，每个从库都要采集binlog，然后消费端收到最后一台binlog数据才删除缓存，或者为了简单，收到一次更新log，删除一次缓存

##### 缓存的问题，击穿，穿透和血崩

- 缓存穿透是指**缓存和数据库中都没有的数据**，而用户不断发起请求，如发起为id为“-1”的数据或id为特别大（不存在的数据）。这时的用户很可能是攻击者，攻击会导致数据库压力过大。
  解决：

1. 接口层增加校验，如用户鉴权校验，id做基础校验，比如 id<=0的直接拦截； 最常见的则是采用**布隆过滤器**，将所有可能存在的数据哈希到一个足够大的bitmap中，一个一定不存在的数据会被这个bitmap拦截掉，从而避免了对底层存储系统的查询压力。

2. 另外也有一个更为**简单粗暴的方法**，如果一个查询返回的数据为空（不管是数据不存在，还是系统故障），我们仍然把这个空结果进行缓存，但它的过期时间会很短，最长不超过五分钟。通过这个直接设置的默认值存放到缓存，这样第二次到缓冲中获取就有值了，而不会继续访问数据库，这种办法最简单粗暴。

- 缓存击穿是指**缓存中没有但数据库中有的数据**，当一个key非常热点（类似于爆款），在不停的扛着大并发，大并发集中对这一个点进行访问；当这个key在失效的瞬间，持续的大并发就穿破缓存，直接请求数据库，就像在一个屏障上凿开了一个洞。
  解决：

1. 设置热点数据永远不过期。
2. 加互斥锁。

- 缓存雪崩是指**缓存中数据大批量到过期时间**，大批量数据同一时间过期，导致请求量全部请求到数据库，造成数据库宕机。
  解决：

1. 给缓存失效时间，加上一个随机值，避免大量缓存集体失效。
2. 双缓存：缓存A和B，比如A的失效时间是20分钟，B不失效。比如从A中没读到，就去B中读，然后异步起一个线程同步到A。

##### **redis的内存淘汰策略**

**内存淘汰策略**

1. noeviction：当内存使用超过配置的时候会返回错误，不会驱逐任何键

2. allkeys-lru：加入键的时候，如果过限，首先通过LRU算法驱逐最久没有使用的键

3. volatile-lru：加入键的时候如果过限，首先从设置了过期时间的键集合中驱逐最久没有使用的键

4. allkeys-random：加入键的时候如果过限，从所有key随机删除

5. volatile-random：加入键的时候如果过限，从过期键的集合中随机驱逐

6. volatile-ttl：从配置了过期时间的键中驱逐马上就要过期的键

7. volatile-lfu：从所有配置了过期时间的键中驱逐使用频率最少的键

8. allkeys-lfu：从所有键中驱逐使用频率最少的键

##### redis过期键的删除策略

其实有三种不同的删除策略：
（1）：立即删除。在设置键的过期时间时，创建一个回调事件，当过期时间达到时，由时间处理器自动执行键的删除操作。
（2）：惰性删除。键过期了就过期了，不管。每次从dict字典中按key取值时，先检查此key是否已经过期，如果过期了就删除它，并返回nil，如果没过期，就返回键值。
（3）：定时删除。每隔一段时间，对expires字典进行检查，删除里面的过期键。
可以看到，第二种为被动删除，第一种和第三种为主动删除，且第一种实时性更高。下面对这三种删除策略进行具体分析。

#### 面试真题

##### 接口的幂等性怎么设计？

**幂等性：**多次调用方法或者接口不会改变业务状态，可以保证重复调用的结果和单次调用的结果一致。

##### **使用幂等的场景**

**1、前端重复提交**

用户注册，用户创建商品等操作，前端都会提交一些数据给后台服务，后台需要根据用户提交的数据在数据库中创建记录。如果用户不小心多点了几次，后端收到了好几次提交，这时就会在数据库中重复创建了多条记录。这就是接口没有幂等性带来的 bug。

**2、接口超时重试**

对于给第三方调用的接口，有可能会因为网络原因而调用失败，这时，一般在设计的时候会对接口调用加上失败重试的机制。如果第一次调用已经执行了一半时，发生了网络异常。这时再次调用时就会因为脏数据的存在而出现调用异常。

**3、消息重复消费**

在使用消息中间件来处理消息队列，且手动 ack 确认消息被正常消费时。如果消费者突然断开连接，那么已经执行了一半的消息会重新放回队列。当消息被其他消费者重新消费时，如果没有幂等性，就会导致消息重复消费时结果异常，如数据库重复数据，数据库数据冲突，资源重复等。

##### **接口的幂等性解决方案**

**1、token 机制实现**

通过token 机制实现接口的幂等性,这是一种比较通用性的实现方法。

**2、基于 mysql 实现**

这种实现方式是利用 mysql 唯一索引的特性。

**3、基于 redis 实现**

这种实现方式是基于 SETNX 命令实现的

SETNX key value：将 key 的值设为 value ，当且仅当 key 不存在。若给定的 key 已经存在，则 SETNX 不做任何动作。

该命令在设置成功时返回 1，设置失败时返回 0。

**总结**

这几种实现幂等的方式其实都是大同小异的，类似的还有使用状态机、悲观锁、乐观锁的方式来实现，都是比较简单的。

总之，当你去设计一个接口的时候，幂等都是首要考虑的问题，特别是当你负责设计转账、支付这种涉及到 money 的接口，你要格外注意喽！

#####  kafka 如何解决消息队列重复消费

**1、消息重复消费场景**
kafka实际上有个offset的概念，就是每个消息写进去，都有一个offset，代表他的序号，然后consumer消费了数据之后，每隔一段时间，会把自己消费过的消息的offset提交一下，代表已经消费过了，下次消费时，会继续从上次消费到的最后一次offset来继续消费。但是凡事总有意外，比如我们之前生产经常遇到的，就是你有时候重启系统，看你怎么重启了，如果碰到点着急的，直接kill进程了，再重启。这会导致consumer有些消息处理了，但是没来得及提交offset。重启之后，少数消息会再次消费一次。
**2、如何保证消息重复消费后的幂等性**
其实重复消费不可怕，可怕的是没考虑到重复消费之后，怎么保证幂等性（一个数据，或者一个请求，给你重复来多次，你得确保对应的数据是不会改变的，不能出错）。

假设你有个系统，消费一条往数据库里插入一条，要是你一个消息重复两次，你不就插入了两条，这数据不就错了？但是你要是消费到第二次的时候，自己判断一下是否已经消费过了，则直接扔了。一条数据重复出现两次，数据库里就只有一条数据，这就保证了系统的幂等性。

 结合业务来思考，我这里给几个思路：

（1）数据写库时，你先根据主键查询一下，如果这数据都有了，则不进行插入，而直接进行update处理，如果是写redis，那没问题了，反正每次都是set，具有天然幂等性。

（2）让生产者发送每条数据的时候，数据里面加一个全局唯一的id，类似订单id之类的东西，然后你这里消费到了之后，先根据这个id 去数据库中查询，如果没有消费过，将该数据写入。如果消费过了，就不进行处理， 保证别重复处理相同的消息即可。

（3）基于数据库的唯一键来保证重复数据不会重复插入多条，因为有唯一键约束了，所以重复数据只会插入报错，不会导致数据库中出现脏数据。

##### hash冲突

就是键(key)经过hash函数得到的结果作为地址去存放当前的键值对(key-value)(这个是hashmap的存值方式)，但是却发现该地址已经有人先来了，一山不容二虎，就会产生冲突。这个冲突就是hash冲突了。
一句话说就是：如果两个不同对象的hashCode相同，这种现象称为hash冲突。

解决hash冲突的办法
开发定址法（线性探测再散列，二次探测再散列，伪随机探测再散列）
再哈希法
链地址法
建立一个公共溢出区
java中hashmap采用的是链地址法

##### 其他面试题


spring的原理，I0C时 ，如何解决bean循环依赖的问题? BeanFactoryPostProcessor的作用? BeanPostProcessor的作用? 对象初始化得到具体的实例对象的时机是什么时候,以及注入的方式有哪些?构造? Setter?

项目中有进行重构迁移的操作?这部分怎么解决的?数据如何迁移?全量迁移还是增量迁移?

Redis中的数据扩容怎么实现?

队列的实现原理? Queue的实现原理?如果数组长度都不够了，如何操作?是移除头部元素?还是扩容?又或循环数组?

分布式事务的思想?如何实现? 2PC是什么? TCC怎么实现补偿机制的?3PC呢?

若有相互调用的系统,位于一个分布式事务中，若-一个 系统宕机了，整个分布式事务如何进行回滚的?逻辑怎么进行?

CountDown (闭锁)怎么实现线程阻塞的?最后一同执行，怎么保证同时唤醒操作?

Map的put方法详解? size方法怎么操作的?

●主要面了项目深挖(整体架构，技术对比和选择原因，负载均衡策略，几种io模型,

●这块比较熟悉说了很多，面试官也没有打断，还追问了epoll具体实现，触发方式等)数据库隔离级别，锁，mvcc的MySQL查询比较慢的话，通过什么方式来优化

●多线程，juc包里的具体实现

●JVM内存模型、垃圾收集算法、判断是否可回收



boolean isOdd(int i,Integer j)和booleanisOdd(Integer i,int j)构成重载吗?如果传int类型和包装类型会调用哪个方法?会报错吗?编译期错误还是运行时错误?具体报什么错?如果入参是两个int类型参数呢? 

问手写非递归线索遍历二叉树算法。

●一面主要是基本技术能力考察，涉及Java基础、多线程、锁、常用中间件、开发框架以及算法。

●整体由浅入深，会结合实际项目进行技术考察，对于中间件如Redis、mq、es都有 所涉及,

●数据库主要是MySQL的InnoDB引擎， 涉及sq|调优内容，框架基本就是spring那-套,常见的源码，也会问问spring cloud。

●算法题不是很难，需要手写。

●一面大概是40-60分钟，沟通比较顺畅。

1二面

●二面是架构师/CTO面，基本围绕原理层面的东西考察。

##### 前中后序递归遍历

- 前序遍历

```java
public List<Integer> preorderTraversal(TreeNode root) {
    List<Integer> list = new ArrayList<Integer>();
    if(root == null) return list;
    Stack<TreeNode> stack = new Stack<TreeNode>();
    while(root != null || !stack.isEmpty()) {
    	// 初始时，先将这棵树的所有最左侧的节点入栈，并添加到list中（因为是先序遍历）
        while(root != null){
            stack.push(root);
            list.add(root.val);
            root = root.left;
        }
        // 此时root已经为空，获取栈顶元素，就是最后一个入栈的左侧节点
        root = stack.pop();
        // 如果栈顶元素的右节点不为空，那么就指向右节点
        if(root.right != null) {
            root = root.right;
        }else{
        // 如果栈顶元素右节点为空，此时当前节点已经被添加过list中了，所以，将他设置为空，然后等待新的栈顶元素赋给他
            root = null;
        }
    }
    return list;
}
```

+ 中序遍历

```java
public List<Integer> inorderTraversal(TreeNode root) {
    List<Integer> list = new ArrayList<Integer>();
    if(root == null) return list;
    Stack<TreeNode> stack = new Stack<TreeNode>();
    while(root != null || !stack.isEmpty()) {
        while(root != null) {
            stack.push(root);
            root = root.left;
        }
        root = stack.pop();
        list.add(root.val);
        if(root.right == null) {
            root = null;
        }else{
            root = root.right;
        }
    }
    return list;
}
```

+ 后序遍历

```java
public List<Integer> postorderTraversal(TreeNode root) {
    List<Integer> list = new ArrayList<Integer>();
    if(root == null) return list;
    // 栈
    Stack<TreeNode> stack = new Stack<TreeNode>();
    TreeNode pre = null;
    while(root != null || !stack.isEmpty()) {
        while(root != null) {
            stack.push(root);
            root = root.left;
        }
        // 说明上一个节点的左子树为空
        root = stack.pop();
        // 然后判断右子树,如果右子树为空或者右子树已经遍历过
        if(root.right == null || root.right == pre) {
            list.add(root.val);
            pre = root;
            root = null;
        }else{
            // 如果还有右子树，那就遍历右子树
            stack.push(root);
            root = root.right;
        }
    }
    return list;
}
```







##### 锁竞争

**锁竞争**

影响锁竞争性的条件有两个：锁被请求的频率和每次持有锁的时间。显然当而这二者都很小的时候，锁竞争不会成为主要的瓶颈。但是如果锁使用不当，导致二者都比较大，那么很有可能CPU不能有效的处理任务，任务被大量堆积。

所以减少锁竞争的方式有下面三种：

1. 减少锁持有的时间
2. 减少锁请求的频率
3. 采用共享锁取代独占锁

**死锁**

1.一种情况是线程A永远不释放锁，结果B一直拿不到锁，所以线程B就“死掉”了
2.第二种情况下，线程A拥有线程B需要的锁Y，同时线程B拥有线程A需要的锁X，那么这时候线程A/B互相依赖对方释放锁，于是二者都“死掉”了。
3.如果一个线程总是不能被调度，那么等待此线程结果的线程可能就死锁了。这种情况叫做线程饥饿死锁。比如说非公平锁中，如果某些线程非常活跃，在高并发情况下这类线程可能总是拿到锁，那么那些活跃度低的线程可能就一直拿不到锁，这样就发生了“饥饿死”。

避免死锁的解决方案是：
1.尽可能的按照锁的使用规范请求锁，另外锁的请求粒度要小（不要在不需要锁的地方占用锁，锁不用了尽快释放）；
2.在高级锁里面总是使用tryLock或者定时机制（就是指定获取锁超时的时间，如果时间到了还没有获取到锁那么就放弃）。高级锁（Lock）里面的这两种方式可以有效的避免死锁。

##### HashMap性能分析

引入红黑树的原因
 HashMap的查询、插入、修改、删除平均时间复杂度都是O(1)。最坏的情况是所有的key都散列到一个Entry中，时间复杂度会退化成O(N)。这就是为什么Java8的HashMap引入了红黑树的原因。当Entry中的链表长度超过8，链表会进化成红黑树。红黑树是一个自平衡二叉查找树，它的查询/插入/修改/删除的平均时间复杂度为O(log(N))。

小结
1）扩容是一个特别耗性能的操作，所以当程序员在使用HashMap的时候，估算map的大小，初始化的时候给一个大致的数值，避免map进行频繁的扩容。
2）负载因子是可以修改的，也可以大于1，但是建议不要轻易修改，除非情况非常特殊。
3）HashMap是线程不安全的，不要在并发的环境中同时操作HashMap，建议使用ConcurrentHashMap。
4）JDK1.8引入红黑树大程度优化了HashMap的性能。
5）HashMap的key为null时不会报空指针异常，但Hashtable会。 

##### 单例模式

**1、懒汉式，线程不安全**:这种方式是最基本的实现方式，这种实现最大的问题就是不支持多线程。因为没有加锁 synchronized，所以严格意义上它并不算单例模式。
这种方式 lazy loading 很明显，不要求线程安全，在多线程不能正常工作。

```java
public class Singleton {  
    private static Singleton instance;  
    private Singleton (){}  
  
    public static Singleton getInstance() {  
        if (instance == null) {  
            instance = new Singleton();  
        }  
        return instance;  
    }  
}
```

**2、懒汉式，线程安全**：这种方式具备很好的 lazy loading，能够在多线程中很好的工作，但是，效率很低，99% 情况下不需要同步。
优点：第一次调用才初始化，避免内存浪费。
缺点：必须加锁 synchronized 才能保证单例，但加锁会影响效率。
getInstance() 的性能对应用程序不是很关键（该方法使用不太频繁）。

```java
public class Singleton {  
    private static Singleton instance;  
    private Singleton (){}  
    public static synchronized Singleton getInstance() {  
        if (instance == null) {  
            instance = new Singleton();  
        }  
        return instance;  
    }  
}
```

**3、饿汉式**:这种方式比较常用，但容易产生垃圾对象。
优点：没有加锁，执行效率会提高。
缺点：类加载时就初始化，浪费内存。
它基于 classloader 机制避免了多线程的同步问题，不过，instance 在类装载时就实例化，虽然导致类装载的原因有很多种，在单例模式中大多数都是调用 getInstance 方法， 但是也不能确定有其他的方式（或者其他的静态方法）导致类装载，这时候初始化 instance 显然没有达到 lazy loading 的效果。

```java
public class Singleton {  
    private static Singleton instance = new Singleton();  
    private Singleton (){}  
    public static Singleton getInstance() {  
    return instance;  
    }  
}
```

**4、双检锁/双重校验锁（DCL，即 double-checked locking）****：这种方式采用双锁机制，安全且在多线程情况下能保持高性能。
getInstance() 的性能对应用程序很关键。

```java
public class Singleton {  
    private volatile static Singleton singleton;  
    private Singleton (){}  
    public static Singleton getSingleton() {  
    if (singleton == null) {  
        synchronized (Singleton.class) {  
            if (singleton == null) {  
                singleton = new Singleton();  
            }  
        }  
    }  
    return singleton;  
    }  
}
```

反转链表

```java
import java.util.*;
public class Solution {
    public ListNode ReverseList(ListNode head) {
        Stack<ListNode> stack=new Stack();
        while(head!=null){
            stack.push(head);
            head=head.next;
        }
        if(stack.isEmpty()){
            return null;
        }
        ListNode node=stack.pop();
        ListNode dummy=node;
        while(!stack.isEmpty()){
            node.next=stack.pop();
            node=node.next;
        }
        node.next=null;
        return dummy;
    }
}
```

##### 排序算法

+ 冒泡排序及其优化

```java
public class bubble_Sort {
    public static void sort(int arr[]){
        for( int i = 0 ; i < arr.length - 1 ; i++ ){
            for(int j = 0;j < arr.length - 1 - i ; j++){
                int temp = 0;
                if(arr[j] > arr[j + 1]){
                    temp = arr[j];
                    arr[j] = arr[j + 1];
                    arr[j + 1] = temp;
                }
            }
        }
    }
}
// 优化
public class Bubble_Sort_optimization {
    public static void sort(int arr[]){
        for( int i = 0;i < arr.length - 1 ; i++ ){
            boolean isSort = true;
            for( int j = 0;j < arr.length - 1 - i ; j++ ){
                int temp = 0;
                if(arr[j] > arr[j + 1]){
                    temp = arr[j];
                    arr[j] = arr[j + 1];
                    arr[j + 1] = temp;
                    isSort = false;
                }
            }
            if(isSort){
                break;
            }
        }
    }
}
```

+ 插入排序

```java
//  插入排序，比较有效地排序方法
    public static void insertionSort(int[] arr) {
        if (arr == null || arr.length < 2) {
            return;
        }
        for (int i = 1; i < arr.length; i++) {
            //使0到i范围内有序
            for (int j = i - 1; j >= 0 && arr[j] > arr[j + 1]; j--) {
                swap(arr, j, j + 1);
            }
        }
    }
//  交换数组中的i, j位置上的元素
    private static void swap(int[] arr, int i, int j) {
        int temp = arr[i];
        arr[i] = arr[j];
        arr[j] = temp;
    }
```

+ 选择排序

```java
public static void selectioinSort(int[] arr) {
    if(arr == null || arr.length < 2) {
        return;
    }
    for (int i = 0; i < arr.length - 1; i++) {
        int minIndex = i;
        for (int j = i + 1; j < arr.length; j++) {
            minIndex = arr[j] < arr[minIndex] ? j : minIndex;
        }
        swap(arr, i, minIndex);
    }
}
```

+ 快速排序

```java
    static void quickSort(int[] nums,int l,int r){
        if(l>=r){
            return;
        }
        int x=nums[l];
        int i=l-1,j=r+1;
        while (i<j){
            do i++;while(nums[i]<x);
            do j--;while(nums[j]>x);
            if(i<j){
                int temp=nums[i];
                nums[i]=nums[j];
                nums[j]=temp;
            }
        }
        quickSort(nums, l, j);
        quickSort(nums,j+1,r);
    }
```

+ 第k个数

```java
public static void main(String[] args){
    int N=100010;
    Scanner sc=new Scanner(System.in);
    int n=sc.nextInt();
    int k=sc.nextInt();
    int[] nums=new int[N];
    for(int i=0;i<n;i++){
        nums[i]=sc.nextInt();
    }
    System.out.println(quickSort(nums,0,n-1,k-1));
}
static int quickSort(int[] nums,int l,int r,int k){
    if(l>=r){
        return nums[k];
    }
    int x=nums[l];
    int i=l-1;
    int j=r+1;
    while(i<j){
        do i++;while(nums[i]<x);
        do j--;while(nums[j]>x);
        if(i<j){
            int temp=nums[i];
            nums[i]=nums[j];
            nums[j]=temp;
        }
    }
    if(k<=j) return quickSort(nums,l,j,k);
    else return quickSort(nums,j+1,r,k);
}
```

+ 归并排序

```java
static void mergeSort(int[] nums,int l,int r){
    if(l>=r){
        return;
    }
    int mid=l+((r-l)>>1);
    mergeSort(nums, l, mid);
    mergeSort(nums, mid+1, r);
    int i=l,j=mid+1,k=0;
    int[] temp=new int[r-l+1];
    while(i<=mid&&j<=r){
        if(nums[i]<=nums[j]){
            temp[k++]=nums[i++];
        }else{
            temp[k++]=nums[j++];
        }
    }
    while(i<=mid){
        temp[k++]=nums[i++];
    }
    while(j<=r){
        temp[k++]=nums[j++];
    }
    for(i=l,j=0;i<=r;i++,j++){
        nums[i]=temp[j];
    }
}
```

+ 逆序对的数量

```java
public class NixuduiNum {
    static long mergeSort(int[] nums,int l,int r){
        if(l>=r){
            return 0;
        }
        int mid = l+((r-l)>>1);
        long res = 0;
        res += mergeSort(nums, l, mid)+mergeSort(nums, mid+1, r);
        int[] temp=new int[r-l+1];
        int i=l,j=mid+1,k=0;
        while(i<=mid&&j<=r){
            if(nums[i]<=nums[j]){
                temp[k++]=nums[i++];
            }else{
                temp[k++]=nums[j++];
                res+=mid-i+1;
            }
        }
        while(i<=mid) temp[k++]=nums[i++];
        while(j<=r) temp[k++] = nums[j++];
        for(i=l,j=0;i<=r;i++,j++){
            nums[i]=temp[j];
        }
        return res;
    }
    public static void main(String[] args) {
        Scanner sc = new Scanner(System.in);
        int n = sc.nextInt();
        int[] nums=new int[n];
        int i=0;
        while(i<n){
            nums[i++]=sc.nextInt();
        }
        System.out.println(mergeSort(nums, 0, nums.length - 1));
    }
}
```

##### 常见Linux指令

+ 常用指令
  ls　　        显示文件或目录

     -l           列出文件详细信息l(list)
  
     -a          列出当前目录下所有文件及目录，包括隐藏的a(all)

mkdir         创建目录

     -p           创建目录，若无父目录，则创建p(parent)

cd               切换目录

touch          创建空文件

echo            创建带有内容的文件。

cat              查看文件内容

cp                拷贝

mv               移动或重命名

rm               删除文件

     -r            递归删除，可删除子目录及文件
    
     -f            强制删除

find              在文件系统中搜索某文件

wc                统计文本中行数、字数、字符数

grep             在文本文件中查找某个字符串

rmdir           删除空目录

tree             树形结构显示目录，需要安装tree包

pwd              显示当前目录

ln                  创建链接文件

more、less  分页显示文本文件内容

head、tail    显示文件头、尾内容

ctrl+alt+F1  命令行全屏模式

+ 系统管理命令

  stat              显示指定文件的详细信息，比ls更详细

who               显示在线登陆用户

whoami          显示当前操作用户

hostname      显示主机名

uname           显示系统信息

top                动态显示当前耗费资源最多进程信息

ps                  显示瞬间进程状态 ps -aux

du                  查看目录大小 du -h /home带有单位显示目录信息

df                  查看磁盘大小 df -h 带有单位显示磁盘信息

ifconfig          查看网络情况

ping                测试网络连通

netstat          显示网络状态信息

man                命令不会用了，找男人  如：man ls

clear              清屏

alias               对命令重命名 如：alias showmeit="ps -aux" ，另外解除使用unaliax showmeit

kill                 杀死进程，可以先用ps 或 top命令查看进程的id，然后再用kill命令杀死进程。


+ 打包压缩相关命令
  gzip：

bzip2：

tar:                打包压缩

     -c              归档文件
    
     -x              压缩文件
    
     -z              gzip压缩文件
    
     -j              bzip2压缩文件
    
     -v              显示压缩或解压缩过程 v(view)
    
     -f              使用档名

例：

tar -cvf /home/abc.tar /home/abc              只打包，不压缩

tar -zcvf /home/abc.tar.gz /home/abc        打包，并用gzip压缩

tar -jcvf /home/abc.tar.bz2 /home/abc      打包，并用bzip2压缩

当然，如果想解压缩，就直接替换上面的命令  tar -cvf  / tar -zcvf  / tar -jcvf 中的“c” 换成“x” 就可以了。

+ 关机/重启机器
  shutdown

     -r             关机重启
  
     -h             关机不重启
  
     now          立刻关机

halt               关机

reboot          重启


+ Linux管道
  将一个命令的标准输出作为另一个命令的标准输入。也就是把几个命令组合起来使用，后一个命令除以前一个命令的结果。

例：grep -r "close" /home/* | more       在home目录下所有文件中查找，包括close的文件，并分页输出。

+ Linux软件包管理
  dpkg (Debian Package)管理工具，软件包名以.deb后缀。这种方法适合系统不能联网的情况下。

比如安装tree命令的安装包，先将tree.deb传到Linux系统中。再使用如下命令安装。

sudo dpkg -i tree_1.5.3-1_i386.deb         安装软件

sudo dpkg -r tree                                     卸载软件

注：将tree.deb传到Linux系统中，有多种方式。VMwareTool，使用挂载方式；使用winSCP工具等；

APT（Advanced Packaging Tool）高级软件工具。这种方法适合系统能够连接互联网的情况。

依然以tree为例

sudo apt-get install tree                         安装tree

sudo apt-get remove tree                       卸载tree

sudo apt-get update                                 更新软件

sudo apt-get upgrade        

将.rpm文件转为.deb文件

.rpm为RedHat使用的软件格式。在Ubuntu下不能直接使用，所以需要转换一下。

sudo alien abc.rpm

+ vim使用
  vim三种模式：命令模式、插入模式、编辑模式。使用ESC或i或：来切换模式。

命令模式下：

:q                      退出

:q!                     强制退出

:wq                   保存并退出

:set number     显示行号

:set nonumber  隐藏行号

/apache            在文档中查找apache 按n跳到下一个，shift+n上一个

yyp                   复制光标所在行，并粘贴

h(左移一个字符←)、j(下一行↓)、k(上一行↑)、l(右移一个字符→)

+ 用户及用户组管理
  /etc/passwd    存储用户账号

/etc/group       存储组账号

/etc/shadow    存储用户账号的密码

/etc/gshadow  存储用户组账号的密码

useradd 用户名

userdel 用户名

adduser 用户名

groupadd 组名

groupdel 组名

passwd root     给root设置密码

su root

su - root 

/etc/profile     系统环境变量

bash_profile     用户环境变量

.bashrc              用户环境变量

su user              切换用户，加载配置文件.bashrc

su - user            切换用户，加载配置文件/etc/profile ，加载bash_profile

更改文件的用户及用户组
sudo chown [-R] owner[:group] {File|Directory}

例如：还以jdk-7u21-linux-i586.tar.gz为例。属于用户hadoop，组hadoop

要想切换此文件所属的用户及组。可以使用命令。

sudo chown root:root jdk-7u21-linux-i586.tar.gz